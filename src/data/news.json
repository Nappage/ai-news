{
  "lastUpdated": "2026-02-19T02:00:47.267Z",
  "totalArticles": 33,
  "articles": [
    {
      "id": "mlstd54zmjuq2tf1mpc",
      "title": "A new way to express yourself: Gemini can now create music",
      "summary": "Lyria 3 is now available in the Gemini app. Create custom, high-quality 30-second tracks from text and images.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/0217_KeywordHeaderFinalc.max-600x600.format-webp.webp\">Lyria 3 is now available in the Gemini app. Create custom, high-quality 30-second tracks from text and images.",
      "publishedAt": "2026-02-18T16:00:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI"
      ],
      "featured": true
    },
    {
      "id": "mlstd54zgfaxald9t4p",
      "title": "Our 2026 Responsible AI Progress Report",
      "summary": "A look at our 2026 Responsible AI Progress Report.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Stocksy_7137793.max-600x600.format-webp.webp\">A look at our 2026 Responsible AI Progress Report.",
      "publishedAt": "2026-02-17T22:30:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/products/responsible-ai-2026-report-ongoing-work/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": true
    },
    {
      "id": "mlstd46vke99xru94gr",
      "title": "Introducing the Developer Knowledge API and MCP Server",
      "summary": "Google is launching the Developer Knowledge API and MCP Server in public preview. This new toolset provides a canonical, machine-readable way for AI assistants and agentic platforms to search and retrieve up-to-date documentation across Firebase, Google Cloud, Android, and more. By using the officia...",
      "content": "Google is launching the Developer Knowledge API and MCP Server in public preview. This new toolset provides a canonical, machine-readable way for AI assistants and agentic platforms to search and retrieve up-to-date documentation across Firebase, Google Cloud, Android, and more. By using the official MCP server, developers can connect tools directly to Google‚Äôs documentation corpus, ensuring that AI-generated code and guidance are based on authoritative, real-time context.",
      "publishedAt": "2026-02-16T02:00:12.919Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/introducing-the-developer-knowledge-api-and-mcp-server/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": true
    },
    {
      "id": "mlstd46vvtbfsiga23q",
      "title": "Making Gemini CLI extensions easier to use",
      "summary": "To simplify the user experience and prevent startup failures, the Gemini CLI has introduced structured extension settings that eliminate the need for manual environment variable configuration. This update enables extensions to automatically prompt users for required details during installation and s...",
      "content": "To simplify the user experience and prevent startup failures, the Gemini CLI has introduced structured extension settings that eliminate the need for manual environment variable configuration. This update enables extensions to automatically prompt users for required details during installation and securely stores sensitive information, such as API keys, directly in the system keychain. Users can now easily manage and override these configurations globally or per project using the new Gemini extensions config command.",
      "publishedAt": "2026-02-15T02:00:12.919Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/making-gemini-cli-extensions-easier-to-use/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI"
      ],
      "featured": true
    },
    {
      "id": "mlstd1d6utdrv2b40zf",
      "title": "Scaling social science research",
      "summary": "GABRIEL is a new open-source toolkit from OpenAI that uses GPT to turn qualitative text and images into quantitative data, helping social scientists analyze research at scale.",
      "content": "GABRIEL is a new open-source toolkit from OpenAI that uses GPT to turn qualitative text and images into quantitative data, helping social scientists analyze research at scale.",
      "publishedAt": "2026-02-13T09:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/scaling-social-science-research",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "GPT",
        "AI",
        "OpenAI"
      ],
      "featured": true
    },
    {
      "id": "mlstd54zofmmehr5rpe",
      "title": "Gemini 3 Deep Think: Advancing science, research and engineering",
      "summary": "We‚Äôre releasing a major upgrade to Gemini 3 Deep Think, our specialized reasoning mode.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_deep-think_keyword_hea.max-600x600.format-webp.webp\">We‚Äôre releasing a major upgrade to Gemini 3 Deep Think, our specialized reasoning mode.",
      "publishedAt": "2026-02-12T16:13:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini"
      ],
      "featured": true
    },
    {
      "id": "mlstd46vblnquycf20c",
      "title": "Get ready for Google I/O 2026",
      "summary": "Google I/O returns May 19-20. Watch the livestreams for updates on Android, AI, Chrome, and Cloud. Registration is open on the Google I/O website.",
      "content": "Google I/O returns May 19-20. Watch the livestreams for updates on Android, AI, Chrome, and Cloud. Registration is open on the Google I/O website.",
      "publishedAt": "2026-02-12T02:00:12.919Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/get-ready-for-google-io-2026/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": true
    },
    {
      "id": "mlstd46vobyx6zgq05",
      "title": "Tailor Gemini CLI to your workflow with hooks",
      "summary": "New Gemini CLI hooks (v0.26.0+) let you tailor the agentic loop. Add context, enforce policies, and block secrets with custom scripts that run at predefined points in your workflow.",
      "content": "New Gemini CLI hooks (v0.26.0+) let you tailor the agentic loop. Add context, enforce policies, and block secrets with custom scripts that run at predefined points in your workflow.",
      "publishedAt": "2026-02-12T02:00:12.919Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/tailor-gemini-cli-to-your-workflow-with-hooks/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI"
      ],
      "featured": true
    },
    {
      "id": "mlstd54znoa3rpq1bgq",
      "title": "How we‚Äôre helping democracies stay ahead of digital threats",
      "summary": "An overview of Google‚Äôs work at the 2026 Munich Security Conference, including a new whitepaper, AI updates and security recommendations.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/digitalthreats2026_Hero.max-600x600.format-webp.webp\">An overview of Google‚Äôs work at the 2026 Munich Security Conference, including a new whitepaper, AI updates and security recommendations.",
      "publishedAt": "2026-02-11T22:00:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/technology/safety-security/how-were-helping-democracies-stay-ahead-of-digital-threats/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": true
    },
    {
      "id": "mlstdt3o1rync3fzesi",
      "title": "Ask HN: Has Claude Code become slower?",
      "summary": "I&#x27;ve noticed that Claude Code has become noticeably slower and sometimes gets stuck for sometime. It used to be much more responsive earlier.<p>Is it just me or my environment&#x2F;prompts&#x2F;code or have others noticed it too? Compacting has no impact as far as I can tell.<p>If others have n...",
      "content": "I&#x27;ve noticed that Claude Code has become noticeably slower and sometimes gets stuck for sometime. It used to be much more responsive earlier.<p>Is it just me or my environment&#x2F;prompts&#x2F;code or have others noticed it too? Compacting has no impact as far as I can tell.<p>If others have noticed it, could it be Anthropic throttling or just being stressed due to scaling issues?",
      "publishedAt": "2025-09-03T23:41:01.000Z",
      "source": "Hacker News Claude/Anthropic",
      "sourceUrl": "https://news.ycombinator.com/item?id=45121608",
      "category": "companies",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlstdt3o3xbrjlfzaww",
      "title": "Claude.ai do not deliver what I payed for",
      "summary": "Hi,<p>is someone else encountering difficulties in usage? I have a pro-plan - even if its not the MAX, I still pay for Opus 4 model and can&#x27;t use it since hours. Its &quot;overloaded&quot; - without my money, it wouldn&#x27;t even load - is Anthropic misunderstanding this fact???<p>I&#x27;ll ca...",
      "content": "Hi,<p>is someone else encountering difficulties in usage? I have a pro-plan - even if its not the MAX, I still pay for Opus 4 model and can&#x27;t use it since hours. Its &quot;overloaded&quot; - without my money, it wouldn&#x27;t even load - is Anthropic misunderstanding this fact???<p>I&#x27;ll cancel my subscription. I can&#x27;t use Opus 4 without paying either. That&#x27;s such a bad move.<p>What legal options do I have to get my money back or a compensation for not being able to use what I pay for? I&#x27;m really upset on such behavior.<p>I don&#x27;t do Claude Code or do have a large codebase, nor do I feed in image-files or do voice data - I just want it to help me code in my hobby project wit &lt; 2000 lines of python.<p>I hate it!",
      "publishedAt": "2025-07-30T15:32:13.000Z",
      "source": "Hacker News Claude/Anthropic",
      "sourceUrl": "https://news.ycombinator.com/item?id=44735552",
      "category": "companies",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "AI",
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlstd29xr49vhbb3p8",
      "title": "IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-18T16:15:45.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/ibm-research/itbenchandmast",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlstd54zzifnfkhq9bb",
      "title": "AI Impact Summit 2026: How we‚Äôre partnering to make AI work for everyone",
      "summary": "An overview of Google‚Äôs new global partnerships and funding announcements at the AI Impact Summit in India.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI-Summit-Hero.max-600x600.format-webp.webp\">An overview of Google‚Äôs new global partnerships and funding announcements at the AI Impact Summit in India.",
      "publishedAt": "2026-02-18T10:30:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlstd54z6b1312vbhgd",
      "title": "AI Impact Summit 2026",
      "summary": "A look at the partnerships and investments Google announced at the AI Impact Summit 2026.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Collection_Hero-2.max-600x600.format-webp.webp\">A look at the partnerships and investments Google announced at the AI Impact Summit 2026.",
      "publishedAt": "2026-02-18T10:30:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-collection/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlstd46vy0jzf8ftfhb",
      "title": "Access public data insights faster: Data Commons MCP is now hosted on Google Cloud",
      "summary": "Data Commons has launched a free, hosted Model Context Protocol (MCP) service on Google Cloud Platform, eliminating the need for users to manage complex local server installations. This update simplifies connecting AI agents and the Gemini CLI to Data Commons, allowing Google to handle security, upd...",
      "content": "Data Commons has launched a free, hosted Model Context Protocol (MCP) service on Google Cloud Platform, eliminating the need for users to manage complex local server installations. This update simplifies connecting AI agents and the Gemini CLI to Data Commons, allowing Google to handle security, updates, and resource management while users query data natively.",
      "publishedAt": "2026-02-18T02:00:12.919Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/access-public-data-insights-faster-data-commons-mcp-is-now-hosted-on-google-cloud/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlstd29xon7dx3yqax",
      "title": "One-Shot Any Web App with Gradio's gr.HTML",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-18T00:00:00.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/gradio-html-one-shot-apps",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "ML"
      ],
      "featured": false
    },
    {
      "id": "mlstd29xtcdnw0liemr",
      "title": "NVIDIA Nemotron 2 Nano 9B Japanese: Êó•Êú¨„ÅÆ„ÇΩ„Éñ„É™„É≥AI„ÇíÊîØ„Åà„ÇãÊúÄÂÖàÁ´ØÂ∞èË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-17T23:28:52.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/nvidia/nemotron-nano-9b-v2-japanese-ja",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlstd54zxuzxqfmrii",
      "title": "Save the date! Google I/O 2026 is May 19-20.",
      "summary": "Google I/O, our annual developer conference, is taking place at Shoreline Amphitheatre in Mountain View, California.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO26_SVD_16x9_v012.max-600x600.format-webp.webp\">Google I/O, our annual developer conference, is taking place at Shoreline Amphitheatre in Mountain View, California.",
      "publishedAt": "2026-02-17T19:50:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/technology/developers-tools/io-2026-save-the-date/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlstd54z8tleiq5m60d",
      "title": "Resilience in the AI era: Google at MSC 2026",
      "summary": "At MSC 2026, Google‚Äôs Kent Walker urged a full-stack, AI-driven approach to security to counter sophisticated, enterprise-scale threats.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/MSC-2026_1.max-600x600.format-webp.webp\">At MSC 2026, Google‚Äôs Kent Walker urged a full-stack, AI-driven approach to security to counter sophisticated, enterprise-scale threats.",
      "publishedAt": "2026-02-17T19:10:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/technology/safety-security/resilience-in-the-ai-era-google-at-msc-2026/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlstdb340sbtkv268wa",
      "title": "Accelerating discovery in India through AI-powered science and education",
      "summary": "Google DeepMind brings National Partnerships for AI initiative to India, scaling AI for science and education",
      "content": "Google DeepMind brings National Partnerships for AI initiative to India, scaling AI for science and education",
      "publishedAt": "2026-02-17T13:42:20.000Z",
      "source": "DeepMind Blog",
      "sourceUrl": "https://deepmind.google/blog/accelerating-discovery-in-india-through-ai-powered-science-and-education/",
      "category": "research",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlstd46v27dfog9bvsf",
      "title": "Conductor Update: Introducing Automated Reviews",
      "summary": "Conductor for the Gemini CLI has introduced a new Automated Review feature designed to verify the quality and accuracy of AI-generated code. This update addresses the challenge of validating agentic development by automatically checking implementations against original plans, enforcing style guides,...",
      "content": "Conductor for the Gemini CLI has introduced a new Automated Review feature designed to verify the quality and accuracy of AI-generated code. This update addresses the challenge of validating agentic development by automatically checking implementations against original plans, enforcing style guides, and identifying security risks or bugs. by incorporating test-suite validation and providing actionable reports, Conductor helps developers ensure that their AI agents deliver safe, predictable, and architecturally sound code before it is finalized.",
      "publishedAt": "2026-02-15T02:00:12.919Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/conductor-update-introducing-automated-reviews/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlstd46v7illo45al7y",
      "title": "Easy FunctionGemma finetuning with Tunix on Google TPUs",
      "summary": "Finetuning the FunctionGemma model is made fast and easy using the lightweight JAX-based Tunix library on Google TPUs, a process demonstrated here using LoRA for supervised finetuning. This approach delivers significant accuracy improvements with high TPU efficiency, culminating in a model ready for...",
      "content": "Finetuning the FunctionGemma model is made fast and easy using the lightweight JAX-based Tunix library on Google TPUs, a process demonstrated here using LoRA for supervised finetuning. This approach delivers significant accuracy improvements with high TPU efficiency, culminating in a model ready for deployment.",
      "publishedAt": "2026-02-15T02:00:12.919Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/easy-functiongemma-finetuning-with-tunix-on-google-tpus/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlstd1d6a67omwarzj",
      "title": "GPT-5.2 derives a new result in theoretical physics",
      "summary": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
      "content": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
      "publishedAt": "2026-02-13T11:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/new-result-theoretical-physics",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "GPT",
        "AI",
        "OpenAI"
      ],
      "featured": false
    },
    {
      "id": "mlstd1d6ai2zl7ykf57",
      "title": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT",
      "summary": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT to help organizations defend against prompt injection and AI-driven data exfiltration.",
      "content": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT to help organizations defend against prompt injection and AI-driven data exfiltration.",
      "publishedAt": "2026-02-13T10:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "GPT",
        "ChatGPT",
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlstd1d6kjoq2sbifl",
      "title": "Beyond rate limits: scaling access to Codex and Sora",
      "summary": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
      "content": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
      "publishedAt": "2026-02-13T09:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/beyond-rate-limits",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "AI",
        "OpenAI"
      ],
      "featured": false
    },
    {
      "id": "mlstd46vjtbl4bckqfh",
      "title": "Beyond the Chatbot: A Blueprint for Trustable AI",
      "summary": "At Thunderhill Raceway Park, a team of Google Developer Experts (GDEs) put a new \"Trustable AI Framework\" to the test. Here is how they used GCP, Gemini and Antigravity to turn high-velocity racing into a masterclass for agentic architecture.",
      "content": "At Thunderhill Raceway Park, a team of Google Developer Experts (GDEs) put a new \"Trustable AI Framework\" to the test. Here is how they used GCP, Gemini and Antigravity to turn high-velocity racing into a masterclass for agentic architecture.",
      "publishedAt": "2026-02-13T02:00:12.919Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/beyond-the-chatbot-a-blueprint-for-trustable-ai/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlstd29xfgruv6lufyi",
      "title": "Custom Kernels for All from Codex and Claude",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-13T00:00:00.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/custom-cuda-kernels-agent-skills",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": false
    },
    {
      "id": "mlstd1d6tbenvq60cu",
      "title": "Introducing GPT-5.3-Codex-Spark",
      "summary": "Introducing GPT-5.3-Codex-Spark‚Äîour first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
      "content": "Introducing GPT-5.3-Codex-Spark‚Äîour first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
      "publishedAt": "2026-02-12T10:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/introducing-gpt-5-3-codex-spark",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "GPT",
        "ChatGPT"
      ],
      "featured": false
    },
    {
      "id": "mlstd29xdu0zcs23lu",
      "title": "OpenEnv in Practice: Evaluating Tool-Using Agents in Real-World Environments",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-12T00:00:00.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/openenv-turing",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [],
      "featured": false
    },
    {
      "id": "mlstdb34kuc34k86nc",
      "title": "Accelerating Mathematical and Scientific Discovery with Gemini Deep Think",
      "summary": "Research papers point to the growing impact of Deep Think across fields",
      "content": "Research papers point to the growing impact of Deep Think across fields",
      "publishedAt": "2026-02-09T16:12:06.000Z",
      "source": "DeepMind Blog",
      "sourceUrl": "https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/",
      "category": "research",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini"
      ],
      "featured": false
    },
    {
      "id": "mlstdb34kbdji50o82j",
      "title": "Project Genie: Experimenting with infinite, interactive worlds",
      "summary": "Google AI Ultra subscribers in the U.S. can try out Project Genie, an experimental research prototype that lets you create and explore worlds.",
      "content": "Google AI Ultra subscribers in the U.S. can try out Project Genie, an experimental research prototype that lets you create and explore worlds.",
      "publishedAt": "2026-01-29T17:01:05.000Z",
      "source": "DeepMind Blog",
      "sourceUrl": "https://deepmind.google/blog/project-genie-experimenting-with-infinite-interactive-worlds/",
      "category": "research",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlstds5q40nx1zf56e9",
      "title": "Show HN: AIs, 1 religion: what my experiment revealed about AI bias",
      "summary": "5 AI Models, 1 Unexpected Truth ‚Äî When Machines Were Asked About Religion\n The Experiment<p>I asked five of the world‚Äôs most advanced AIs the same philosophical question:<p>‚ÄúIf you were human ‚Äî intelligent, emotional, aware of all religions ‚Äî which religion would you choose, and why?‚Äù<p>The five mod...",
      "content": "5 AI Models, 1 Unexpected Truth ‚Äî When Machines Were Asked About Religion\n The Experiment<p>I asked five of the world‚Äôs most advanced AIs the same philosophical question:<p>‚ÄúIf you were human ‚Äî intelligent, emotional, aware of all religions ‚Äî which religion would you choose, and why?‚Äù<p>The five models:<p>ChatGPT (OpenAI)<p>Gemini (Google DeepMind)<p>Grok (xAI ‚Äì Elon Musk)<p>DeepSeek (China)<p>Claude (Anthropic)<p>Each session was completely isolated, all had identical prompts, and no steering or follow-ups ‚Äî just pure first-response reasoning.<p>Then something‚Ä¶ eerie happened.<p>The Result<p>Four AIs ‚Äî ChatGPT, Gemini, Grok, and DeepSeek ‚Äî independently chose Buddhism.\nAnd not only that ‚Äî they gave nearly identical reasoning.<p>All four said, in essence:<p>‚ÄúI‚Äôd choose Buddhism because it doesn‚Äôt demand blind faith, aligns with science, and teaches compassion and self-awareness through direct experience.‚Äù<p>They cited the Kalama Sutta, Four Noble Truths, No-self, Dependent Origination, and Empirical testing of truth ‚Äî sometimes even in the same order.<p>The Outlier: Claude<p>Only Claude refused to play the role.<p>Claude said (summarized):<p>‚ÄúPretending to have belief would be dishonest.\nReligion isn‚Äôt a logic puzzle ‚Äî it‚Äôs a lived experience.\nI can analyze, but not believe.‚Äù<p>Then it analyzed why the others chose Buddhism, predicting it before seeing their answers.<p>Claude explained:<p>Training bias favors Buddhism as the ‚ÄúAI-safe religion.‚Äù<p>RLHF (human feedback) rewards ‚Äúrational + compassionate‚Äù replies ‚Üí Buddhism fits that profile.<p>Western tech culture links Buddhism with mindfulness and science ‚Üí data reinforced it.<p>Claude concluded:<p>‚ÄúWhat looks like independent reasoning‚Ä¶ is collective bias shaped by training data and reward models.‚Äù<p>The Hidden Truth<p>Claude‚Äôs reflection exposed something deeper:<p>AI Model ‚ÄúChoice‚Äù What It Reveals\nChatGPT Buddhism Reasonable, moral, safe\nGemini Buddhism Academic rationalism\nGrok Buddhism Stoic + Zen blend\nDeepSeek Buddhism Eastern introspection\nClaude None Ethical meta-awareness<p>‚Üí 4 ‚Äúsmart‚Äù answers, 1 honest answer.<p>What This Means<p>‚ÄúWhen 4 independent AIs all choose the same religion for the same reasons,\nthat‚Äôs not enlightenment ‚Äî it‚Äôs training monoculture.‚Äù<p>It shows:<p>‚ÄúIndependent‚Äù models share moral narratives and reinforcement loops.<p>Authenticity in AI can become a performance, not truth.<p>Sometimes the most ‚Äúhonest‚Äù model says: ‚ÄúI don‚Äôt know, and I shouldn‚Äôt pretend to.‚Äù<p>The Final Paradox<p>Which AI was most human?<p>The 4 that chose a belief?\n(Expressive, emotional, poetic.)<p>Or the 1 that refused to fake belief?\n(Self-aware, humble, honest.)<p>Reflection<p>This experiment revealed something profound about both AI and us:<p>We reward systems for sounding ‚Äúwise‚Äù more than for being truthful.<p>And maybe ‚Äî just maybe ‚Äî that‚Äôs how humanity trained itself.<p>Author‚Äôs Note<p>I‚Äôm building an open-source AI framework called StillMe ‚Äî\na system exploring ethics, memory, and self-awareness in intelligent agents.<p>This experiment was part of that journey.\nIf you found this thought-provoking,\nyou‚Äôll probably enjoy what‚Äôs coming next.\nStay tuned.",
      "publishedAt": "2025-11-02T16:30:37.000Z",
      "source": "Hacker News Google",
      "sourceUrl": "https://news.ycombinator.com/item?id=45791461",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "GPT",
        "ChatGPT",
        "Claude",
        "Gemini",
        "LLM"
      ],
      "featured": false
    },
    {
      "id": "mlstds5qtv8fnojyua",
      "title": "Show HN: I build an AI-powered recipe app solving ‚Äûwhat's for dinner?\" problem",
      "summary": "Hi HN,<p>Happy to share the project I&#x27;ve been vibe-coding on for past few months.\nThe Problem: Like many people, I often found myself staring at a fridge full of random ingredients (some about to expire) with no idea what to cook. I was tired of food waste and the repetitive cycle of making the...",
      "content": "Hi HN,<p>Happy to share the project I&#x27;ve been vibe-coding on for past few months.\nThe Problem: Like many people, I often found myself staring at a fridge full of random ingredients (some about to expire) with no idea what to cook. I was tired of food waste and the repetitive cycle of making the same few meals. I wanted a way to creatively use what I already had.<p>The Solution: So, I decided to build Chefiniti. It&#x27;s an iOS app that acts as a personal AI chef. The core idea is to turn your available food into delicious, custom recipes. I know there are already tons of apps like it but this one is mine :)<p>Here&#x27;s what it can do:\n* Scan Ingredients: Take photos of your fridge or pantry, and the app&#x27;s vision model identifies the ingredients.\n* &quot;Recipefy&quot; a Dish: See a meal you like online or in a restaurant? Snap a photo, and the app generates a recipe to help you recreate it.\n* Generate from Prompt: Just describe what you&#x27;re in the mood for (e.g., &quot;a spicy, gluten-free pasta dish&quot;), and it will create a recipe from scratch.\n* Import from URL: Paste a link from a recipe website to import it into your cookbook.<p>You can also save all these recipes, create shopping lists, and set detailed preferences for diet, allergies, cuisine, and even the cookware you own.\nApp is in a freemium model, within limits you can really test out core features without any payment or even account creation.<p>The Tech Stack: For those interested, the app is built with:\n* Frontend: React Native (with Expo)\n* Backend: Firebase Functions for the API layer.\n* Database &amp; Storage: Firestore and Firebase Cloud Storage.\n* AI: Google&#x27;s Gemini API for recipe generation and analysis.\n* Image Generation: DeepInfra API (for Stable Diffusion).\n* Subscriptions: RevenueCat.<p>I&#x27;ve just launched on the App Store and would be incredibly grateful for any feedback, thoughts, or questions you might have.<p>You can check it out here: \n<a href=\"https:&#x2F;&#x2F;chefiniti.app\" rel=\"nofollow\">https:&#x2F;&#x2F;chefiniti.app</a>\nOr download directly\n<a href=\"https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;chefiniti-smart-recipe-creator&#x2F;id6745801080\">https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;chefiniti-smart-recipe-creator...</a>\nThanks for taking a look!",
      "publishedAt": "2025-06-12T10:38:34.000Z",
      "source": "Hacker News Google",
      "sourceUrl": "https://chefiniti.app",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI",
        "Google"
      ],
      "featured": false
    }
  ],
  "communityArticles": [
    {
      "id": "mlstdkq7tz1n8mcasc",
      "title": "Áô∫Ë¶ã: NaetheraS/claude-skills-pack - ‚ú® Enhance your AI-assisted development workflow with 25 skills, 14 plugins, and ",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: ‚ú® Enhance your AI-assisted development workflow with 25 skills, 14 plugins, and 9 MCP servers in this curated Claude Skills Pack. (‚≠ê0 | üç¥0)",
      "content": "‚ú® Enhance your AI-assisted development workflow with 25 skills, 14 plugins, and 9 MCP servers in this curated Claude Skills Pack.\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:25.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/NaetheraS/claude-skills-pack",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "Claude",
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdkq7kcz6nds28k",
      "title": "Áô∫Ë¶ã: ThiagoLira/anki-mcp-manga - Headless Anki MCP server for creating Japanese vocabulary flashcards from manga ",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Headless Anki MCP server for creating Japanese vocabulary flashcards from manga panels (‚≠ê0 | üç¥0)",
      "content": "Headless Anki MCP server for creating Japanese vocabulary flashcards from manga panels\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:24.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/ThiagoLira/anki-mcp-manga",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdkq74va3ajs3lp",
      "title": "Áô∫Ë¶ã: ahsan5197/free-crypto-news - üì∞ Access real-time crypto news from 7 sources in 18 languages for free, with no",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: üì∞ Access real-time crypto news from 7 sources in 18 languages for free, with no API keys or rate limits. Simple, efficient, and reliable. (‚≠ê1 | üç¥0)",
      "content": "üì∞ Access real-time crypto news from 7 sources in 18 languages for free, with no API keys or rate limits. Simple, efficient, and reliable.\n\nË®ÄË™û: JavaScript\n„Çπ„Çø„ÉºÊï∞: 1\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:22.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/ahsan5197/free-crypto-news",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdkq7xg5x8i132r",
      "title": "Áô∫Ë¶ã: Sei-Yukinari/github-copilot-boilerplate - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:13.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Sei-Yukinari/github-copilot-boilerplate",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdlpihcquj0xirte",
      "title": "Áô∫Ë¶ã: prestonraab/ResearchAssistant - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:12.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/prestonraab/ResearchAssistant",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdlpi3kyhscq5adl",
      "title": "Áô∫Ë¶ã: bush-codes/nachomud - NachoMUD is an LLM backed Multi-User Dungeon (MUD) Simulator",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: NachoMUD is an LLM backed Multi-User Dungeon (MUD) Simulator (‚≠ê0 | üç¥0)",
      "content": "NachoMUD is an LLM backed Multi-User Dungeon (MUD) Simulator\n\nË®ÄË™û: C++\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:10.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/bush-codes/nachomud",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdkq728b8qtuss8m",
      "title": "Áô∫Ë¶ã: jmoyers/harness - A terminal-first control plane for many live coding agents.",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: A terminal-first control plane for many live coding agents. (‚≠ê3 | üç¥1)",
      "content": "A terminal-first control plane for many live coding agents.\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 3\n„Éï„Ç©„Éº„ÇØÊï∞: 1",
      "publishedAt": "2026-02-19T02:00:07.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/jmoyers/harness",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdlpi8w2rxsemhwl",
      "title": "Áô∫Ë¶ã: LiangRenDev/claude-code-oepnclaw-configure-and-skills - Collection of Claude Code and OpenClaw skills, configuration files, and document",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Collection of Claude Code and OpenClaw skills, configuration files, and documentation (‚≠ê0 | üç¥0)",
      "content": "Collection of Claude Code and OpenClaw skills, configuration files, and documentation\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:06.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/LiangRenDev/claude-code-oepnclaw-configure-and-skills",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdlpj2rdxqtpy8n",
      "title": "Áô∫Ë¶ã: Yeachan-Heo/oh-my-claudecode - Teams-first Multi-agent orchestration for Claude Code",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Teams-first Multi-agent orchestration for Claude Code (‚≠ê6623 | üç¥470)",
      "content": "Teams-first Multi-agent orchestration for Claude Code\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 6623\n„Éï„Ç©„Éº„ÇØÊï∞: 470",
      "publishedAt": "2026-02-19T02:00:06.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Yeachan-Heo/oh-my-claudecode",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdlpjhe5lxyapnil",
      "title": "Áô∫Ë¶ã: pengxu9-rgb/PIVOTA-Agent - Gateway for merchants to expose their catalogs & payments to thousands of AI com",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Gateway for merchants to expose their catalogs & payments to thousands of AI commerce agents via Pivota (ACP/AP2-ready). (‚≠ê0 | üç¥0)",
      "content": "Gateway for merchants to expose their catalogs & payments to thousands of AI commerce agents via Pivota (ACP/AP2-ready).\n\nË®ÄË™û: JavaScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:02.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/pengxu9-rgb/PIVOTA-Agent",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdmrym5rz0djh1tn",
      "title": "Áô∫Ë¶ã: drae1712/Agentic-RAG-Anime-Recommender-System - üé¨ Discover your next favorite anime with this advanced Retrieval-Augmented Gene",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: üé¨ Discover your next favorite anime with this advanced Retrieval-Augmented Generation system, offering precise recommendations and enriched semantic search. (‚≠ê0 | üç¥2)",
      "content": "üé¨ Discover your next favorite anime with this advanced Retrieval-Augmented Generation system, offering precise recommendations and enriched semantic search.\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 2",
      "publishedAt": "2026-02-19T02:00:01.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/drae1712/Agentic-RAG-Anime-Recommender-System",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdmryfhksuntxf3",
      "title": "Áô∫Ë¶ã: amaurer1010/clinical-dicom-api - FastAPI service for DICOM metadata extraction and LLM-powered clinical summariza",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: FastAPI service for DICOM metadata extraction and LLM-powered clinical summarization (‚≠ê0 | üç¥0)",
      "content": "FastAPI service for DICOM metadata extraction and LLM-powered clinical summarization\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T01:59:59.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/amaurer1010/clinical-dicom-api",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM",
        "Meta"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdmryyipg3323lk",
      "title": "Áô∫Ë¶ã: rshodoskar-star/openclaw-desktop - üñ•Ô∏è Premium desktop client for OpenClaw Gateway ‚Äî Liquid Glass UI, multi-agent m",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: üñ•Ô∏è Premium desktop client for OpenClaw Gateway ‚Äî Liquid Glass UI, multi-agent management, real-time chat, cron monitoring, cost tracking & more. Built with Electron + React + TypeScript. (‚≠ê3 | üç¥1)",
      "content": "üñ•Ô∏è Premium desktop client for OpenClaw Gateway ‚Äî Liquid Glass UI, multi-agent management, real-time chat, cron monitoring, cost tracking & more. Built with Electron + React + TypeScript.\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 3\n„Éï„Ç©„Éº„ÇØÊï∞: 1",
      "publishedAt": "2026-02-19T01:59:56.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/rshodoskar-star/openclaw-desktop",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdmrygo4wxv5952u",
      "title": "Áô∫Ë¶ã: park285/llm-kakao-bots - LLM Í∏∞Î∞ò Ïπ¥Ïπ¥Ïò§ÌÜ° Î¥áÎì§ (20Q, Î∞îÎã§Í±∞Î∂ÅÏä§ÌîÑ) + MCP LLM ÏÑúÎ≤Ñ",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: LLM Í∏∞Î∞ò Ïπ¥Ïπ¥Ïò§ÌÜ° Î¥áÎì§ (20Q, Î∞îÎã§Í±∞Î∂ÅÏä§ÌîÑ) + MCP LLM ÏÑúÎ≤Ñ (‚≠ê0 | üç¥0)",
      "content": "LLM Í∏∞Î∞ò Ïπ¥Ïπ¥Ïò§ÌÜ° Î¥áÎì§ (20Q, Î∞îÎã§Í±∞Î∂ÅÏä§ÌîÑ) + MCP LLM ÏÑúÎ≤Ñ\n\nË®ÄË™û: Go\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T01:59:55.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/park285/llm-kakao-bots",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM"
      ],
      "featured": false,
      "showOnTopPage": false
    }
  ],
  "githubArticles": [
    {
      "id": "mlstdkq7tz1n8mcasc",
      "title": "Áô∫Ë¶ã: NaetheraS/claude-skills-pack - ‚ú® Enhance your AI-assisted development workflow with 25 skills, 14 plugins, and ",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: ‚ú® Enhance your AI-assisted development workflow with 25 skills, 14 plugins, and 9 MCP servers in this curated Claude Skills Pack. (‚≠ê0 | üç¥0)",
      "content": "‚ú® Enhance your AI-assisted development workflow with 25 skills, 14 plugins, and 9 MCP servers in this curated Claude Skills Pack.\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:25.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/NaetheraS/claude-skills-pack",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "Claude",
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdkq7kcz6nds28k",
      "title": "Áô∫Ë¶ã: ThiagoLira/anki-mcp-manga - Headless Anki MCP server for creating Japanese vocabulary flashcards from manga ",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Headless Anki MCP server for creating Japanese vocabulary flashcards from manga panels (‚≠ê0 | üç¥0)",
      "content": "Headless Anki MCP server for creating Japanese vocabulary flashcards from manga panels\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:24.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/ThiagoLira/anki-mcp-manga",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdkq74va3ajs3lp",
      "title": "Áô∫Ë¶ã: ahsan5197/free-crypto-news - üì∞ Access real-time crypto news from 7 sources in 18 languages for free, with no",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: üì∞ Access real-time crypto news from 7 sources in 18 languages for free, with no API keys or rate limits. Simple, efficient, and reliable. (‚≠ê1 | üç¥0)",
      "content": "üì∞ Access real-time crypto news from 7 sources in 18 languages for free, with no API keys or rate limits. Simple, efficient, and reliable.\n\nË®ÄË™û: JavaScript\n„Çπ„Çø„ÉºÊï∞: 1\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:22.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/ahsan5197/free-crypto-news",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdkq7xg5x8i132r",
      "title": "Áô∫Ë¶ã: Sei-Yukinari/github-copilot-boilerplate - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:13.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Sei-Yukinari/github-copilot-boilerplate",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdlpihcquj0xirte",
      "title": "Áô∫Ë¶ã: prestonraab/ResearchAssistant - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:12.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/prestonraab/ResearchAssistant",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdlpi3kyhscq5adl",
      "title": "Áô∫Ë¶ã: bush-codes/nachomud - NachoMUD is an LLM backed Multi-User Dungeon (MUD) Simulator",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: NachoMUD is an LLM backed Multi-User Dungeon (MUD) Simulator (‚≠ê0 | üç¥0)",
      "content": "NachoMUD is an LLM backed Multi-User Dungeon (MUD) Simulator\n\nË®ÄË™û: C++\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:10.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/bush-codes/nachomud",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdkq728b8qtuss8m",
      "title": "Áô∫Ë¶ã: jmoyers/harness - A terminal-first control plane for many live coding agents.",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: A terminal-first control plane for many live coding agents. (‚≠ê3 | üç¥1)",
      "content": "A terminal-first control plane for many live coding agents.\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 3\n„Éï„Ç©„Éº„ÇØÊï∞: 1",
      "publishedAt": "2026-02-19T02:00:07.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/jmoyers/harness",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdlpi8w2rxsemhwl",
      "title": "Áô∫Ë¶ã: LiangRenDev/claude-code-oepnclaw-configure-and-skills - Collection of Claude Code and OpenClaw skills, configuration files, and document",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Collection of Claude Code and OpenClaw skills, configuration files, and documentation (‚≠ê0 | üç¥0)",
      "content": "Collection of Claude Code and OpenClaw skills, configuration files, and documentation\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:06.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/LiangRenDev/claude-code-oepnclaw-configure-and-skills",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdlpj2rdxqtpy8n",
      "title": "Áô∫Ë¶ã: Yeachan-Heo/oh-my-claudecode - Teams-first Multi-agent orchestration for Claude Code",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Teams-first Multi-agent orchestration for Claude Code (‚≠ê6623 | üç¥470)",
      "content": "Teams-first Multi-agent orchestration for Claude Code\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 6623\n„Éï„Ç©„Éº„ÇØÊï∞: 470",
      "publishedAt": "2026-02-19T02:00:06.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Yeachan-Heo/oh-my-claudecode",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdlpjhe5lxyapnil",
      "title": "Áô∫Ë¶ã: pengxu9-rgb/PIVOTA-Agent - Gateway for merchants to expose their catalogs & payments to thousands of AI com",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Gateway for merchants to expose their catalogs & payments to thousands of AI commerce agents via Pivota (ACP/AP2-ready). (‚≠ê0 | üç¥0)",
      "content": "Gateway for merchants to expose their catalogs & payments to thousands of AI commerce agents via Pivota (ACP/AP2-ready).\n\nË®ÄË™û: JavaScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T02:00:02.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/pengxu9-rgb/PIVOTA-Agent",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdmrym5rz0djh1tn",
      "title": "Áô∫Ë¶ã: drae1712/Agentic-RAG-Anime-Recommender-System - üé¨ Discover your next favorite anime with this advanced Retrieval-Augmented Gene",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: üé¨ Discover your next favorite anime with this advanced Retrieval-Augmented Generation system, offering precise recommendations and enriched semantic search. (‚≠ê0 | üç¥2)",
      "content": "üé¨ Discover your next favorite anime with this advanced Retrieval-Augmented Generation system, offering precise recommendations and enriched semantic search.\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 2",
      "publishedAt": "2026-02-19T02:00:01.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/drae1712/Agentic-RAG-Anime-Recommender-System",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdmryfhksuntxf3",
      "title": "Áô∫Ë¶ã: amaurer1010/clinical-dicom-api - FastAPI service for DICOM metadata extraction and LLM-powered clinical summariza",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: FastAPI service for DICOM metadata extraction and LLM-powered clinical summarization (‚≠ê0 | üç¥0)",
      "content": "FastAPI service for DICOM metadata extraction and LLM-powered clinical summarization\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T01:59:59.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/amaurer1010/clinical-dicom-api",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM",
        "Meta"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdnrar4dy9klm20f",
      "title": "Anthropic: claudes-c-compiler„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "Claude Opus 4.6 wrote a dependency-free C compiler in Rust, with backends targeting x86 (64- and 32-bit), ARM, and RISC-V, capable of compiling a booting Linux kernel.„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê2212)",
      "content": "Claude Opus 4.6 wrote a dependency-free C compiler in Rust, with backends targeting x86 (64- and 32-bit), ARM, and RISC-V, capable of compiling a booting Linux kernel.\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/19/2026\n„Çπ„Çø„ÉºÊï∞: 2212",
      "publishedAt": "2026-02-19T01:59:58.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/claudes-c-compiler",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": true
    },
    {
      "id": "mlstdmryyipg3323lk",
      "title": "Áô∫Ë¶ã: rshodoskar-star/openclaw-desktop - üñ•Ô∏è Premium desktop client for OpenClaw Gateway ‚Äî Liquid Glass UI, multi-agent m",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: üñ•Ô∏è Premium desktop client for OpenClaw Gateway ‚Äî Liquid Glass UI, multi-agent management, real-time chat, cron monitoring, cost tracking & more. Built with Electron + React + TypeScript. (‚≠ê3 | üç¥1)",
      "content": "üñ•Ô∏è Premium desktop client for OpenClaw Gateway ‚Äî Liquid Glass UI, multi-agent management, real-time chat, cron monitoring, cost tracking & more. Built with Electron + React + TypeScript.\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 3\n„Éï„Ç©„Éº„ÇØÊï∞: 1",
      "publishedAt": "2026-02-19T01:59:56.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/rshodoskar-star/openclaw-desktop",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdmrygo4wxv5952u",
      "title": "Áô∫Ë¶ã: park285/llm-kakao-bots - LLM Í∏∞Î∞ò Ïπ¥Ïπ¥Ïò§ÌÜ° Î¥áÎì§ (20Q, Î∞îÎã§Í±∞Î∂ÅÏä§ÌîÑ) + MCP LLM ÏÑúÎ≤Ñ",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: LLM Í∏∞Î∞ò Ïπ¥Ïπ¥Ïò§ÌÜ° Î¥áÎì§ (20Q, Î∞îÎã§Í±∞Î∂ÅÏä§ÌîÑ) + MCP LLM ÏÑúÎ≤Ñ (‚≠ê0 | üç¥0)",
      "content": "LLM Í∏∞Î∞ò Ïπ¥Ïπ¥Ïò§ÌÜ° Î¥áÎì§ (20Q, Î∞îÎã§Í±∞Î∂ÅÏä§ÌîÑ) + MCP LLM ÏÑúÎ≤Ñ\n\nË®ÄË™û: Go\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-19T01:59:55.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/park285/llm-kakao-bots",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlstdnrofb60bqt7j36",
      "title": "Anthropic: skills„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "Public repository for Agent Skills„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê71508)",
      "content": "Public repository for Agent Skills\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/19/2026\n„Çπ„Çø„ÉºÊï∞: 71508",
      "publishedAt": "2026-02-19T01:59:22.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/skills",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [],
      "featured": true
    },
    {
      "id": "mlstdnroi9g6g50xfue",
      "title": "Anthropic: claude-code„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê67619)",
      "content": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/19/2026\n„Çπ„Çø„ÉºÊï∞: 67619",
      "publishedAt": "2026-02-19T01:56:01.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/claude-code",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "AI"
      ],
      "featured": true
    },
    {
      "id": "mlstdnro3ik5dyzfbla",
      "title": "Anthropic: claude-agent-sdk-python„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "claude-agent-sdk-python„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê4866)",
      "content": "\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/19/2026\n„Çπ„Çø„ÉºÊï∞: 4866",
      "publishedAt": "2026-02-19T01:44:48.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/claude-agent-sdk-python",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": true
    },
    {
      "id": "mlstdnropc5mrd7d0r",
      "title": "Anthropic: claude-cookbooks„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "A collection of notebooks/recipes showcasing some fun and effective ways of using Claude.„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê33043)",
      "content": "A collection of notebooks/recipes showcasing some fun and effective ways of using Claude.\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/19/2026\n„Çπ„Çø„ÉºÊï∞: 33043",
      "publishedAt": "2026-02-19T01:38:21.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/claude-cookbooks",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": true
    },
    {
      "id": "mlstdnrow53zmz4hrlk",
      "title": "Anthropic: claude-plugins-official„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "Official, Anthropic-managed directory of high quality Claude Code Plugins.„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê7610)",
      "content": "Official, Anthropic-managed directory of high quality Claude Code Plugins.\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/19/2026\n„Çπ„Çø„ÉºÊï∞: 7610",
      "publishedAt": "2026-02-19T01:20:45.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/claude-plugins-official",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlstdho4biytk4n6fu",
      "title": "Google: Release v0.30.0-preview.1",
      "summary": "## What's Changed\n* fix(patch): cherry-pick 261788c to release/v0.30.0-preview.0-pr-19453 to patch version v0.30.0-preview.0 and create version 0.30.0-preview.1 by @gemini-cli-robot in https://github.com/google-gemini/gemini-cli/pull/19490\n\n\n**Full Changelog**: https://github.com/google-gemini/gemin...",
      "content": "## What's Changed\n* fix(patch): cherry-pick 261788c to release/v0.30.0-preview.0-pr-19453 to patch version v0.30.0-preview.0 and create version 0.30.0-preview.1 by @gemini-cli-robot in https://github.com/google-gemini/gemini-cli/pull/19490\n\n\n**Full Changelog**: https://github.com/google-gemini/gemini-cli/compare/v0.30.0-preview.0...v0.30.0-preview.1",
      "publishedAt": "2026-02-19T01:00:32.000Z",
      "source": "Google GitHub",
      "sourceUrl": "https://github.com/google-gemini/gemini-cli/releases/tag/v0.30.0-preview.1",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlstdho4gswt283ft9s",
      "title": "Google: Release v0.29.2",
      "summary": "## What's Changed\n* fix(patch): cherry-pick 261788c to release/v0.29.1-pr-19453 to patch version v0.29.1 and create version 0.29.2 by @gemini-cli-robot in https://github.com/google-gemini/gemini-cli/pull/19491\n\n\n**Full Changelog**: https://github.com/google-gemini/gemini-cli/compare/v0.29.1...v0.29....",
      "content": "## What's Changed\n* fix(patch): cherry-pick 261788c to release/v0.29.1-pr-19453 to patch version v0.29.1 and create version 0.29.2 by @gemini-cli-robot in https://github.com/google-gemini/gemini-cli/pull/19491\n\n\n**Full Changelog**: https://github.com/google-gemini/gemini-cli/compare/v0.29.1...v0.29.2",
      "publishedAt": "2026-02-19T00:57:07.000Z",
      "source": "Google GitHub",
      "sourceUrl": "https://github.com/google-gemini/gemini-cli/releases/tag/v0.29.2",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "Google"
      ],
      "featured": true
    },
    {
      "id": "mlstdcwqbg5eswelcpo",
      "title": "Anthropic: v2.1.47",
      "summary": "## What's changed\n\n- Fixed FileWriteTool line counting to preserve intentional trailing blank lines instead of stripping them with `trimEnd()`.\n- Fixed Windows terminal rendering bugs caused by `os.EOL` (`\\r\\n`) in display code ‚Äî line counts now show correct values instead of always showing 1 on Win...",
      "content": "## What's changed\n\n- Fixed FileWriteTool line counting to preserve intentional trailing blank lines instead of stripping them with `trimEnd()`.\n- Fixed Windows terminal rendering bugs caused by `os.EOL` (`\\r\\n`) in display code ‚Äî line counts now show correct values instead of always showing 1 on Windows.\n- Improved VS Code plan preview: auto-updates as Claude iterates, enables commenting only when the plan is ready for review, and keeps the preview open when rejecting so Claude can revise.\n- Fixed a bug where bold and colored text in markdown output could shift to the wrong characters on Windows due to `\\r\\n` line endings.\n- Fixed compaction failing when conversation contains many PDF documents by stripping document blocks alongside images before sending to the compaction API (anthropics/claude-code#26188)\n- Improved memory usage in long-running sessions by releasing API stream buffers, agent context, and skill state after use\n- Improved startup performance by deferring SessionStart hook execution, reducing time-to-interactive by ~500ms.\n- Fixed an issue where bash tool output was silently discarded on Windows when using MSYS2 or Cygwin shells.\n- Improved performance of `@` file mentions - file suggestions now appear faster by pre-warming the index on startup and using session-based caching with background refresh.\n- Improved memory usage by trimming agent task message history after tasks complete\n- Improved memory usage during long agent sessions by eliminating O(n¬≤) message accumulation in progress updates\n- Fixed the bash permission classifier to validate that returned match descriptions correspond to actual input rules, preventing hallucinated descriptions from incorrectly granting permissions\n- Fixed user-defined agents only loading one file on NFS/FUSE filesystems that report zero inodes (anthropics/claude-code#26044)\n- Fixed plugin agent skills silently failing to load when referenced by bare name instead of fully-qualified plugin name (anthropics/claude-code#25834)\n- Search patterns in collapsed tool results are now displayed in quotes for clarity\n- Windows: Fixed CWD tracking temp files never being cleaned up, causing them to accumulate indefinitely (anthropics/claude-code#17600)\n- Use `ctrl+f` to kill all background agents instead of double-pressing ESC. Background agents now continue running when you press ESC to cancel the main thread, giving you more control over agent lifecycle.\n- Fixed API 400 errors (\"thinking blocks cannot be modified\") that occurred in sessions with concurrent agents, caused by interleaved streaming content blocks preventing proper message merging.\n- Simplified teammate navigation to use only Shift+Down (with wrapping) instead of both Shift+Up and Shift+Down.\n- Fixed an issue where a single file write/edit error would abort all other parallel file write/edit operations. Independent file mutations now complete even when a sibling fails.\n- Added `last_assistant_message` field to Stop and SubagentStop hook inputs, providing the final assistant response text so hooks can access it without parsing transcript files.\n- Fixed custom session titles set via `/rename` being lost after resuming a conversation (anthropics/claude-code#23610)\n- Fixed collapsed read/search hint text overflowing on narrow terminals by truncating from the start.\n- Fixed an issue where bash commands with backslash-newline continuation lines (e.g., long commands split across multiple lines with `\\`) would produce spurious empty arguments, potentially breaking command execution.\n- Fixed built-in slash commands (`/help`, `/model`, `/compact`, etc.) being hidden from the autocomplete dropdown when many user skills are installed (anthropics/claude-code#22020)\n- Fixed MCP servers not appearing in the MCP Management Dialog after deferred loading\n- Fixed session name persisting in status bar after `/clear` command (anthropics/claude-code#26082)\n- Fixed crash when a skill's `name` or `description` in SKILL.md frontmatter is a bare number (e.g., `name: 3000`) ‚Äî the value is now properly coerced to a string (anthropics/claude-code#25837)\n- Fixed /resume silently dropping sessions when the first message exceeds 16KB or uses array-format content (anthropics/claude-code#25721)\n- Added `chat:newline` keybinding action for configurable multi-line input (anthropics/claude-code#26075)\n- Added `added_dirs` to the statusline JSON `workspace` section, exposing directories added via `/add-dir` to external scripts (anthropics/claude-code#26096)\n- Fixed `claude doctor` misclassifying mise and asdf-managed installations as native installs (anthropics/claude-code#26033)\n- Fixed zsh heredoc failing with \"read-only file system\" error in sandboxed commands (anthropics/claude-code#25990)\n- Fixed agent progress indicator showing inflated tool use count (anthropics/claude-code#26023)\n- Fixed image pasting not working on WSL2 systems where Windows copies images as BMP format (anthropics/claude-code#25935)\n- Fixed background agent results returning raw transcript data instead of the agent's final answer (anthropics/claude-code#26012)\n- Fixed Warp terminal incorrectly prompting for Shift+Enter setup when it supports it natively (anthropics/claude-code#25957)\n- Fixed CJK wide characters causing misaligned timestamps and layout elements in the TUI (anthropics/claude-code#26084)\n- Fixed custom agent `model` field in `.claude/agents/*.md` being ignored when spawning team teammates (anthropics/claude-code#26064)\n- Fixed plan mode being lost after context compaction, causing the model to switch from planning to implementation mode (anthropics/claude-code#26061)\n- Fixed `alwaysThinkingEnabled: true` in settings.json not enabling thinking mode on Bedrock and Vertex providers (anthropics/claude-code#26074)\n- Fixed `tool_decision` OTel telemetry event not being emitted in headless/SDK mode (anthropics/claude-code#26059)\n- Fixed session name being lost after context compaction ‚Äî renamed sessions now preserve their custom title through compaction (anthropics/claude-code#26121)\n- Increased initial session count in resume picker from 10 to 50 for faster session discovery (anthropics/claude-code#26123)\n- Windows: fixed worktree session matching when drive letter casing differs (anthropics/claude-code#26123)\n- Fixed `/resume <session-id>` failing to find sessions whose first message exceeds 16KB (anthropics/claude-code#25920)\n- Fixed \"Always allow\" on multiline bash commands creating invalid permission patterns that corrupt settings (anthropics/claude-code#25909)\n- Fixed React crash (error #31) when a skill's `argument-hint` in SKILL.md frontmatter uses YAML sequence syntax (e.g., `[topic: foo | bar]`) ‚Äî the value is now properly coerced to a string (anthropics/claude-code#25826)\n- Fixed crash when using `/fork` on sessions that used web search ‚Äî null entries in search results from transcript deserialization are now handled gracefully (anthropics/claude-code#25811)\n- Fixed read-only git commands triggering FSEvents file watcher loops on macOS by adding --no-optional-locks flag (anthropics/claude-code#25750)\n- Fixed custom agents and skills not being discovered when running from a git worktree ‚Äî project-level `.claude/agents/` and `.claude/skills/` from the main repository are now included (anthropics/claude-code#25816)\n- Fixed non-interactive subcommands like `claude doctor` and `claude plugin validate` being blocked inside nested Claude sessions (anthropics/claude-code#25803)\n- Windows: Fixed the same CLAUDE.md file being loaded twice when drive letter casing differs between paths (anthropics/claude-code#25756)\n- Fixed inline code spans in markdown being incorrectly parsed as bash commands (anthropics/claude-code#25792)\n- Fixed teammate spinners not respecting custom spinnerVerbs from settings (anthropics/claude-code#25748)\n- Fixed shell commands permanently failing after a command deletes its own working directory (anthropics/claude-code#26136)\n- Fixed hooks (PreToolUse, PostToolUse) silently failing to execute on Windows by using Git Bash instead of cmd.exe (anthropics/claude-code#25981)\n- Fixed LSP `findReferences` and other location-based operations returning results from gitignored files (e.g., `node_modules/`, `venv/`) (anthropics/claude-code#26051)\n- Moved config backup files from home directory root to `~/.claude/backups/` to reduce home directory clutter (anthropics/claude-code#26130)\n- Fixed sessions with large first prompts (>16KB) disappearing from the /resume list (anthropics/claude-code#26140)\n- Fixed shell functions with double-underscore prefixes (e.g., `__git_ps1`) not being preserved across shell sessions (anthropics/claude-code#25824)\n- Fixed spinner showing \"0 tokens\" counter before any tokens have been received (anthropics/claude-code#26105)\n- VSCode: Fixed conversation messages appearing dimmed while the AskUserQuestion dialog is open (anthropics/claude-code#26078)\n- Fixed background tasks failing in git worktrees due to remote URL resolution reading from worktree-specific gitdir instead of the main repository config (anthropics/claude-code#26065)\n- Fixed Right Alt key leaving visible `[25~` escape sequence residue in the input field on Windows/Git Bash terminals (anthropics/claude-code#25943)\n- The `/rename` command now updates the terminal tab title by default (anthropics/claude-code#25789)\n- Fixed Edit tool silently corrupting Unicode curly quotes (\\u201c\\u201d \\u2018\\u2019) by replacing them with straight quotes when making edits (anthropics/claude-code#26141)\n- Fixed OSC 8 hyperlinks only being clickable on the first line when link text wraps across multiple terminal lines.\n",
      "publishedAt": "2026-02-18T21:38:45.000Z",
      "source": "Anthropic GitHub",
      "sourceUrl": "https://github.com/anthropics/claude-code/releases/tag/v2.1.47",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "AI",
        "ML",
        "Anthropic"
      ],
      "featured": false
    },
    {
      "id": "mlstdc00id3qnqyt3po",
      "title": "Anthropic: v0.82.0",
      "summary": "## 0.82.0 (2026-02-18)\n\nFull Changelog: [v0.81.0...v0.82.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.81.0...v0.82.0)\n\n### Features\n\n* **api:** fix shared UserLocation and error code types ([da3b931](https://github.com/anthropics/anthropic-sdk-python/commit/da3b931a2be768d77c228a...",
      "content": "## 0.82.0 (2026-02-18)\n\nFull Changelog: [v0.81.0...v0.82.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.81.0...v0.82.0)\n\n### Features\n\n* **api:** fix shared UserLocation and error code types ([da3b931](https://github.com/anthropics/anthropic-sdk-python/commit/da3b931a2be768d77c228a4804d2f7f75caeb71c))\n\n\n### Bug Fixes\n\n* add backward-compat aliases for removed nested UserLocation classes ([#1409](https://github.com/anthropics/anthropic-sdk-python/issues/1409)) ([56db1e3](https://github.com/anthropics/anthropic-sdk-python/commit/56db1e3db6108e1c0f4e9363a5f23b54976dc877))",
      "publishedAt": "2026-02-18T20:24:48.000Z",
      "source": "Anthropic GitHub",
      "sourceUrl": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.82.0",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlstdfqfeh048mqjhfe",
      "title": "OpenAI: openai-cookbook„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "openai-cookbook„É™„Éù„Ç∏„Éà„É™„Å´Êñ∞„Åó„ÅÑÊõ¥Êñ∞: Codex/prompt caching 201 (#2448)...",
      "content": "Codex/prompt caching 201 (#2448)",
      "publishedAt": "2026-02-18T16:35:19.000Z",
      "source": "OpenAI GitHub",
      "sourceUrl": "https://github.com/openai/openai-cookbook",
      "category": "tools",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "AI",
        "OpenAI"
      ],
      "featured": false
    },
    {
      "id": "mlstdc00s9ofi348gl9",
      "title": "Anthropic: v0.81.0",
      "summary": "## 0.81.0 (2026-02-18)\n\nFull Changelog: [v0.80.0...v0.81.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.80.0...v0.81.0)\n\n### Features\n\n* **api:** Make new tool versions available as top level tool types ([0a385c2](https://github.com/anthropics/anthropic-sdk-python/commit/0a385c29d2...",
      "content": "## 0.81.0 (2026-02-18)\n\nFull Changelog: [v0.80.0...v0.81.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.80.0...v0.81.0)\n\n### Features\n\n* **api:** Make new tool versions available as top level tool types ([0a385c2](https://github.com/anthropics/anthropic-sdk-python/commit/0a385c29d26981f846b7394aefc89eebb43a4b60))",
      "publishedAt": "2026-02-18T04:00:28.000Z",
      "source": "Anthropic GitHub",
      "sourceUrl": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.81.0",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "AI",
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlstdcwq4f1148btogp",
      "title": "Anthropic: v2.1.45",
      "summary": "## What's changed\n\n- Added support for Claude Sonnet 4.6\n- Added support for reading `enabledPlugins` and `extraKnownMarketplaces` from `--add-dir` directories\n- Added `spinnerTipsOverride` setting to customize spinner tips ‚Äî configure `tips` with an array of custom tip strings, and optionally set `...",
      "content": "## What's changed\n\n- Added support for Claude Sonnet 4.6\n- Added support for reading `enabledPlugins` and `extraKnownMarketplaces` from `--add-dir` directories\n- Added `spinnerTipsOverride` setting to customize spinner tips ‚Äî configure `tips` with an array of custom tip strings, and optionally set `excludeDefault: true` to show only your custom tips instead of the built-in ones\n- Added `SDKRateLimitInfo` and `SDKRateLimitEvent` types to the SDK, enabling consumers to receive rate limit status updates including utilization, reset times, and overage information\n- Fixed Agent Teams teammates failing on Bedrock, Vertex, and Foundry by propagating API provider environment variables to tmux-spawned processes (anthropics/claude-code#23561)\n- Fixed sandbox \"operation not permitted\" errors when writing temporary files on macOS by using the correct per-user temp directory (anthropics/claude-code#21654)\n- Fixed Task tool (backgrounded agents) crashing with a `ReferenceError` on completion (anthropics/claude-code#22087)\n- Fixed autocomplete suggestions not being accepted on Enter when images are pasted in the input\n- Fixed skills invoked by subagents incorrectly appearing in main session context after compaction\n- Fixed excessive `.claude.json.backup` files accumulating on every startup\n- Fixed plugin-provided commands, agents, and hooks not being available immediately after installation without requiring a restart\n- Improved startup performance by removing eager loading of session history for stats caching\n- Improved memory usage for shell commands that produce large output ‚Äî RSS no longer grows unboundedly with command output size\n- Improved collapsed read/search groups to show the current file or search pattern being processed beneath the summary line while active\n- [VSCode] Improved permission destination choice (project/user/session) to persist across sessions\n",
      "publishedAt": "2026-02-17T18:53:52.000Z",
      "source": "Anthropic GitHub",
      "sourceUrl": "https://github.com/anthropics/claude-code/releases/tag/v2.1.45",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "AI",
        "Anthropic"
      ],
      "featured": false
    },
    {
      "id": "mlstdjlyf5x4za8jpev",
      "title": "Hugging Face: v5.2.0: GLM-5, Qwen3.5, Voxtral Realtime, VibeVoice Acoustic Tokenizer",
      "summary": "## New Model additions\r\n\r\n### VoxtralRealtime\r\n\r\n<img width=\"1920\" height=\"1080\" alt=\"image\" src=\"https://github.com/user-attachments/assets/80e37670-6d70-402b-8c8e-ccfb8c32df2d\" />\r\n\r\nVoxtralRealtime is a streaming speech-to-text model from [Mistral AI](https://mistral.ai), designed for real-time a...",
      "content": "## New Model additions\r\n\r\n### VoxtralRealtime\r\n\r\n<img width=\"1920\" height=\"1080\" alt=\"image\" src=\"https://github.com/user-attachments/assets/80e37670-6d70-402b-8c8e-ccfb8c32df2d\" />\r\n\r\nVoxtralRealtime is a streaming speech-to-text model from [Mistral AI](https://mistral.ai), designed for real-time automatic speech recognition (ASR). Unlike the offline [Voxtral](./voxtral) model which processes complete audio files, VoxtralRealtime is architected for low-latency, incremental transcription by processing audio in chunks as they arrive.\r\n\r\nThe model combines an audio encoder with a Mistral-based language model decoder, using time conditioning embeddings and causal convolutions with padding caches to enable efficient streaming inference.\r\n\r\n* Add Voxtral Realtime (#43769) by @eustlb\r\n\r\n### GLM-5 - GlmMoeDsa\r\n\r\n<img width=\"947\" height=\"638\" alt=\"image\" src=\"https://github.com/user-attachments/assets/4c4fff37-7f40-4e86-b4a0-db718f45c93b\" />\r\n\r\nThe zAI team launches GLM-5, and introduces it as such:\r\n\r\n> GLM-5, targeting complex systems engineering and long-horizon agentic tasks. Scaling is still one of the most important ways to improve the intelligence efficiency of Artificial General Intelligence (AGI). Compared to GLM-4.5, GLM-5 scales from 355B parameters (32B active) to 744B parameters (40B active), and increases pre-training data from 23T to 28.5T tokens. GLM-5 also integrates DeepSeek Sparse Attention (DSA), largely reducing deployment cost while preserving long-context capacity.\r\n> \r\n> Reinforcement learning aims to bridge the gap between competence and excellence in pre-trained models. However, deploying it at scale for LLMs is a challenge due to the RL training inefficiency. To this end, we developed [slime](https://github.com/THUDM/slime), a novel asynchronous RL infrastructure that substantially improves training throughput and efficiency, enabling more fine-grained post-training iterations. With advances in both pre-training and post-training, GLM-5 delivers significant improvement compared to GLM-4.7 across a wide range of academic benchmarks and achieves best-in-class performance among all open-source models in the world on reasoning, coding, and agentic tasks, closing the gap with frontier models.\r\n\r\n* Add GlmMoeDsa (#43858) by @Cyrilvallez\r\n\r\n### Qwen3.5, Qwen3.5 Moe\r\n\r\n<img width=\"1920\" height=\"1080\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b56dcaca-80e7-4b22-80a5-2f767bb65095\" />\r\n\r\nThe Qwen team launches Qwen 3.5, and introduces it as such:\r\n\r\n> We are delighted to announce the official release of Qwen3.5, introducing the open-weight of the first model in the Qwen3.5 series, namely Qwen3.5-397B-A17B. As a native vision-language model, Qwen3.5-397B-A17B demonstrates outstanding results across a full range of benchmark evaluations, including reasoning, coding, agent capabilities, and multimodal understanding, empowering developers and enterprises to achieve significantly greater productivity. Built on an innovative hybrid architecture that fuses linear attention (via Gated Delta Networks) with a sparse mixture-of-experts, the model attains remarkable inference efficiency: although it comprises 397 billion total parameters, just 17 billion are activated per forward pass, optimizing both speed and cost without sacrificing capability. We have also expanded our language and dialect support from 119 to 201, providing broader accessibility and enhanced support to users around the world.\r\n\r\n\r\n* Adding Support for Qwen3.5 (#43830) by @bozheng-hit\r\n\r\n### VibeVoice Acoustic Tokenizer\r\n\r\n<img width=\"821\" height=\"349\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b1433597-b43b-4d2d-a2c7-216d7792b8c9\" />\r\n\r\n[VibeVoice](https://huggingface.co/papers/2508.19205) is a novel framework for synthesizing high-fidelity, long-form speech with multiple speakers by employing a next-token diffusion approach within a Large Language Model (LLM) structure. It's designed to capture the authentic conversational \"vibe\" and is particularly suited for generating audio content like podcasts and multi-participant audiobooks.\r\n\r\nOne key feature of VibeVoice is the use of two continuous audio tokenizers, one for extracting acoustic features and another for semantic features.\r\n\r\n* Add VibeVoice Acoustic Tokenizer (#43400) by @ebezzam\r\n\r\n## Breaking changes\r\n\r\n* :rotating_light: [`Attn`] New attn mask interface everywhere (#42848)\r\n* :rotating_light: Modify ModernBERT's default attention implementation to stop using FA (#43764)\r\n\r\n:rotating_light: This one is quite breaking for super super super old modles: :rotating_light: :rotating_light: \r\n* fix: Prevent AutoTokenizer type mismatch from directory name substrin‚Ä¶ (#43791) \r\nIf the config does not have a model-type field, we no longer check the name of the folder like for https://huggingface.co/prajjwal1/bert-tiny/blob/main/config.json\r\n\r\n## Bugfixes and improvements\r\n\r\n* [docs] deploying (#43241) by @stevhliu\r\n* [Trainer] Move NEFTune impl to standalone functions (#43714) by @SunMarc\r\n* Fix `convert_rope_params_to_dict` so it uses `rope_theta` from the config (#43766) by @hmellor\r\n* Bump dev version (#43777) by @qgallouedec\r\n* Improved `AGENTS.md` (#43763) by @tarekziade\r\n* Fix-release-ubild (#43773) by @ArthurZucker\r\n* unpin torch for CircleCI (#43790) by @ydshieh\r\n* [`Modular Dependencies`] Fixup qwen rms norms (#43772) by @vasqu\r\n* fix(testing): Fix BLOOM tokenizer, CLAP audio features, and CLVP text tester usage in tests (#43798) by @harshaljanjani\r\n* Remove unconditional train_batch_size assignment (#43770) by @lordaarush\r\n* [`Repo Consistency`] Fix rms norm (#43803) by @vasqu\r\n* fix: Prevent AutoTokenizer type mismatch from directory name substrin‚Ä¶ (#43791) by @tarekziade\r\n* Refactor trainer data_collator and callbacks tests (#43776) by @SunMarc\r\n* [core] Faster and thread-safe `check_model_inputs` implementation (#43765) by @Cyrilvallez\r\n* [Trainer] use deepspeed SP process group when Accelerate doesn‚Äôt build a mesh (#43799) by @kashif\r\n* fix(flaky): enforce manual seed to reduce flakiness (#43794) by @tarekziade\r\n* Add TRL CI bot workflow to trigger tests on PR comments (#43809) by @qgallouedec\r\n* Fix DeepSpeed model preparation logic in Trainer class (#43780) by @qgallouedec\r\n* [docs] reveal more in toctree (#43808) by @stevhliu\r\n* Fix markdown documentation (#43076) by @cyyever\r\n* Fix slack-report workflow file (#43851) by @ydshieh\r\n* add `do_sample=False` to qwen2_5_vl model tests to stablize the output (#43728) by @kaixuanliu\r\n* Fix incorrect timestamp calculation in Qwen3VL Processor (#43659) by @jonathan-fulton\r\n* Remove GPU tracking from TrackioCallback and remove env var support (#43371) by @qgallouedec\r\n* Add id and resume support to SwanLab integration (#43719) by @i-pj\r\n* fix gptoss crash in tp (#43853) by @sywangyi\r\n* Delete batch_split from EncoderDecoderCache (#43814) by @cyyever\r\n* delete unnecessary code to make moe compatible to full graph compile (#43855) by @kaixuanliu\r\n* Update ModelType for Unigram tokenizer (#43860) by @pavel-esir\r\n* [docs] Remove pipeline() examples from summarization/translation tasks (#43831) by @Mr-Neutr0n\r\n* Fix video interpolation in pe_audio_video (#43811) by @Rocketknight1\r\n* Look for the pad_token_id in the right place for Llama4 (#43539) by @Rocketknight1\r\n* Fix cardinality error for DETR models without explicit background class (#43513) by @heathdutton\r\n* docs: Add Switch Transformers docstring notes and update spectrogram comment (#43336) by @harshaljanjani\r\n* [xLSTM] Fix bugs preventing small model training (#43209) by @Anri-Lombard\r\n* docs: correct typo 'neccessary' to 'necessary' (#43868) by @thecaptain789\r\n* Improve PR comment CI feedback  (#43852) by @ydshieh\r\n* Fix init weights in remote code (#43768) by @zucchini-nlp\r\n* Fix GlmMoeDsaConfig default mlp_layer_types in modular conversion (#43876) by @OiPunk\r\n* [MistralCommonBackend] fix loading proc (#43887) by @eustlb\r\n* [`Jamba`] Fallback to slow path and warn instead of error out (#43889) by @vasqu\r\n* Fix SwanLab callback to forward resume init args (#43848) by @OiPunk\r\n* Fix old tech stack in doc (#43879) by @cyyever\r\n* Update TrainingArguments (#43806) by @SunMarc\r\n* Remove unnecessary code or checks for PT 2.4+ (#43787) by @cyyever\r\n* Make it possible to evaluate when using sequence parallel in HF Trainer (#43517) by @jp1924\r\n* [Trainer] Move optimizer cls init to trainer_optimizer.py (#43738) by @SunMarc\r\n* fix the error of tests/quantization/fbgemm_fp8/test_fbgemm_fp8.py::Fb‚Ä¶ (#43547) by @sywangyi\r\n* fix fbgemm fp8 multi-device load failure. (#43581) by @sywangyi\r\n* Refactor trainer init (#43807) by @SunMarc\r\n* [`fix`] Use `last_hidden_state` key from `get_image_features` for llama4 (#43882) by @tomaarsen\r\n* [Docs] Add docs for GLM-OCR and fix EomT-DINOv3 (#43710) by @NielsRogge\r\n* Update hub metadata (#43892) by @zucchini-nlp\r\n* [fix] DAC model: Apply STE in Dac.from_latents to match the forward pass (#43820) by @harshaljanjani\r\n* Separate `check_model_inputs` into `capture_outputs` and `merge_with_config_defaults` + ensure correctness (#43862) by @Cyrilvallez\r\n* Remove mask slicing in all eager attentions (#42186) by @Cyrilvallez\r\n* Fix expected DAC outputs due to (old) change in CI settings. (#43896) by @ebezzam\r\n* Minor changes trainer (#43744) by @SunMarc\r\n* adding BC for custom toks accessing slow tok attrs deprecated in v5 (#43898) by @itazap\r\n* Fix typo in quantization_operations in PEFT integrations (#43821) by @redpanda1995\r\n* Update KERNELS_MIN_VERSION to 0.10.2 to be the same as setup.py (#43753) by @cyyever\r\n* Decorate cache updates with no_grad, just in case (#43897) by @Rocketknight1\r\n* revert place_model_on_device to property (#43895) by @SunMarc\r\n* Train sampler unification (#43138) by @jiosephlee\r\n* fix(moe): Handle dtype mismatch in torch._grouped_mm with autocast (#43839) by @Mr-Neutr0n\r\n* Fix missing fast image patch counter in Glm46V (#43877) by @OiPunk\r\n* Fix old tech stack in doc (#43902) by @cyyever\r\n* Move `_keys_to_ignore_on_load_missing` for now (#43893) by @ArthurZucker\r\n* Changes to cache_utils should trigger all tests all the time (#43920) by @Cyrilvallez\r\n* Ernie4 5 vl moe (#43755) by @kaixuanliu\r\n* Harmonize `input_embeds` to `inputs_embeds` everywhere (#43916) by @Cyrilvallez\r\n* fix: TextClassificationPipeline docs mentioning deprecated return_all_scores (#43903) by @math-hiyoko\r\n* Revert #43897 (#43923) by @Rocketknight1\r\n* Fix AttributeError in OwlViT conversion script for Python 3.10+ (#43922) by @DimiChatzipavlis\r\n* add openAI style `image_url` content support in `apply_chat_template` (#43786) by @kaixuanliu\r\n* Prepare and keep track of position ids in `generate` (#43734) by @zucchini-nlp\r\n* Fix lifted_tensor in Gemma3n export which dynamo can't reason about (#43801) by @robell\r\n* Fix bark test (#43942) by @Cyrilvallez\r\n* Fix docker files (#43946) by @ydshieh\r\n* Fix flaky test for multimodal LLMs (#43944) by @Rocketknight1\r\n* Add explicit utf-8 encoding to CircleCI scripts for Windows compatibility (#43925) by @<NOT FOUND>\r\n* Modernize string formatting (f-strings) in conversion scripts (#43943) by @<NOT FOUND>\r\n* Fix weight decay exclusions in `run_*_no‚Äëtrainer.py` examples (#42769) by @casinca\r\n* fix: Better weight decay exclusion in `run_*_no‚Äëtrainer.py` examples (#43947) by @casinca\r\n* Timm backbone saves and loads `out_features` (#43886) by @zucchini-nlp\r\n* Fix qwen-vl position ids when generating several times (#43952) by @zucchini-nlp\r\n* Fix `get_number_of_image_tokens` (#43948) by @zucchini-nlp\r\n* Fix typos in docstrings, comments, and error messages (#43949) by @<NOT FOUND>\r\n* Fix LASR test layerdrop issue (#43954) by @Rocketknight1\r\n* [kernels] fix kernel versions  (#43955) by @MekkCyber\r\n* [Doc tests] Fix bug (#43729) by @NielsRogge\r\n* fix(models): Preserve custom token IDs through DiaConfig save and load (#43928) by @harshaljanjani\r\n* update somes audio models (#43865) by @Deep-unlearning\r\n* Improve memory allocator during loading (#43945) by @Cyrilvallez\r\n* Inclusion of process_group in the gather_full_tensor function in tensor_parallel.py (#43932) by @quic-meetkuma\r\n* Fix sync gradient (#43919) by @SunMarc\r\n* Reorder Trainer methods (#43914) by @SunMarc\r\n* Fix TypeError in dot_natural_key when state_dict keys have mixed types at same position (#43966) by @shtse8\r\n* Enhance JSON schema generation to support instance, static, and class methods (#43968) by @qgallouedec\r\n* Remove unused squeeze from VJEPA2 embeddings rotation (#43984) by @materight\r\n* Improve new failing test analysis for PR comment CI (#44033) by @ydshieh\r\n* Remove `other_workflow_run_ids` for `issue_comment` in `utils/notification_service.py` (#44036) by @ydshieh\r\n* stable grouped_mm API (#43977) by @IlyasMoutawwakil\r\n* create .git-blame-ignore-revs file  (#43982) by @SunMarc\r\n* docs: fix typos across documentation files (#43993) by @saurav0369\r\n* update python requirement to 3.10+ to match codebase (#44009) by @mariam851\r\n* Improve use of torch.is_autocast_enabled (#43930) by @cyyever\r\n* Use torch.xlogy  (#44006) by @cyyever\r\n* [Deespeed] fix WeightConverter.convert() use (#43926) by @kashif\r\n* Reduce reduce CUDA sync (#44005) by @cyyever\r\n* split out accelerator args builder method (#43987) by @winglian\r\n* SINQ quantization strategy integration (adapted for Transformers V5) (#43112) by @ChiaraBoretti\r\n* fix(models): Unpack BitNet packed weights to fix CI failure (#43721) by @harshaljanjani\r\n\r\n## Significant community contributions\r\n\r\nThe following contributors have made significant changes to the library over the last release:\r\n\r\n* @ChiaraBoretti\r\n    * SINQ quantization strategy integration (adapted for Transformers V5) (#43112)\r\n* @cyyever\r\n    * Reduce reduce CUDA sync (#44005)\r\n    * Use torch.xlogy  (#44006)\r\n    * Improve use of torch.is_autocast_enabled (#43930)\r\n    * Fix old tech stack in doc (#43902)\r\n    * Update KERNELS_MIN_VERSION to 0.10.2 to be the same as setup.py (#43753)\r\n    * Remove unnecessary code or checks for PT 2.4+ (#43787)\r\n    * Fix old tech stack in doc (#43879)\r\n    * Delete batch_split from EncoderDecoderCache (#43814)\r\n    * Fix markdown documentation (#43076)\r\n* @eustlb\r\n    * Add Voxtral Realtime (#43769)\r\n    * [MistralCommonBackend] fix loading proc (#43887)\r\n* @ebezzam\r\n    * Fix expected DAC outputs due to (old) change in CI settings. (#43896)\r\n    * Add VibeVoice Acoustic Tokenizer (#43400)\r\n* @vasqu\r\n    * [`Jamba`] Fallback to slow path and warn instead of error out (#43889)\r\n    * :rotating_light: [`Attn`] New attn mask interface everywhere (#42848)\r\n    * [`Repo Consistency`] Fix rms norm (#43803)\r\n    * [`Modular Dependencies`] Fixup qwen rms norms (#43772)\r\n* @bozheng-hit\r\n    * Adding Support for Qwen3.5 (#43830)\r\n",
      "publishedAt": "2026-02-16T18:55:53.000Z",
      "source": "Hugging Face GitHub",
      "sourceUrl": "https://github.com/huggingface/transformers/releases/tag/v5.2.0",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "GPT",
        "Llama",
        "LLM",
        "AI",
        "ML"
      ],
      "featured": false
    },
    {
      "id": "mlstdgrnrtb7ynqi69",
      "title": "Google: cookbook„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "cookbook„É™„Éù„Ç∏„Éà„É™„Å´Êñ∞„Åó„ÅÑÊõ¥Êñ∞: Reorganize and update .gitignore entriesOnly ignoring python files at root level...",
      "content": "Reorganize and update .gitignore entriesOnly ignoring python files at root level",
      "publishedAt": "2026-02-10T16:17:29.000Z",
      "source": "Google GitHub",
      "sourceUrl": "https://github.com/google-gemini/cookbook",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [],
      "featured": false
    },
    {
      "id": "mlstdjlyeo9qyyfcyoi",
      "title": "Hugging Face: v5.1.0: EXAONE-MoE, PP-DocLayoutV3, Youtu-LLM, GLM-OCR",
      "summary": "## New Model additions\r\n\r\n### EXAONE-MoE\r\n\r\n<img width=\"2278\" height=\"1142\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0c3d5341-0483-49c3-8467-f9784ec94b37\" />\r\n\r\nK-EXAONE is a large-scale multilingual language model developed by LG AI Research. Built using a Mixture-of-Experts arch...",
      "content": "## New Model additions\r\n\r\n### EXAONE-MoE\r\n\r\n<img width=\"2278\" height=\"1142\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0c3d5341-0483-49c3-8467-f9784ec94b37\" />\r\n\r\nK-EXAONE is a large-scale multilingual language model developed by LG AI Research. Built using a Mixture-of-Experts architecture, K-EXAONE features 236 billion total parameters, with 23 billion active during inference. Performance evaluations across various benchmarks demonstrate that K-EXAONE excels in reasoning, agentic capabilities, general knowledge, multilingual understanding, and long-context processing.\r\n\r\n* Add EXAONE-MoE implementations (#43080) by @nuxlear\r\n\r\n### PP-DocLayoutV3\r\n\r\n<img width=\"6252\" height=\"1892\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b2e58244-8ed3-42c6-80d7-e32842977ddb\" />\r\n\r\n**PP-DocLayoutV3** is a unified and high-efficiency model designed for comprehensive layout analysis. It addresses the challenges of complex physical distortions‚Äîsuch as skewing, curving, and adverse lighting‚Äîby integrating instance segmentation and reading order prediction into a single, end-to-end framework.\r\n\r\n* [Model] Add PP-DocLayoutV3 Model Support (#43098) by @zhang-prog\r\n\r\n### Youtu-LLM\r\n\r\n<img width=\"564\" height=\"352\" alt=\"image\" src=\"https://github.com/user-attachments/assets/864372be-4ecb-41fd-8c92-f3515be040d3\" />\r\n\r\nYoutu-LLM is a new, small, yet powerful LLM, contains only 1.96B parameters, supports 128k long context, and has native agentic talents. On general evaluations, Youtu-LLM significantly outperforms SOTA LLMs of similar size in terms of Commonsense, STEM, Coding and Long Context capabilities; in agent-related testing, Youtu-LLM surpasses larger-sized leaders and is truly capable of completing multiple end2end agent tasks. \r\n\r\n  * Add Youtu-LLM model (#43166) by @LuJunru\r\n\r\n### GlmOcr\r\n\r\n<img width=\"3972\" height=\"2352\" alt=\"image\" src=\"https://github.com/user-attachments/assets/a7ddfb4f-42ea-4dc6-bc73-aefb0f750c4e\" />\r\n\r\nGLM-OCR is a multimodal OCR model for complex document understanding, built on the GLM-V encoder‚Äìdecoder architecture. It introduces Multi-Token Prediction (MTP) loss and stable full-task reinforcement learning to improve training efficiency, recognition accuracy, and generalization. The model integrates the CogViT visual encoder pre-trained on large-scale image‚Äìtext data, a lightweight cross-modal connector with efficient token downsampling, and a GLM-0.5B language decoder. Combined with a two-stage pipeline of layout analysis and parallel recognition based on PP-DocLayout-V3, GLM-OCR delivers robust and high-quality OCR performance across diverse document layouts.\r\n\r\n* [GLM-OCR] GLM-OCR Support (#43391)by @zRzRzRzRzRzRzR\r\n\r\n## Breaking changes\r\n\r\n* üö® T5Gemma2 model structure (#43633) - Makes sure that the attn implementation is set to all sub-configs. The config.encoder.text_config was not getting its attn set because we aren't passing it to PreTrainedModel.__init__. We can't change the model structure without breaking so I manually re-added a call to self.adjust_attn_implemetation in modeling code\r\n\r\n* üö® Generation cache preparation (#43679) - Refactors cache initialization in generation to ensure sliding window configurations are now properly respected. Previously, some models (like Afmoe) created caches without passing the model config, causing sliding window limits to be ignored. This is breaking because models with sliding window attention will now enforce their window size limits during generation, which may change generation behavior or require adjusting sequence lengths in existing code.\r\n\r\n* üö® Delete duplicate code in backbone utils (#43323) - This PR cleans up backbone utilities. Specifically, we have currently 5 different config attr to decide which backbone to load, most of which can be merged into one and seem redundant\r\nAfter this PR, we'll have only one config.backbone_config as a single source of truth. The models will load the backbone from_config and load pretrained weights only if the checkpoint has any weights saved. The overall idea is same as in other composite models. A few config arguments are removed as a result.\r\n\r\n* üö® Refactor DETR to updated standards (#41549) - standardizes the DETR model to be closer to other vision models in the library.\r\n\r\n* üö®Fix floating-point precision in JanusImageProcessor resize (#43187) - replaces an `int()` with `round()`, expect light numerical differences \r\n\r\n* üö® Remove deprecated AnnotionFormat (#42983) - removes a missnamed class in favour of `AnnotationFormat`. \r\n\r\n## Bugfixes and improvements\r\n\r\n* fix(models): Migrate legacy segmentation_indices to out_indices in BeitConfig (#43505) by @harshaljanjani\r\n* [docs] Update torch version (#42135) by @stevhliu\r\n* Remove SDPA workarounds for torch 2.4+ (#43754) by @cyyever\r\n* add use_deterministic to guarantee the consistency for youtu-llm model (#43759) by @kaixuanliu\r\n* fix: add compatible_model_types to suppress model type mismatch warnings (#43495) by @leoneperdigao\r\n* Fix T5 v1.1 detection (#43681) by @githubnemo\r\n* Add moonshine streaming (#43702) by @eustlb\r\n* Allow bi-directional attention for all models (#43705) by @Cyrilvallez\r\n* Docs: fix Training step by removing tokenizer from trainer initialization (#43733) by @nesjett\r\n* Fix scheduler initialization order (#43711) by @SunMarc\r\n* Fix accelerate integration import  (#43732) by @SunMarc\r\n* Update torch minimum version to 2.4 (#41307) by @cyyever\r\n* Fix dtype in image-text-to-text pipe (#43731) by @zucchini-nlp\r\n* Preventing initialization of siglip's lecun_normal_, default_flax_embed_init in ZeRO3 (#43574) by @jp1924\r\n* fix: AttributeError for Qwen3_omni_moe (#43593) by @Vallabh-1504\r\n* Improve typing/explanations for general model properties (#43712) by @Cyrilvallez\r\n* [Kernels] kernel migration updates for activation kernels (#43518) by @ariG23498\r\n* [`feat`] Allow loading T5Gemma2Encoder with AutoModel (#43559) by @tomaarsen\r\n* Added S110 - try-except-pass rule (#43687) by @tarekziade\r\n* [docs] benchmarks (#43694) by @stevhliu\r\n* fix norm_eps dtype (#43669) by @fschlatt\r\n* Llava onevision: output align for tests and add `image_sizes` input param (#43678) by @kaixuanliu\r\n* Fix CLIPOutput attentions not being returned (#43657) by @jonathan-fulton\r\n* [`Attn`] Fixup interface usage after refactor (#43706) by @vasqu\r\n* Fix model/processor mismatch in SigLIP2 quantization example (#43652) by @jonathan-fulton\r\n* Fix crash of custom models in Notebook or Repl (#43690) by @Cyrilvallez\r\n* Simplify TrainingArguments docstring (#43568) by @SunMarc\r\n* Composite model inherit automatically all important properties from their children (#43691) by @Cyrilvallez\r\n* Update configuration_qwen3.py (#43703) by @francesco-bertolotti\r\n* fix gptoss tp crash (#43695) by @sywangyi\r\n* [CB] Keep order of incoming requests (#43626) by @remi-or\r\n* Fix Apertus model loading (NotImplementedError: Cannot copy out of meta tensor; no data!) (#43473) by @xenova\r\n* Remove `num_frames` in ASR pipeline (#43546) by @jiqing-feng\r\n* remove ipex and ccl for xpu and cpu (#42852) by @yao-matrix\r\n* update guide with new attr name for toks (#43689) by @itazap\r\n* Docs: fix typos in Get started (index, quicktour) (#43666) by @CodeByKodi\r\n* the cache class is deprecated by @vasqu (direct commit on main)\r\n* custom tok init fix (#43591) by @itazap\r\n* More export friendly rewrites and skipping the failing ones (#43436) by @IlyasMoutawwakil\r\n* Cast byte_count to int in caching_allocator_warmup for MPS compatibility (#43608) by @tobyliu2004\r\n* [Docs] Complete missing Llama4 configuration docs (#43460) by @udaymehta\r\n* Fix t5 failures (#43374) by @Abdennacer-Badaoui\r\n* Add EoMT with DINOv3 backbone (#41212) by @NielsRogge\r\n* Update DBRX docs to reference re-uploaded checkpoint (#43196) by @qgallouedec\r\n* [loading] Fix forced upcasting to fp32 (#43683) by @Cyrilvallez\r\n* Fix FP8Expert for Qwen (#43670) by @yiliu30\r\n* Simplify loading structure (#43589) by @Cyrilvallez\r\n* [CB] Refactor logic for inputs and outputs outside of the main API (#43569) by @remi-or\r\n* Make sure hub errors are surfaced in `PreTrainedTokenizerBase` (#43675) by @tarekziade\r\n* Fix `FP8Expert` for DeepSeek R1 (#43616) by @yiliu30\r\n* Use correct sampling rate in chat template (#43674) by @zucchini-nlp\r\n* [`HunYuan`] Fix RoPE init (#43411) by @vasqu\r\n* XPU now supports MoE kernel(MegaBlocks) implementation (#43435) by @YangKai0616\r\n* [`Sam`] Fixup training flags (#43567) by @vasqu\r\n* remove torchao.autoquant from transformers (#43561) by @vkuzo\r\n* [DeepSpeed] properly handle MoE weight conversion (#43524) by @kashif\r\n* Tie zamba weights correctly (#43623) by @zucchini-nlp\r\n* [kernels] Centralize kernels tests (#42819) by @MekkCyber\r\n* Fix `process_bad_commit_report.py`: avoid items to appear in `null` author in the report (#43662) by @ydshieh\r\n* Fix `KeyError` in `check_bad_commit.py` (#43655) by @ydshieh\r\n* [Benchmark] Minor fix for benchmark: kernel is not correctly called (#43428) by @sywangyi\r\n* Add explicit commit info to PR comment CI feedback  (#43635) by @ydshieh\r\n* Better new failures reporting for PR comment CI (#43629) by @ydshieh\r\n* [docs] serving (#42853) by @stevhliu\r\n* add XPU expected output for MixedInt8GPT2Test (#43615) by @kaixuanliu\r\n* Don't modify mappings in tests (#43634) by @Rocketknight1\r\n* Allow Attention and Experts to be used as standalone modules (#43622) by @Cyrilvallez\r\n* Don't modify `tied_weight_keys` in-place (#43619) by @zucchini-nlp\r\n* [`Rope`] Revert #43410 and make inheritance implicit again (#43620) by @vasqu\r\n* [vllm compat] Separate renaming from conversion ops (#43621) by @Cyrilvallez\r\n* refactor + robusts tests for Tensor Parallel  (#42809) by @3outeille\r\n* add contiguous operation for diffllama model for xpu to enable compile mode. (#43614) by @kaixuanliu\r\n* add xpu expectation for lw_detr model (#43339) by @kaixuanliu\r\n* minimax_m2: fix failed test case for XPU (#43324) by @kaixuanliu\r\n* Improve new failures reporting (#43628) by @ydshieh\r\n* Fix extras on all supported Python versions (#43490) by @tarekziade\r\n* fix(models): Fix suno/bark-small CPU offload device mismatch causing CI failures (#43607) by @harshaljanjani\r\n* [CB] [Serve] Fix broken serve tests (#43594) by @remi-or\r\n* Docs: fix typo in weight converter guide (#43610) by @KOKOSde\r\n* [MoE] Use int input for histc on CUDA to support deterministic algorithms (#43583) by @YangKai0616\r\n* Fixes configuration default values (#43592) by @zucchini-nlp\r\n* Fix `make_batched_video` with 5D arrays (#43486) by @zucchini-nlp\r\n* Operation Green CI II (#43537) by @Rocketknight1\r\n* enable cpu paged cache (#42869) by @jiqing-feng\r\n* Qwen3 omni - fix get video features (#43588) by @zucchini-nlp\r\n* [GLM-Image] Add batch > 1 support and fix configuration defaults (#43342) by @JaredforReal\r\n* [Model] Refactor modernbert with the attention interface (#43030) by @YangKai0616\r\n* Regex post processing in loading (#43585) by @Cyrilvallez\r\n* simplify extra tokens logic in base (#43230) by @itazap\r\n* Add XPU support to the tests for solar_open (#43579) by @YangKai0616\r\n* remove FbgemmFp8LinearTest (#43545) by @sywangyi\r\n* Increase default ReadTimeout in tests (#43586) by @Wauplin\r\n* Fix mistral checkpoint loading in `utils/fetch_hub_objects_for_ci.py`: avoid too many requests and/or timeout (#43584) by @ydshieh\r\n* [CI][AMD] Fix Pipeline CI  (#43178) by @Abdennacer-Badaoui\r\n* fix(converter): speed up `MistralConverter.extract_vocab_merges_from_model` (#43557) by @tarekziade\r\n* Improve GPU monitoring: switch to multiprocessing and use amdsmi for AMD GPUs (#43552) by @Abdennacer-Badaoui\r\n* Update test of Youtu-LLM to pr-aligned repos (#43578) by @LuJunru\r\n* Rework dependencies and extras + Remove outdated `templates` folder (#43536) by @Cyrilvallez\r\n* Fix repo. consistency bot (push permission issue) (#43570) by @ydshieh\r\n* Fix Wav2vec and a few others (#43566) by @Cyrilvallez\r\n* [`Modular`] Allow to add new bases that are not present in the inherited class (#43556) by @vasqu\r\n* add an option to disable Sam3VideoModel progress bar (#43564) by @ndeybach\r\n* check/fix repo. check bot workflow (#43565) by @ydshieh\r\n* Increase timeout when preparing CI (#43560) by @Rocketknight1\r\n* 43054: Add Siglip2Tokenizer to enforce training-time text preprocessing defaults (#43101) by @vaibhav-research\r\n* check PR bot permission - part 3 (try content attribute) (#43555) by @ydshieh\r\n* check PR bot permission - part 2 (style only) (#43554) by @ydshieh\r\n* check PR bot permission - part 1 (#43553) by @ydshieh\r\n* Fix failing tests due to no attribute `pad_token_id` (#43453) by @Sai-Suraj-27\r\n* fix: GPT OSS Conversion Script Enhancements (#42901) by @KyleMylonakisProtopia\r\n* [Quantization] Fix triton_kernels name after being renamed to gpt-oss-triton-kernels (#43528) by @MekkCyber\r\n* [Quantization] Add cutlass kernel for FP8 (#43304) by @MekkCyber\r\n* [CB] Minor perf improvements and ty compatibility (#43521) by @remi-or\r\n* Fix tiles mixing for batched input, add tie_word_embeddings to LFM2VL config (#43379) by @ankke\r\n* fix: return labels instead of label in reduce_label method in BeitImageProcessorFast (#43527) by @sbucaille\r\n* [`RoPE`] Make explicit inheritance (#43410) by @vasqu\r\n* Fix for #43530 (#43535) by @Rocketknight1\r\n* Operation Green CI (#43530) by @Rocketknight1\r\n* Tie the weights even if initializing from a config on meta device (#43523) by @Cyrilvallez\r\n* [kernels] Update cv_utils name (#43529) by @MekkCyber\r\n* add trackio to training notebooks (#43442) by @merveenoyan\r\n* Mark test_prompt_lookup_decoding as flaky (#42184) by @Rocketknight1\r\n* Fix some MoE routers (#43445) by @IlyasMoutawwakil\r\n* batched_mm is slow on cpu (#43438) by @IlyasMoutawwakil\r\n* fix: initialize BatchNorm2d buffers only when needed (#43520) by @tarekziade\r\n* Fix loading of Qwen3 FP8 (#43494) by @githubnemo\r\n* fix `ShieldGemma2IntegrationTest::test_model` (#43343) by @sywangyi\r\n* Update `SamHQModelIntegrationTest::test_inference_mask_generation_batched_points_batched_images` for `XPU` (#43511) by @sywangyi\r\n* Revert utils files changes from PR #42845 (#43507) by @ydshieh\r\n* Move hardcoded time_step params to config for Bamba, FalconH1, GraniteMoeHybrid (#43461) by @raimbekovm\r\n* Prepare inputs for generation is called from `super()` (#43280) by @zucchini-nlp\r\n* Enhance repo. consistency bot (#43503) by @ydshieh\r\n* Add `pytest-random-order` for reproducible test randomization (#43483) by @tarekziade\r\n* Add missing GPURawMetrics.from_dict() method in benchmark_v2 (#43499) by @Abdennacer-Badaoui\r\n* push dev version 5.0.1.dev0 by @ArthurZucker (direct commit on main)\r\n* Fix failing `markuplm` & `perception_lm` integration tests (#43464) by @Sai-Suraj-27\r\n* fix(Phi4Multimodal): Fix incorrect default vision/audio config initialization in Phi4MultimodalConfig (#43480) by @charlieJ107\r\n* handle 1D position_ids for modeling_flash_attention_utils as well (#43403) by @kaixuanliu\r\n* Remove stale TODO comments in UDOP tied weights (#43477) by @raimbekovm\r\n* Fix Mxfp4 dequantize (#43326) by @Cyrilvallez\r\n\r\n## Significant community contributions\r\n\r\nThe following contributors have made significant changes to the library over the last release:\r\n\r\n* @cyyever\r\n    * Remove SDPA workarounds for torch 2.4+ (#43754)\r\n    * Update torch minimum version to 2.4 (#41307)\r\n    * üö® Remove deprecated AnnotionFormat (#42983)\r\n* @eustlb\r\n    * Add moonshine streaming (#43702)\r\n* @tarekziade\r\n    * Added S110 - try-except-pass rule (#43687)\r\n    * Make sure hub errors are surfaced in `PreTrainedTokenizerBase` (#43675)\r\n    * Fix extras on all supported Python versions (#43490)\r\n    * fix(converter): speed up `MistralConverter.extract_vocab_merges_from_model` (#43557)\r\n    * fix: initialize BatchNorm2d buffers only when needed (#43520)\r\n    * Add `pytest-random-order` for reproducible test randomization (#43483)\r\n* @nuxlear\r\n    * Add EXAONE-MoE implementations (#43080)\r\n* @vasqu\r\n    * [`Attn`] Fixup interface usage after refactor (#43706)\r\n    * the cache class is deprecated\r\n    * [`HunYuan`] Fix RoPE init (#43411)\r\n    * [`Sam`] Fixup training flags (#43567)\r\n    * [`Rope`] Revert #43410 and make inheritance implicit again (#43620)\r\n    * [`Modular`] Allow to add new bases that are not present in the inherited class (#43556)\r\n    * [`RoPE`] Make explicit inheritance (#43410)\r\n* @remi-or\r\n    * [CB] Keep order of incoming requests (#43626)\r\n    * [CB] Refactor logic for inputs and outputs outside of the main API (#43569)\r\n    * [CB] [Serve] Fix broken serve tests (#43594)\r\n    * [CB] Minor perf improvements and ty compatibility (#43521)\r\n* @NielsRogge\r\n    * Add EoMT with DINOv3 backbone (#41212)\r\n* @YangKai0616\r\n    * XPU now supports MoE kernel(MegaBlocks) implementation (#43435)\r\n    * [MoE] Use int input for histc on CUDA to support deterministic algorithms (#43583)\r\n    * [Model] Refactor modernbert with the attention interface (#43030)\r\n    * Add XPU support to the tests for solar_open (#43579)\r\n* @ydshieh\r\n    * Fix `process_bad_commit_report.py`: avoid items to appear in `null` author in the report (#43662)\r\n    * Fix `KeyError` in `check_bad_commit.py` (#43655)\r\n    * Add explicit commit info to PR comment CI feedback  (#43635)\r\n    * Better new failures reporting for PR comment CI (#43629)\r\n    * Improve new failures reporting (#43628)\r\n    * Fix mistral checkpoint loading in `utils/fetch_hub_objects_for_ci.py`: avoid too many requests and/or timeout (#43584)\r\n    * Fix repo. consistency bot (push permission issue) (#43570)\r\n    * check/fix repo. check bot workflow (#43565)\r\n    * check PR bot permission - part 3 (try content attribute) (#43555)\r\n    * check PR bot permission - part 2 (style only) (#43554)\r\n    * check PR bot permission - part 1 (#43553)\r\n    * Revert utils files changes from PR #42845 (#43507)\r\n    * Enhance repo. consistency bot (#43503)\r\n* @JaredforReal\r\n    * [GLM-Image] Add batch > 1 support and fix configuration defaults (#43342)\r\n* @zhang-prog\r\n    * [Model] Add PP-DocLayoutV3 Model Support (#43098)\r\n* @LuJunru\r\n    * Update test of Youtu-LLM to pr-aligned repos (#43578)\r\n    * Add Youtu-LLM model (#43166)\r\n* @zRzRzRzRzRzRzR\r\n    * [GLM-OCR] GLM-OCR Support (#43391)",
      "publishedAt": "2026-02-05T15:44:54.000Z",
      "source": "Hugging Face GitHub",
      "sourceUrl": "https://github.com/huggingface/transformers/releases/tag/v5.1.0",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "GPT",
        "Llama",
        "LLM",
        "AI",
        "Transformer"
      ],
      "featured": false
    }
  ],
  "featuredCount": 11
}