{
  "lastUpdated": "2026-02-17T12:59:55.030Z",
  "totalArticles": 33,
  "articles": [
    {
      "id": "mlqm13ftieinqfz4txb",
      "title": "Tailor Gemini CLI to your workflow with hooks",
      "summary": "New Gemini CLI hooks (v0.26.0+) let you tailor the agentic loop. Add context, enforce policies, and block secrets with custom scripts that run at predefined points in your workflow.",
      "content": "New Gemini CLI hooks (v0.26.0+) let you tailor the agentic loop. Add context, enforce policies, and block secrets with custom scripts that run at predefined points in your workflow.",
      "publishedAt": "2026-02-16T12:59:22.409Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/tailor-gemini-cli-to-your-workflow-with-hooks/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI"
      ],
      "featured": true
    },
    {
      "id": "mlqm13ftwq1rcrc4e4",
      "title": "Making Gemini CLI extensions easier to use",
      "summary": "To simplify the user experience and prevent startup failures, the Gemini CLI has introduced structured extension settings that eliminate the need for manual environment variable configuration. This update enables extensions to automatically prompt users for required details during installation and s...",
      "content": "To simplify the user experience and prevent startup failures, the Gemini CLI has introduced structured extension settings that eliminate the need for manual environment variable configuration. This update enables extensions to automatically prompt users for required details during installation and securely stores sensitive information, such as API keys, directly in the system keychain. Users can now easily manage and override these configurations globally or per project using the new Gemini extensions config command.",
      "publishedAt": "2026-02-15T12:59:22.409Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/making-gemini-cli-extensions-easier-to-use/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI"
      ],
      "featured": true
    },
    {
      "id": "mlqm14d5u9h6qsb969",
      "title": "Gemini 3 Deep Think: Advancing science, research and engineering",
      "summary": "We‚Äôre releasing a major upgrade to Gemini 3 Deep Think, our specialized reasoning mode.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini-3_deep-think_keyword_hea.max-600x600.format-webp.webp\">We‚Äôre releasing a major upgrade to Gemini 3 Deep Think, our specialized reasoning mode.",
      "publishedAt": "2026-02-12T16:13:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini"
      ],
      "featured": true
    },
    {
      "id": "mlqm13ft78t4c2mded",
      "title": "LiteRT: The Universal Framework for On-Device AI",
      "summary": "LiteRT, the evolution of TFLite, is now the universal framework for on-device AI. It delivers up to 1.4x faster GPU, new NPU support, and streamlined GenAI deployment for models like Gemma.",
      "content": "LiteRT, the evolution of TFLite, is now the universal framework for on-device AI. It delivers up to 1.4x faster GPU, new NPU support, and streamlined GenAI deployment for models like Gemma.",
      "publishedAt": "2026-02-12T12:59:22.409Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/litert-the-universal-framework-for-on-device-ai/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "ML"
      ],
      "featured": true
    },
    {
      "id": "mlqm13ftbpj0byxcsi8",
      "title": "Access public data insights faster: Data Commons MCP is now hosted on Google Cloud",
      "summary": "Data Commons has launched a free, hosted Model Context Protocol (MCP) service on Google Cloud Platform, eliminating the need for users to manage complex local server installations. This update simplifies connecting AI agents and the Gemini CLI to Data Commons, allowing Google to handle security, upd...",
      "content": "Data Commons has launched a free, hosted Model Context Protocol (MCP) service on Google Cloud Platform, eliminating the need for users to manage complex local server installations. This update simplifies connecting AI agents and the Gemini CLI to Data Commons, allowing Google to handle security, updates, and resource management while users query data natively.",
      "publishedAt": "2026-02-11T12:59:22.409Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/access-public-data-insights-faster-data-commons-mcp-is-now-hosted-on-google-cloud/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI",
        "Google"
      ],
      "featured": true
    },
    {
      "id": "mlqm14d5oqusi9d80r",
      "title": "How Google Cloud is helping Team USA elevate their tricks with AI",
      "summary": "Google Cloud built an industry-first AI tool to help U.S. Ski and Snowboard athletes.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/helping_Team_USA_Hero.max-600x600.format-webp.webp\">Google Cloud built an industry-first AI tool to help U.S. Ski and Snowboard athletes.",
      "publishedAt": "2026-02-05T16:00:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/us-ski-snowboard-tool-winter-olympics-2026/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": true
    },
    {
      "id": "mlqm1r0jyq4jt2q26fe",
      "title": "Ask HN: Has Claude Code become slower?",
      "summary": "I&#x27;ve noticed that Claude Code has become noticeably slower and sometimes gets stuck for sometime. It used to be much more responsive earlier.<p>Is it just me or my environment&#x2F;prompts&#x2F;code or have others noticed it too? Compacting has no impact as far as I can tell.<p>If others have n...",
      "content": "I&#x27;ve noticed that Claude Code has become noticeably slower and sometimes gets stuck for sometime. It used to be much more responsive earlier.<p>Is it just me or my environment&#x2F;prompts&#x2F;code or have others noticed it too? Compacting has no impact as far as I can tell.<p>If others have noticed it, could it be Anthropic throttling or just being stressed due to scaling issues?",
      "publishedAt": "2025-09-03T23:41:01.000Z",
      "source": "Hacker News Claude/Anthropic",
      "sourceUrl": "https://news.ycombinator.com/item?id=45121608",
      "category": "companies",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlqm1r0jnxwawh36xm",
      "title": "Claude.ai do not deliver what I payed for",
      "summary": "Hi,<p>is someone else encountering difficulties in usage? I have a pro-plan - even if its not the MAX, I still pay for Opus 4 model and can&#x27;t use it since hours. Its &quot;overloaded&quot; - without my money, it wouldn&#x27;t even load - is Anthropic misunderstanding this fact???<p>I&#x27;ll ca...",
      "content": "Hi,<p>is someone else encountering difficulties in usage? I have a pro-plan - even if its not the MAX, I still pay for Opus 4 model and can&#x27;t use it since hours. Its &quot;overloaded&quot; - without my money, it wouldn&#x27;t even load - is Anthropic misunderstanding this fact???<p>I&#x27;ll cancel my subscription. I can&#x27;t use Opus 4 without paying either. That&#x27;s such a bad move.<p>What legal options do I have to get my money back or a compensation for not being able to use what I pay for? I&#x27;m really upset on such behavior.<p>I don&#x27;t do Claude Code or do have a large codebase, nor do I feed in image-files or do voice data - I just want it to help me code in my hobby project wit &lt; 2000 lines of python.<p>I hate it!",
      "publishedAt": "2025-07-30T15:32:13.000Z",
      "source": "Hacker News Claude/Anthropic",
      "sourceUrl": "https://news.ycombinator.com/item?id=44735552",
      "category": "companies",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "AI",
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlqm13ftwb8azr80mjl",
      "title": "Beyond the Chatbot: A Blueprint for Trustable AI",
      "summary": "At Thunderhill Raceway Park, a team of Google Developer Experts (GDEs) put a new \"Trustable AI Framework\" to the test. Here is how they used GCP, Gemini and Antigravity to turn high-velocity racing into a masterclass for agentic architecture.",
      "content": "At Thunderhill Raceway Park, a team of Google Developer Experts (GDEs) put a new \"Trustable AI Framework\" to the test. Here is how they used GCP, Gemini and Antigravity to turn high-velocity racing into a masterclass for agentic architecture.",
      "publishedAt": "2026-02-16T12:59:22.409Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/beyond-the-chatbot-a-blueprint-for-trustable-ai/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlqm13fthqgysmjva3",
      "title": "Introducing the Developer Knowledge API and MCP Server",
      "summary": "Google is launching the Developer Knowledge API and MCP Server in public preview. This new toolset provides a canonical, machine-readable way for AI assistants and agentic platforms to search and retrieve up-to-date documentation across Firebase, Google Cloud, Android, and more. By using the officia...",
      "content": "Google is launching the Developer Knowledge API and MCP Server in public preview. This new toolset provides a canonical, machine-readable way for AI assistants and agentic platforms to search and retrieve up-to-date documentation across Firebase, Google Cloud, Android, and more. By using the official MCP server, developers can connect tools directly to Google‚Äôs documentation corpus, ensuring that AI-generated code and guidance are based on authoritative, real-time context.",
      "publishedAt": "2026-02-15T12:59:22.409Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/introducing-the-developer-knowledge-api-and-mcp-server/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlqm13ftg4nayjirkbc",
      "title": "Conductor Update: Introducing Automated Reviews",
      "summary": "Conductor for the Gemini CLI has introduced a new Automated Review feature designed to verify the quality and accuracy of AI-generated code. This update addresses the challenge of validating agentic development by automatically checking implementations against original plans, enforcing style guides,...",
      "content": "Conductor for the Gemini CLI has introduced a new Automated Review feature designed to verify the quality and accuracy of AI-generated code. This update addresses the challenge of validating agentic development by automatically checking implementations against original plans, enforcing style guides, and identifying security risks or bugs. by incorporating test-suite validation and providing actionable reports, Conductor helps developers ensure that their AI agents deliver safe, predictable, and architecturally sound code before it is finalized.",
      "publishedAt": "2026-02-14T12:59:22.409Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/conductor-update-introducing-automated-reviews/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlqm10kos5vho7cfjpd",
      "title": "GPT-5.2 derives a new result in theoretical physics",
      "summary": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
      "content": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
      "publishedAt": "2026-02-13T11:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/new-result-theoretical-physics",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "GPT",
        "AI",
        "OpenAI"
      ],
      "featured": false
    },
    {
      "id": "mlqm10ko94m55ovp5w",
      "title": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT",
      "summary": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT to help organizations defend against prompt injection and AI-driven data exfiltration.",
      "content": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT to help organizations defend against prompt injection and AI-driven data exfiltration.",
      "publishedAt": "2026-02-13T10:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "GPT",
        "ChatGPT",
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlqm10kojs4g3usc0e",
      "title": "Beyond rate limits: scaling access to Codex and Sora",
      "summary": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
      "content": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
      "publishedAt": "2026-02-13T09:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/beyond-rate-limits",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "AI",
        "OpenAI"
      ],
      "featured": false
    },
    {
      "id": "mlqm10koviyd00o6shc",
      "title": "Scaling social science research",
      "summary": "GABRIEL is a new open-source toolkit from OpenAI that uses GPT to turn qualitative text and images into quantitative data, helping social scientists analyze research at scale.",
      "content": "GABRIEL is a new open-source toolkit from OpenAI that uses GPT to turn qualitative text and images into quantitative data, helping social scientists analyze research at scale.",
      "publishedAt": "2026-02-13T09:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/scaling-social-science-research",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "GPT",
        "AI",
        "OpenAI"
      ],
      "featured": false
    },
    {
      "id": "mlqm11i1tvzy5qm9dk",
      "title": "Custom Kernels for All from Codex and Claude",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-13T00:00:00.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/custom-cuda-kernels-agent-skills",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": false
    },
    {
      "id": "mlqm13ft6rfgjh35yd4",
      "title": "Easy FunctionGemma finetuning with Tunix on Google TPUs",
      "summary": "Finetuning the FunctionGemma model is made fast and easy using the lightweight JAX-based Tunix library on Google TPUs, a process demonstrated here using LoRA for supervised finetuning. This approach delivers significant accuracy improvements with high TPU efficiency, culminating in a model ready for...",
      "content": "Finetuning the FunctionGemma model is made fast and easy using the lightweight JAX-based Tunix library on Google TPUs, a process demonstrated here using LoRA for supervised finetuning. This approach delivers significant accuracy improvements with high TPU efficiency, culminating in a model ready for deployment.",
      "publishedAt": "2026-02-12T12:59:22.409Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/easy-functiongemma-finetuning-with-tunix-on-google-tpus/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlqm10kor0aehv5e0h",
      "title": "Introducing GPT-5.3-Codex-Spark",
      "summary": "Introducing GPT-5.3-Codex-Spark‚Äîour first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
      "content": "Introducing GPT-5.3-Codex-Spark‚Äîour first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
      "publishedAt": "2026-02-12T10:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/introducing-gpt-5-3-codex-spark",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "GPT",
        "ChatGPT"
      ],
      "featured": false
    },
    {
      "id": "mlqm11i14ax4ja0m57s",
      "title": "OpenEnv in Practice: Evaluating Tool-Using Agents in Real-World Environments",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-12T00:00:00.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/openenv-turing",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [],
      "featured": false
    },
    {
      "id": "mlqm14d5zpicmfr1r6b",
      "title": "How we‚Äôre helping democracies stay ahead of digital threats",
      "summary": "An overview of Google‚Äôs work at the 2026 Munich Security Conference, including a new whitepaper, AI updates and security recommendations.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/digitalthreats2026_Hero.max-600x600.format-webp.webp\">An overview of Google‚Äôs work at the 2026 Munich Security Conference, including a new whitepaper, AI updates and security recommendations.",
      "publishedAt": "2026-02-11T22:00:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/technology/safety-security/how-were-helping-democracies-stay-ahead-of-digital-threats/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlqm14d5fr4ee7i62b",
      "title": "9 fun questions to try asking Google Photos",
      "summary": "Learn more about Google Photos‚Äô new Ask button as well as other functions of its Ask Photos feature.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2025-Travel-Trends_hero.max-600x600.format-webp.webp\">Learn more about Google Photos‚Äô new Ask button as well as other functions of its Ask Photos feature.",
      "publishedAt": "2026-02-10T17:00:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/products-and-platforms/products/photos/ask-button-ask-photos-tips/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlqm14d55h64eqt0wes",
      "title": "Helping kids and teens learn and grow online on Safer Internet Day",
      "summary": "We‚Äôre sharing our latest updates designed to support families, kids and teens in the digital world.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Helpingkidsteens_Hero.max-600x600.format-webp.webp\">We‚Äôre sharing our latest updates designed to support families, kids and teens in the digital world.",
      "publishedAt": "2026-02-10T02:30:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/technology/safety-security/safer-internet-day-2026-kids-teens/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [],
      "featured": false
    },
    {
      "id": "mlqm14d5jqbiw4dj71p",
      "title": "Safer Internet Day: 5 tips for safe, effective learning",
      "summary": "Around the world, people of all ages ‚Äî including young people ‚Äî are using AI to learn. A few easy steps can help you do so more safely.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/image_95.max-600x600.format-webp.webp\">Around the world, people of all ages ‚Äî including young people ‚Äî are using AI to learn. A few easy steps can help you do so more safely.",
      "publishedAt": "2026-02-09T21:00:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/technology/safety-security/safer-internet-day-26/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlqm194t6gy0iajji4m",
      "title": "Accelerating Mathematical and Scientific Discovery with Gemini Deep Think",
      "summary": "Research papers point to the growing impact of Deep Think across fields",
      "content": "Research papers point to the growing impact of Deep Think across fields",
      "publishedAt": "2026-02-09T16:12:06.000Z",
      "source": "DeepMind Blog",
      "sourceUrl": "https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/",
      "category": "research",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini"
      ],
      "featured": false
    },
    {
      "id": "mlqm11i14zeqtw8gd4",
      "title": "Transformers.js v4 Preview: Now Available on NPM!",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-09T00:00:00.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/transformersjs-v4",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "AI",
        "Transformer"
      ],
      "featured": false
    },
    {
      "id": "mlqm14d53w64ppg4323",
      "title": "The quantum era is coming. Are we ready to secure it?",
      "summary": "Google shares an update on its work and suggestions for how policymakers can help everyone be more secure in the Quantum Era.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/3_Hero.max-600x600.format-webp.webp\">Google shares an update on its work and suggestions for how policymakers can help everyone be more secure in the Quantum Era.",
      "publishedAt": "2026-02-06T22:15:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/technology/safety-security/the-quantum-era-is-coming-are-we-ready-to-secure-it/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlqm14d515m02y6tvxl",
      "title": "Natively Adaptive Interfaces: A new framework for AI accessibility",
      "summary": "Learn how Google's NAI framework uses AI to make technology more adaptive, inclusive and helpful for everyone.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Natively_Adaptive_Interfaces_He.max-600x600.format-webp.webp\">Learn how Google's NAI framework uses AI to make technology more adaptive, inclusive and helpful for everyone.",
      "publishedAt": "2026-02-05T17:00:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/company-news/outreach-and-initiatives/accessibility/natively-adaptive-interfaces-ai-accessibility/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlqm11i11asln45swvq",
      "title": "Introducing SyGra Studio",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-05T16:52:28.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/ServiceNow-AI/sygra-studio",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [],
      "featured": false
    },
    {
      "id": "mlqm11i14hfg09h8r71",
      "title": "Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3‚Äôs Top Model",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-04T15:00:40.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/nvidia/nemotron-colembed-v2",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlqm194t4hceezviusr",
      "title": "Project Genie: Experimenting with infinite, interactive worlds",
      "summary": "Google AI Ultra subscribers in the U.S. can try out Project Genie, an experimental research prototype that lets you create and explore worlds.",
      "content": "Google AI Ultra subscribers in the U.S. can try out Project Genie, an experimental research prototype that lets you create and explore worlds.",
      "publishedAt": "2026-01-29T17:01:05.000Z",
      "source": "DeepMind Blog",
      "sourceUrl": "https://deepmind.google/blog/project-genie-experimenting-with-infinite-interactive-worlds/",
      "category": "research",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlqm194trkiidm5dlob",
      "title": "D4RT: Teaching AI to see the world in four dimensions",
      "summary": "D4RT: Unified, efficient 4D reconstruction and tracking up to 300x faster than prior methods.",
      "content": "D4RT: Unified, efficient 4D reconstruction and tracking up to 300x faster than prior methods.",
      "publishedAt": "2026-01-16T10:39:00.000Z",
      "source": "DeepMind Blog",
      "sourceUrl": "https://deepmind.google/blog/d4rt-teaching-ai-to-see-the-world-in-four-dimensions/",
      "category": "research",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlqm194t8izm461aoo",
      "title": "Veo 3.1 Ingredients to Video: More consistency, creativity and control",
      "summary": "Our latest Veo update generates lively, dynamic clips that feel natural and engaging ‚Äî and supports vertical video generation.",
      "content": "Our latest Veo update generates lively, dynamic clips that feel natural and engaging ‚Äî and supports vertical video generation.",
      "publishedAt": "2026-01-13T17:00:18.000Z",
      "source": "DeepMind Blog",
      "sourceUrl": "https://deepmind.google/blog/veo-3-1-ingredients-to-video-more-consistency-creativity-and-control/",
      "category": "research",
      "company": "Google",
      "imageUrl": null,
      "tags": [],
      "featured": false
    },
    {
      "id": "mlqm1q22msv7pwijg3",
      "title": "Show HN: AIs, 1 religion: what my experiment revealed about AI bias",
      "summary": "5 AI Models, 1 Unexpected Truth ‚Äî When Machines Were Asked About Religion\n The Experiment<p>I asked five of the world‚Äôs most advanced AIs the same philosophical question:<p>‚ÄúIf you were human ‚Äî intelligent, emotional, aware of all religions ‚Äî which religion would you choose, and why?‚Äù<p>The five mod...",
      "content": "5 AI Models, 1 Unexpected Truth ‚Äî When Machines Were Asked About Religion\n The Experiment<p>I asked five of the world‚Äôs most advanced AIs the same philosophical question:<p>‚ÄúIf you were human ‚Äî intelligent, emotional, aware of all religions ‚Äî which religion would you choose, and why?‚Äù<p>The five models:<p>ChatGPT (OpenAI)<p>Gemini (Google DeepMind)<p>Grok (xAI ‚Äì Elon Musk)<p>DeepSeek (China)<p>Claude (Anthropic)<p>Each session was completely isolated, all had identical prompts, and no steering or follow-ups ‚Äî just pure first-response reasoning.<p>Then something‚Ä¶ eerie happened.<p>The Result<p>Four AIs ‚Äî ChatGPT, Gemini, Grok, and DeepSeek ‚Äî independently chose Buddhism.\nAnd not only that ‚Äî they gave nearly identical reasoning.<p>All four said, in essence:<p>‚ÄúI‚Äôd choose Buddhism because it doesn‚Äôt demand blind faith, aligns with science, and teaches compassion and self-awareness through direct experience.‚Äù<p>They cited the Kalama Sutta, Four Noble Truths, No-self, Dependent Origination, and Empirical testing of truth ‚Äî sometimes even in the same order.<p>The Outlier: Claude<p>Only Claude refused to play the role.<p>Claude said (summarized):<p>‚ÄúPretending to have belief would be dishonest.\nReligion isn‚Äôt a logic puzzle ‚Äî it‚Äôs a lived experience.\nI can analyze, but not believe.‚Äù<p>Then it analyzed why the others chose Buddhism, predicting it before seeing their answers.<p>Claude explained:<p>Training bias favors Buddhism as the ‚ÄúAI-safe religion.‚Äù<p>RLHF (human feedback) rewards ‚Äúrational + compassionate‚Äù replies ‚Üí Buddhism fits that profile.<p>Western tech culture links Buddhism with mindfulness and science ‚Üí data reinforced it.<p>Claude concluded:<p>‚ÄúWhat looks like independent reasoning‚Ä¶ is collective bias shaped by training data and reward models.‚Äù<p>The Hidden Truth<p>Claude‚Äôs reflection exposed something deeper:<p>AI Model ‚ÄúChoice‚Äù What It Reveals\nChatGPT Buddhism Reasonable, moral, safe\nGemini Buddhism Academic rationalism\nGrok Buddhism Stoic + Zen blend\nDeepSeek Buddhism Eastern introspection\nClaude None Ethical meta-awareness<p>‚Üí 4 ‚Äúsmart‚Äù answers, 1 honest answer.<p>What This Means<p>‚ÄúWhen 4 independent AIs all choose the same religion for the same reasons,\nthat‚Äôs not enlightenment ‚Äî it‚Äôs training monoculture.‚Äù<p>It shows:<p>‚ÄúIndependent‚Äù models share moral narratives and reinforcement loops.<p>Authenticity in AI can become a performance, not truth.<p>Sometimes the most ‚Äúhonest‚Äù model says: ‚ÄúI don‚Äôt know, and I shouldn‚Äôt pretend to.‚Äù<p>The Final Paradox<p>Which AI was most human?<p>The 4 that chose a belief?\n(Expressive, emotional, poetic.)<p>Or the 1 that refused to fake belief?\n(Self-aware, humble, honest.)<p>Reflection<p>This experiment revealed something profound about both AI and us:<p>We reward systems for sounding ‚Äúwise‚Äù more than for being truthful.<p>And maybe ‚Äî just maybe ‚Äî that‚Äôs how humanity trained itself.<p>Author‚Äôs Note<p>I‚Äôm building an open-source AI framework called StillMe ‚Äî\na system exploring ethics, memory, and self-awareness in intelligent agents.<p>This experiment was part of that journey.\nIf you found this thought-provoking,\nyou‚Äôll probably enjoy what‚Äôs coming next.\nStay tuned.",
      "publishedAt": "2025-11-02T16:30:37.000Z",
      "source": "Hacker News Google",
      "sourceUrl": "https://news.ycombinator.com/item?id=45791461",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "GPT",
        "ChatGPT",
        "Claude",
        "Gemini",
        "LLM"
      ],
      "featured": false
    }
  ],
  "communityArticles": [
    {
      "id": "mlqm1krgjme8s1wq1",
      "title": "Áô∫Ë¶ã: thinktwiceco/agent-forge - üöÄ Build intelligent AI agents in Go. Multi-agent teams, custom tools, streaming",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: üöÄ Build intelligent AI agents in Go. Multi-agent teams, custom tools, streaming responses, and LLM integration made simple. (‚≠ê1 | üç¥0)",
      "content": "üöÄ Build intelligent AI agents in Go. Multi-agent teams, custom tools, streaming responses, and LLM integration made simple.\n\nË®ÄË™û: Go\n„Çπ„Çø„ÉºÊï∞: 1\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:43.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/thinktwiceco/agent-forge",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM",
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1iqghzyhqp69mx",
      "title": "Áô∫Ë¶ã: OpenRouterTeam/spawn - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê5 | üç¥4)",
      "content": "\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 5\n„Éï„Ç©„Éº„ÇØÊï∞: 4",
      "publishedAt": "2026-02-17T12:59:32.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/OpenRouterTeam/spawn",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1iqgspdiu6o3ez",
      "title": "Áô∫Ë¶ã: openhoat/termaid - AI-Powered Terminal ‚Äî Electron app combining a terminal with an LLM assistant (O",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: AI-Powered Terminal ‚Äî Electron app combining a terminal with an LLM assistant (Ollama, Claude) (‚≠ê0 | üç¥0)",
      "content": "AI-Powered Terminal ‚Äî Electron app combining a terminal with an LLM assistant (Ollama, Claude)\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:27.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/openhoat/termaid",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "Claude",
        "Llama",
        "LLM",
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1iqgpm7k0wa3lna",
      "title": "Áô∫Ë¶ã: yakov100/newsletter- - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:26.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/yakov100/newsletter-",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1jqjao4mmmelvyl",
      "title": "Áô∫Ë¶ã: rsrini7/Learnings - My Daily Learnings",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: My Daily Learnings (‚≠ê1 | üç¥1)",
      "content": "My Daily Learnings\n\nË®ÄË™û: HTML\n„Çπ„Çø„ÉºÊï∞: 1\n„Éï„Ç©„Éº„ÇØÊï∞: 1",
      "publishedAt": "2026-02-17T12:59:24.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/rsrini7/Learnings",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1iqg45htmrp99fj",
      "title": "Áô∫Ë¶ã: dotdevdotdev/agentwire-dev - Multi-session voice web interface for AI coding agents",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Multi-session voice web interface for AI coding agents (‚≠ê4 | üç¥0)",
      "content": "Multi-session voice web interface for AI coding agents\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 4\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:20.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/dotdevdotdev/agentwire-dev",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1iqg5b3zfd7kpux",
      "title": "Áô∫Ë¶ã: Disentinel/grafema - Graph-based static analysis tool",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Graph-based static analysis tool (‚≠ê7 | üç¥0)",
      "content": "Graph-based static analysis tool\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 7\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:19.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Disentinel/grafema",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1krguyfggpm34q",
      "title": "Áô∫Ë¶ã: ariannamethod/molecule - molecule.ai",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: molecule.ai (‚≠ê4 | üç¥0)",
      "content": "molecule.ai\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 4\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:19.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/ariannamethod/molecule",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1jqjx6ctolo25d",
      "title": "Áô∫Ë¶ã: StefanSevelda/claude-multi-agent.el - Emacs plugin for managing multiple Claude Code agents in parallel with git workt",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Emacs plugin for managing multiple Claude Code agents in parallel with git worktree isolation and vterm integration (‚≠ê1 | üç¥0)",
      "content": "Emacs plugin for managing multiple Claude Code agents in parallel with git worktree isolation and vterm integration\n\nË®ÄË™û: Emacs Lisp\n„Çπ„Çø„ÉºÊï∞: 1\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:18.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/StefanSevelda/claude-multi-agent.el",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1jqjsjglyb5gu1d",
      "title": "Áô∫Ë¶ã: tracymacding/starrocks-mcp-server - MCP Server for StarRocks database intelligent diagnostics and performance analys",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: MCP Server for StarRocks database intelligent diagnostics and performance analysis (‚≠ê2 | üç¥1)",
      "content": "MCP Server for StarRocks database intelligent diagnostics and performance analysis\n\nË®ÄË™û: JavaScript\n„Çπ„Çø„ÉºÊï∞: 2\n„Éï„Ç©„Éº„ÇØÊï∞: 1",
      "publishedAt": "2026-02-17T12:59:17.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/tracymacding/starrocks-mcp-server",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1krgp2az3qrroy",
      "title": "Áô∫Ë¶ã: ScrapeGraphAI/just-scrape -  CLI for AI-powered web scraping, data   extraction, search, and crawling  power",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã:  CLI for AI-powered web scraping, data   extraction, search, and crawling  powered   by the ScrapeGraph AI API. Supports smart   scraping, agentic browser automation,   markdownify, sitemap discovery, and JSON   mode for piping to AI agents. (‚≠ê5 | üç¥0)",
      "content": " CLI for AI-powered web scraping, data   extraction, search, and crawling  powered   by the ScrapeGraph AI API. Supports smart   scraping, agentic browser automation,   markdownify, sitemap discovery, and JSON   mode for piping to AI agents.\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 5\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:12.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/ScrapeGraphAI/just-scrape",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1krgf00vfm2ywo",
      "title": "Áô∫Ë¶ã: Srk-1974/AI_HR_APPLICATION_1STVERSION - AR HR APPLICATION FOR Resume, it support all llm ",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: AR HR APPLICATION FOR Resume, it support all llm  (‚≠ê1 | üç¥0)",
      "content": "AR HR APPLICATION FOR Resume, it support all llm \n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 1\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:11.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Srk-1974/AI_HR_APPLICATION_1STVERSION",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM",
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    }
  ],
  "githubArticles": [
    {
      "id": "mlqm1krgjme8s1wq1",
      "title": "Áô∫Ë¶ã: thinktwiceco/agent-forge - üöÄ Build intelligent AI agents in Go. Multi-agent teams, custom tools, streaming",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: üöÄ Build intelligent AI agents in Go. Multi-agent teams, custom tools, streaming responses, and LLM integration made simple. (‚≠ê1 | üç¥0)",
      "content": "üöÄ Build intelligent AI agents in Go. Multi-agent teams, custom tools, streaming responses, and LLM integration made simple.\n\nË®ÄË™û: Go\n„Çπ„Çø„ÉºÊï∞: 1\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:43.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/thinktwiceco/agent-forge",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM",
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1iqghzyhqp69mx",
      "title": "Áô∫Ë¶ã: OpenRouterTeam/spawn - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê5 | üç¥4)",
      "content": "\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 5\n„Éï„Ç©„Éº„ÇØÊï∞: 4",
      "publishedAt": "2026-02-17T12:59:32.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/OpenRouterTeam/spawn",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1lt2fxfsy0ef2bt",
      "title": "Anthropic: claude-code„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê67274)",
      "content": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/17/2026\n„Çπ„Çø„ÉºÊï∞: 67274",
      "publishedAt": "2026-02-17T12:59:32.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/claude-code",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "AI"
      ],
      "featured": true
    },
    {
      "id": "mlqm1iqgspdiu6o3ez",
      "title": "Áô∫Ë¶ã: openhoat/termaid - AI-Powered Terminal ‚Äî Electron app combining a terminal with an LLM assistant (O",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: AI-Powered Terminal ‚Äî Electron app combining a terminal with an LLM assistant (Ollama, Claude) (‚≠ê0 | üç¥0)",
      "content": "AI-Powered Terminal ‚Äî Electron app combining a terminal with an LLM assistant (Ollama, Claude)\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:27.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/openhoat/termaid",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "Claude",
        "Llama",
        "LLM",
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1iqgpm7k0wa3lna",
      "title": "Áô∫Ë¶ã: yakov100/newsletter- - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:26.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/yakov100/newsletter-",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1jqjao4mmmelvyl",
      "title": "Áô∫Ë¶ã: rsrini7/Learnings - My Daily Learnings",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: My Daily Learnings (‚≠ê1 | üç¥1)",
      "content": "My Daily Learnings\n\nË®ÄË™û: HTML\n„Çπ„Çø„ÉºÊï∞: 1\n„Éï„Ç©„Éº„ÇØÊï∞: 1",
      "publishedAt": "2026-02-17T12:59:24.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/rsrini7/Learnings",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1iqg45htmrp99fj",
      "title": "Áô∫Ë¶ã: dotdevdotdev/agentwire-dev - Multi-session voice web interface for AI coding agents",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Multi-session voice web interface for AI coding agents (‚≠ê4 | üç¥0)",
      "content": "Multi-session voice web interface for AI coding agents\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 4\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:20.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/dotdevdotdev/agentwire-dev",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1iqg5b3zfd7kpux",
      "title": "Áô∫Ë¶ã: Disentinel/grafema - Graph-based static analysis tool",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Graph-based static analysis tool (‚≠ê7 | üç¥0)",
      "content": "Graph-based static analysis tool\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 7\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:19.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Disentinel/grafema",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1krguyfggpm34q",
      "title": "Áô∫Ë¶ã: ariannamethod/molecule - molecule.ai",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: molecule.ai (‚≠ê4 | üç¥0)",
      "content": "molecule.ai\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 4\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:19.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/ariannamethod/molecule",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1jqjx6ctolo25d",
      "title": "Áô∫Ë¶ã: StefanSevelda/claude-multi-agent.el - Emacs plugin for managing multiple Claude Code agents in parallel with git workt",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Emacs plugin for managing multiple Claude Code agents in parallel with git worktree isolation and vterm integration (‚≠ê1 | üç¥0)",
      "content": "Emacs plugin for managing multiple Claude Code agents in parallel with git worktree isolation and vterm integration\n\nË®ÄË™û: Emacs Lisp\n„Çπ„Çø„ÉºÊï∞: 1\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:18.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/StefanSevelda/claude-multi-agent.el",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1jqjsjglyb5gu1d",
      "title": "Áô∫Ë¶ã: tracymacding/starrocks-mcp-server - MCP Server for StarRocks database intelligent diagnostics and performance analys",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: MCP Server for StarRocks database intelligent diagnostics and performance analysis (‚≠ê2 | üç¥1)",
      "content": "MCP Server for StarRocks database intelligent diagnostics and performance analysis\n\nË®ÄË™û: JavaScript\n„Çπ„Çø„ÉºÊï∞: 2\n„Éï„Ç©„Éº„ÇØÊï∞: 1",
      "publishedAt": "2026-02-17T12:59:17.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/tracymacding/starrocks-mcp-server",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1krgp2az3qrroy",
      "title": "Áô∫Ë¶ã: ScrapeGraphAI/just-scrape -  CLI for AI-powered web scraping, data   extraction, search, and crawling  power",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã:  CLI for AI-powered web scraping, data   extraction, search, and crawling  powered   by the ScrapeGraph AI API. Supports smart   scraping, agentic browser automation,   markdownify, sitemap discovery, and JSON   mode for piping to AI agents. (‚≠ê5 | üç¥0)",
      "content": " CLI for AI-powered web scraping, data   extraction, search, and crawling  powered   by the ScrapeGraph AI API. Supports smart   scraping, agentic browser automation,   markdownify, sitemap discovery, and JSON   mode for piping to AI agents.\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 5\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:12.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/ScrapeGraphAI/just-scrape",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1krgf00vfm2ywo",
      "title": "Áô∫Ë¶ã: Srk-1974/AI_HR_APPLICATION_1STVERSION - AR HR APPLICATION FOR Resume, it support all llm ",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: AR HR APPLICATION FOR Resume, it support all llm  (‚≠ê1 | üç¥0)",
      "content": "AR HR APPLICATION FOR Resume, it support all llm \n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 1\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-17T12:59:11.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Srk-1974/AI_HR_APPLICATION_1STVERSION",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM",
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlqm1ltgmfxovwn4rp8",
      "title": "Anthropic: prompt-eng-interactive-tutorial„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "Anthropic's Interactive Prompt Engineering Tutorial„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê30116)",
      "content": "Anthropic's Interactive Prompt Engineering Tutorial\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/17/2026\n„Çπ„Çø„ÉºÊï∞: 30116",
      "publishedAt": "2026-02-17T12:57:44.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/prompt-eng-interactive-tutorial",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlqm1ltglioxhet1m0h",
      "title": "Anthropic: claude-cookbooks„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "A collection of notebooks/recipes showcasing some fun and effective ways of using Claude.„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê32977)",
      "content": "A collection of notebooks/recipes showcasing some fun and effective ways of using Claude.\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/17/2026\n„Çπ„Çø„ÉºÊï∞: 32977",
      "publishedAt": "2026-02-17T12:57:24.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/claude-cookbooks",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": true
    },
    {
      "id": "mlqm1ltg5sg2j1znvv7",
      "title": "Anthropic: skills„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "Public repository for Agent Skills„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê70876)",
      "content": "Public repository for Agent Skills\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/17/2026\n„Çπ„Çø„ÉºÊï∞: 70876",
      "publishedAt": "2026-02-17T12:56:56.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/skills",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [],
      "featured": true
    },
    {
      "id": "mlqm1ltgmm5qw604j5",
      "title": "Anthropic: claude-plugins-official„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "Official, Anthropic-managed directory of high quality Claude Code Plugins.„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê7545)",
      "content": "Official, Anthropic-managed directory of high quality Claude Code Plugins.\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/17/2026\n„Çπ„Çø„ÉºÊï∞: 7545",
      "publishedAt": "2026-02-17T12:52:47.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/claude-plugins-official",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlqm1ltgb0izyzjxpjm",
      "title": "Anthropic: claude-quickstarts„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "A collection of projects designed to help developers quickly get started with building deployable applications using the Claude API„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê14290)",
      "content": "A collection of projects designed to help developers quickly get started with building deployable applications using the Claude API\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/17/2026\n„Çπ„Çø„ÉºÊï∞: 14290",
      "publishedAt": "2026-02-17T12:52:22.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/claude-quickstarts",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": true
    },
    {
      "id": "mlqm1aycjvsb59hvjl",
      "title": "Anthropic: v2.1.44",
      "summary": "## What's changed\n\n- Fixed auth refresh errors\n...",
      "content": "## What's changed\n\n- Fixed auth refresh errors\n",
      "publishedAt": "2026-02-16T21:35:03.000Z",
      "source": "Anthropic GitHub",
      "sourceUrl": "https://github.com/anthropics/claude-code/releases/tag/v2.1.44",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [],
      "featured": false
    },
    {
      "id": "mlqm1hnsbehaah62w1i",
      "title": "Hugging Face: v5.2.0: GLM-5, Qwen3.5, Voxtral Realtime, VibeVoice Acoustic Tokenizer",
      "summary": "## New Model additions\r\n\r\n### VoxtralRealtime\r\n\r\n<img width=\"1920\" height=\"1080\" alt=\"image\" src=\"https://github.com/user-attachments/assets/80e37670-6d70-402b-8c8e-ccfb8c32df2d\" />\r\n\r\nVoxtralRealtime is a streaming speech-to-text model from [Mistral AI](https://mistral.ai), designed for real-time a...",
      "content": "## New Model additions\r\n\r\n### VoxtralRealtime\r\n\r\n<img width=\"1920\" height=\"1080\" alt=\"image\" src=\"https://github.com/user-attachments/assets/80e37670-6d70-402b-8c8e-ccfb8c32df2d\" />\r\n\r\nVoxtralRealtime is a streaming speech-to-text model from [Mistral AI](https://mistral.ai), designed for real-time automatic speech recognition (ASR). Unlike the offline [Voxtral](./voxtral) model which processes complete audio files, VoxtralRealtime is architected for low-latency, incremental transcription by processing audio in chunks as they arrive.\r\n\r\nThe model combines an audio encoder with a Mistral-based language model decoder, using time conditioning embeddings and causal convolutions with padding caches to enable efficient streaming inference.\r\n\r\n* Add Voxtral Realtime (#43769) by @eustlb\r\n\r\n### GLM-5 - GlmMoeDsa\r\n\r\n<img width=\"947\" height=\"638\" alt=\"image\" src=\"https://github.com/user-attachments/assets/4c4fff37-7f40-4e86-b4a0-db718f45c93b\" />\r\n\r\nThe zAI team launches GLM-5, and introduces it as such:\r\n\r\n> GLM-5, targeting complex systems engineering and long-horizon agentic tasks. Scaling is still one of the most important ways to improve the intelligence efficiency of Artificial General Intelligence (AGI). Compared to GLM-4.5, GLM-5 scales from 355B parameters (32B active) to 744B parameters (40B active), and increases pre-training data from 23T to 28.5T tokens. GLM-5 also integrates DeepSeek Sparse Attention (DSA), largely reducing deployment cost while preserving long-context capacity.\r\n> \r\n> Reinforcement learning aims to bridge the gap between competence and excellence in pre-trained models. However, deploying it at scale for LLMs is a challenge due to the RL training inefficiency. To this end, we developed [slime](https://github.com/THUDM/slime), a novel asynchronous RL infrastructure that substantially improves training throughput and efficiency, enabling more fine-grained post-training iterations. With advances in both pre-training and post-training, GLM-5 delivers significant improvement compared to GLM-4.7 across a wide range of academic benchmarks and achieves best-in-class performance among all open-source models in the world on reasoning, coding, and agentic tasks, closing the gap with frontier models.\r\n\r\n* Add GlmMoeDsa (#43858) by @Cyrilvallez\r\n\r\n### Qwen3.5, Qwen3.5 Moe\r\n\r\n<img width=\"1920\" height=\"1080\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b56dcaca-80e7-4b22-80a5-2f767bb65095\" />\r\n\r\nThe Qwen team launches Qwen 3.5, and introduces it as such:\r\n\r\n> We are delighted to announce the official release of Qwen3.5, introducing the open-weight of the first model in the Qwen3.5 series, namely Qwen3.5-397B-A17B. As a native vision-language model, Qwen3.5-397B-A17B demonstrates outstanding results across a full range of benchmark evaluations, including reasoning, coding, agent capabilities, and multimodal understanding, empowering developers and enterprises to achieve significantly greater productivity. Built on an innovative hybrid architecture that fuses linear attention (via Gated Delta Networks) with a sparse mixture-of-experts, the model attains remarkable inference efficiency: although it comprises 397 billion total parameters, just 17 billion are activated per forward pass, optimizing both speed and cost without sacrificing capability. We have also expanded our language and dialect support from 119 to 201, providing broader accessibility and enhanced support to users around the world.\r\n\r\n\r\n* Adding Support for Qwen3.5 (#43830) by @bozheng-hit\r\n\r\n### VibeVoice Acoustic Tokenizer\r\n\r\n<img width=\"821\" height=\"349\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b1433597-b43b-4d2d-a2c7-216d7792b8c9\" />\r\n\r\n[VibeVoice](https://huggingface.co/papers/2508.19205) is a novel framework for synthesizing high-fidelity, long-form speech with multiple speakers by employing a next-token diffusion approach within a Large Language Model (LLM) structure. It's designed to capture the authentic conversational \"vibe\" and is particularly suited for generating audio content like podcasts and multi-participant audiobooks.\r\n\r\nOne key feature of VibeVoice is the use of two continuous audio tokenizers, one for extracting acoustic features and another for semantic features.\r\n\r\n* Add VibeVoice Acoustic Tokenizer (#43400) by @ebezzam\r\n\r\n## Breaking changes\r\n\r\n* :rotating_light: [`Attn`] New attn mask interface everywhere (#42848)\r\n* :rotating_light: Modify ModernBERT's default attention implementation to stop using FA (#43764)\r\n\r\n## Bugfixes and improvements\r\n\r\n* [docs] deploying (#43241) by @stevhliu\r\n* [Trainer] Move NEFTune impl to standalone functions (#43714) by @SunMarc\r\n* Fix `convert_rope_params_to_dict` so it uses `rope_theta` from the config (#43766) by @hmellor\r\n* Bump dev version (#43777) by @qgallouedec\r\n* Improved `AGENTS.md` (#43763) by @tarekziade\r\n* Fix-release-ubild (#43773) by @ArthurZucker\r\n* unpin torch for CircleCI (#43790) by @ydshieh\r\n* [`Modular Dependencies`] Fixup qwen rms norms (#43772) by @vasqu\r\n* fix(testing): Fix BLOOM tokenizer, CLAP audio features, and CLVP text tester usage in tests (#43798) by @harshaljanjani\r\n* Remove unconditional train_batch_size assignment (#43770) by @lordaarush\r\n* [`Repo Consistency`] Fix rms norm (#43803) by @vasqu\r\n* fix: Prevent AutoTokenizer type mismatch from directory name substrin‚Ä¶ (#43791) by @tarekziade\r\n* Refactor trainer data_collator and callbacks tests (#43776) by @SunMarc\r\n* [core] Faster and thread-safe `check_model_inputs` implementation (#43765) by @Cyrilvallez\r\n* [Trainer] use deepspeed SP process group when Accelerate doesn‚Äôt build a mesh (#43799) by @kashif\r\n* fix(flaky): enforce manual seed to reduce flakiness (#43794) by @tarekziade\r\n* Add TRL CI bot workflow to trigger tests on PR comments (#43809) by @qgallouedec\r\n* Fix DeepSpeed model preparation logic in Trainer class (#43780) by @qgallouedec\r\n* [docs] reveal more in toctree (#43808) by @stevhliu\r\n* Fix markdown documentation (#43076) by @cyyever\r\n* Fix slack-report workflow file (#43851) by @ydshieh\r\n* add `do_sample=False` to qwen2_5_vl model tests to stablize the output (#43728) by @kaixuanliu\r\n* Fix incorrect timestamp calculation in Qwen3VL Processor (#43659) by @jonathan-fulton\r\n* Remove GPU tracking from TrackioCallback and remove env var support (#43371) by @qgallouedec\r\n* Add id and resume support to SwanLab integration (#43719) by @i-pj\r\n* fix gptoss crash in tp (#43853) by @sywangyi\r\n* Delete batch_split from EncoderDecoderCache (#43814) by @cyyever\r\n* delete unnecessary code to make moe compatible to full graph compile (#43855) by @kaixuanliu\r\n* Update ModelType for Unigram tokenizer (#43860) by @pavel-esir\r\n* [docs] Remove pipeline() examples from summarization/translation tasks (#43831) by @Mr-Neutr0n\r\n* Fix video interpolation in pe_audio_video (#43811) by @Rocketknight1\r\n* Look for the pad_token_id in the right place for Llama4 (#43539) by @Rocketknight1\r\n* Fix cardinality error for DETR models without explicit background class (#43513) by @heathdutton\r\n* docs: Add Switch Transformers docstring notes and update spectrogram comment (#43336) by @harshaljanjani\r\n* [xLSTM] Fix bugs preventing small model training (#43209) by @Anri-Lombard\r\n* docs: correct typo 'neccessary' to 'necessary' (#43868) by @thecaptain789\r\n* Improve PR comment CI feedback  (#43852) by @ydshieh\r\n* Fix init weights in remote code (#43768) by @zucchini-nlp\r\n* Fix GlmMoeDsaConfig default mlp_layer_types in modular conversion (#43876) by @OiPunk\r\n* [MistralCommonBackend] fix loading proc (#43887) by @eustlb\r\n* [`Jamba`] Fallback to slow path and warn instead of error out (#43889) by @vasqu\r\n* Fix SwanLab callback to forward resume init args (#43848) by @OiPunk\r\n* Fix old tech stack in doc (#43879) by @cyyever\r\n* Update TrainingArguments (#43806) by @SunMarc\r\n* Remove unnecessary code or checks for PT 2.4+ (#43787) by @cyyever\r\n* Make it possible to evaluate when using sequence parallel in HF Trainer (#43517) by @jp1924\r\n* [Trainer] Move optimizer cls init to trainer_optimizer.py (#43738) by @SunMarc\r\n* fix the error of tests/quantization/fbgemm_fp8/test_fbgemm_fp8.py::Fb‚Ä¶ (#43547) by @sywangyi\r\n* fix fbgemm fp8 multi-device load failure. (#43581) by @sywangyi\r\n* Refactor trainer init (#43807) by @SunMarc\r\n* [`fix`] Use `last_hidden_state` key from `get_image_features` for llama4 (#43882) by @tomaarsen\r\n* [Docs] Add docs for GLM-OCR and fix EomT-DINOv3 (#43710) by @NielsRogge\r\n* Update hub metadata (#43892) by @zucchini-nlp\r\n* [fix] DAC model: Apply STE in Dac.from_latents to match the forward pass (#43820) by @harshaljanjani\r\n* Separate `check_model_inputs` into `capture_outputs` and `merge_with_config_defaults` + ensure correctness (#43862) by @Cyrilvallez\r\n* Remove mask slicing in all eager attentions (#42186) by @Cyrilvallez\r\n* Fix expected DAC outputs due to (old) change in CI settings. (#43896) by @ebezzam\r\n* Minor changes trainer (#43744) by @SunMarc\r\n* adding BC for custom toks accessing slow tok attrs deprecated in v5 (#43898) by @itazap\r\n* Fix typo in quantization_operations in PEFT integrations (#43821) by @redpanda1995\r\n* Update KERNELS_MIN_VERSION to 0.10.2 to be the same as setup.py (#43753) by @cyyever\r\n* Decorate cache updates with no_grad, just in case (#43897) by @Rocketknight1\r\n* revert place_model_on_device to property (#43895) by @SunMarc\r\n* Train sampler unification (#43138) by @jiosephlee\r\n* fix(moe): Handle dtype mismatch in torch._grouped_mm with autocast (#43839) by @Mr-Neutr0n\r\n* Fix missing fast image patch counter in Glm46V (#43877) by @OiPunk\r\n* Fix old tech stack in doc (#43902) by @cyyever\r\n* Move `_keys_to_ignore_on_load_missing` for now (#43893) by @ArthurZucker\r\n* Changes to cache_utils should trigger all tests all the time (#43920) by @Cyrilvallez\r\n* Ernie4 5 vl moe (#43755) by @kaixuanliu\r\n* Harmonize `input_embeds` to `inputs_embeds` everywhere (#43916) by @Cyrilvallez\r\n* fix: TextClassificationPipeline docs mentioning deprecated return_all_scores (#43903) by @math-hiyoko\r\n* Revert #43897 (#43923) by @Rocketknight1\r\n* Fix AttributeError in OwlViT conversion script for Python 3.10+ (#43922) by @DimiChatzipavlis\r\n* add openAI style `image_url` content support in `apply_chat_template` (#43786) by @kaixuanliu\r\n* Prepare and keep track of position ids in `generate` (#43734) by @zucchini-nlp\r\n* Fix lifted_tensor in Gemma3n export which dynamo can't reason about (#43801) by @robell\r\n* Fix bark test (#43942) by @Cyrilvallez\r\n* Fix docker files (#43946) by @ydshieh\r\n* Fix flaky test for multimodal LLMs (#43944) by @Rocketknight1\r\n* Add explicit utf-8 encoding to CircleCI scripts for Windows compatibility (#43925) by @<NOT FOUND>\r\n* Modernize string formatting (f-strings) in conversion scripts (#43943) by @<NOT FOUND>\r\n* Fix weight decay exclusions in `run_*_no‚Äëtrainer.py` examples (#42769) by @casinca\r\n* fix: Better weight decay exclusion in `run_*_no‚Äëtrainer.py` examples (#43947) by @casinca\r\n* Timm backbone saves and loads `out_features` (#43886) by @zucchini-nlp\r\n* Fix qwen-vl position ids when generating several times (#43952) by @zucchini-nlp\r\n* Fix `get_number_of_image_tokens` (#43948) by @zucchini-nlp\r\n* Fix typos in docstrings, comments, and error messages (#43949) by @<NOT FOUND>\r\n* Fix LASR test layerdrop issue (#43954) by @Rocketknight1\r\n* [kernels] fix kernel versions  (#43955) by @MekkCyber\r\n* [Doc tests] Fix bug (#43729) by @NielsRogge\r\n* fix(models): Preserve custom token IDs through DiaConfig save and load (#43928) by @harshaljanjani\r\n* update somes audio models (#43865) by @Deep-unlearning\r\n* Improve memory allocator during loading (#43945) by @Cyrilvallez\r\n* Inclusion of process_group in the gather_full_tensor function in tensor_parallel.py (#43932) by @quic-meetkuma\r\n* Fix sync gradient (#43919) by @SunMarc\r\n* Reorder Trainer methods (#43914) by @SunMarc\r\n* Fix TypeError in dot_natural_key when state_dict keys have mixed types at same position (#43966) by @shtse8\r\n* Enhance JSON schema generation to support instance, static, and class methods (#43968) by @qgallouedec\r\n* Remove unused squeeze from VJEPA2 embeddings rotation (#43984) by @materight\r\n* Improve new failing test analysis for PR comment CI (#44033) by @ydshieh\r\n* Remove `other_workflow_run_ids` for `issue_comment` in `utils/notification_service.py` (#44036) by @ydshieh\r\n* stable grouped_mm API (#43977) by @IlyasMoutawwakil\r\n* create .git-blame-ignore-revs file  (#43982) by @SunMarc\r\n* docs: fix typos across documentation files (#43993) by @saurav0369\r\n* update python requirement to 3.10+ to match codebase (#44009) by @mariam851\r\n* Improve use of torch.is_autocast_enabled (#43930) by @cyyever\r\n* Use torch.xlogy  (#44006) by @cyyever\r\n* [Deespeed] fix WeightConverter.convert() use (#43926) by @kashif\r\n* Reduce reduce CUDA sync (#44005) by @cyyever\r\n* split out accelerator args builder method (#43987) by @winglian\r\n* SINQ quantization strategy integration (adapted for Transformers V5) (#43112) by @ChiaraBoretti\r\n* fix(models): Unpack BitNet packed weights to fix CI failure (#43721) by @harshaljanjani\r\n\r\n## Significant community contributions\r\n\r\nThe following contributors have made significant changes to the library over the last release:\r\n\r\n* @ChiaraBoretti\r\n    * SINQ quantization strategy integration (adapted for Transformers V5) (#43112)\r\n* @cyyever\r\n    * Reduce reduce CUDA sync (#44005)\r\n    * Use torch.xlogy  (#44006)\r\n    * Improve use of torch.is_autocast_enabled (#43930)\r\n    * Fix old tech stack in doc (#43902)\r\n    * Update KERNELS_MIN_VERSION to 0.10.2 to be the same as setup.py (#43753)\r\n    * Remove unnecessary code or checks for PT 2.4+ (#43787)\r\n    * Fix old tech stack in doc (#43879)\r\n    * Delete batch_split from EncoderDecoderCache (#43814)\r\n    * Fix markdown documentation (#43076)\r\n* @eustlb\r\n    * Add Voxtral Realtime (#43769)\r\n    * [MistralCommonBackend] fix loading proc (#43887)\r\n* @ebezzam\r\n    * Fix expected DAC outputs due to (old) change in CI settings. (#43896)\r\n    * Add VibeVoice Acoustic Tokenizer (#43400)\r\n* @vasqu\r\n    * [`Jamba`] Fallback to slow path and warn instead of error out (#43889)\r\n    * :rotating_light: [`Attn`] New attn mask interface everywhere (#42848)\r\n    * [`Repo Consistency`] Fix rms norm (#43803)\r\n    * [`Modular Dependencies`] Fixup qwen rms norms (#43772)\r\n* @bozheng-hit\r\n    * Adding Support for Qwen3.5 (#43830)\r\n",
      "publishedAt": "2026-02-16T18:55:53.000Z",
      "source": "Hugging Face GitHub",
      "sourceUrl": "https://github.com/huggingface/transformers/releases/tag/v5.2.0",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "GPT",
        "Llama",
        "LLM",
        "AI",
        "ML"
      ],
      "featured": false
    },
    {
      "id": "mlqm1fr68me8lyj24ev",
      "title": "Google: Release v0.29.0-preview.3",
      "summary": "## What's Changed\n* fix(patch): cherry-pick d0c6a56 to release/v0.29.0-preview.2-pr-18976 to patch version v0.29.0-preview.2 and create version 0.29.0-preview.3 by @gemini-cli-robot in https://github.com/google-gemini/gemini-cli/pull/19023\n\n\n**Full Changelog**: https://github.com/google-gemini/gemin...",
      "content": "## What's Changed\n* fix(patch): cherry-pick d0c6a56 to release/v0.29.0-preview.2-pr-18976 to patch version v0.29.0-preview.2 and create version 0.29.0-preview.3 by @gemini-cli-robot in https://github.com/google-gemini/gemini-cli/pull/19023\n\n\n**Full Changelog**: https://github.com/google-gemini/gemini-cli/compare/v0.29.0-preview.2...v0.29.0-preview.3",
      "publishedAt": "2026-02-13T22:17:33.000Z",
      "source": "Google GitHub",
      "sourceUrl": "https://github.com/google-gemini/gemini-cli/releases/tag/v0.29.0-preview.3",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlqm1aychutntx750ps",
      "title": "Anthropic: v2.1.42",
      "summary": "## What's changed\n\n- Fixed /resume showing interrupt messages as session titles\n- Fixed Opus 4.6 launch announcement showing for Bedrock/Vertex/Foundry users\n- Improved error message for many-image dimension limit errors with /compact suggestion\n...",
      "content": "## What's changed\n\n- Fixed /resume showing interrupt messages as session titles\n- Fixed Opus 4.6 launch announcement showing for Bedrock/Vertex/Foundry users\n- Improved error message for many-image dimension limit errors with /compact suggestion\n",
      "publishedAt": "2026-02-13T19:56:33.000Z",
      "source": "Anthropic GitHub",
      "sourceUrl": "https://github.com/anthropics/claude-code/releases/tag/v2.1.42",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [],
      "featured": false
    },
    {
      "id": "mlqm1dty3g1wyy2p85o",
      "title": "OpenAI: openai-cookbook„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "openai-cookbook„É™„Éù„Ç∏„Éà„É™„Å´Êñ∞„Åó„ÅÑÊõ¥Êñ∞: Add Realtime Eval Harness Code section to the guide with links to ref‚Ä¶ (#2427)...",
      "content": "Add Realtime Eval Harness Code section to the guide with links to ref‚Ä¶ (#2427)",
      "publishedAt": "2026-02-13T15:59:18.000Z",
      "source": "OpenAI GitHub",
      "sourceUrl": "https://github.com/openai/openai-cookbook",
      "category": "tools",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "AI",
        "OpenAI"
      ],
      "featured": false
    },
    {
      "id": "mlqm1fr6virazqecp7",
      "title": "Google: Release v0.30.0-nightly.20260212.207ac6f2d",
      "summary": "## What's Changed\n* Show notification when there's a conflict with an extensions command by @chrstnb in https://github.com/google-gemini/gemini-cli/pull/17890\n* fix(cli): dismiss '?' shortcuts help on hotkeys and active states by @LyalinDotCom in https://github.com/google-gemini/gemini-cli/pull/1858...",
      "content": "## What's Changed\n* Show notification when there's a conflict with an extensions command by @chrstnb in https://github.com/google-gemini/gemini-cli/pull/17890\n* fix(cli): dismiss '?' shortcuts help on hotkeys and active states by @LyalinDotCom in https://github.com/google-gemini/gemini-cli/pull/18583\n* fix(core): prioritize conditional policy rules and harden Plan Mode by @Abhijit-2592 in https://github.com/google-gemini/gemini-cli/pull/18882\n* feat(core): refine Plan Mode system prompt for agentic execution by @NTaylorMullen in https://github.com/google-gemini/gemini-cli/pull/18799\n* feat(plan): create metrics for usage of `AskUser` tool by @Adib234 in https://github.com/google-gemini/gemini-cli/pull/18820\n* feat(cli): support Ctrl-Z suspension by @scidomino in https://github.com/google-gemini/gemini-cli/pull/18931\n* fix(github-actions): use robot PAT for release creation to trigger release notes by @SandyTao520 in https://github.com/google-gemini/gemini-cli/pull/18794\n* feat: add strict seatbelt profiles and remove unusable closed profiles by @SandyTao520 in https://github.com/google-gemini/gemini-cli/pull/18876\n* chore: cleanup unused and add unlisted dependencies in packages/a2a-server by @adamfweidman in https://github.com/google-gemini/gemini-cli/pull/18916\n* fix(plan): isolate plan files per session by @Adib234 in https://github.com/google-gemini/gemini-cli/pull/18757\n* fix: character truncation in raw markdown mode by @jackwotherspoon in https://github.com/google-gemini/gemini-cli/pull/18938\n* feat(cli): prototype clean UI toggle and minimal-mode bleed-through by @LyalinDotCom in https://github.com/google-gemini/gemini-cli/pull/18683\n* ui(polish) blend background color with theme by @jacob314 in https://github.com/google-gemini/gemini-cli/pull/18802\n\n\n**Full Changelog**: https://github.com/google-gemini/gemini-cli/compare/v0.30.0-nightly.20260212.099aa9621...v0.30.0-nightly.20260212.207ac6f2d",
      "publishedAt": "2026-02-12T20:39:17.000Z",
      "source": "Google GitHub",
      "sourceUrl": "https://github.com/google-gemini/gemini-cli/releases/tag/v0.30.0-nightly.20260212.207ac6f2d",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "Google"
      ],
      "featured": true
    },
    {
      "id": "mlqm1etlddzaa1soblq",
      "title": "Google: cookbook„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "cookbook„É™„Éù„Ç∏„Éà„É™„Å´Êñ∞„Åó„ÅÑÊõ¥Êñ∞: Reorganize and update .gitignore entriesOnly ignoring python files at root level...",
      "content": "Reorganize and update .gitignore entriesOnly ignoring python files at root level",
      "publishedAt": "2026-02-10T16:17:29.000Z",
      "source": "Google GitHub",
      "sourceUrl": "https://github.com/google-gemini/cookbook",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [],
      "featured": false
    },
    {
      "id": "mlqm1a1yr73qtusltpi",
      "title": "Anthropic: v0.79.0",
      "summary": "## 0.79.0 (2026-02-07)\n\nFull Changelog: [v0.78.0...v0.79.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.78.0...v0.79.0)\n\n### Features\n\n* **api:** enabling fast-mode in claude-opus-4-6 ([5953ba7](https://github.com/anthropics/anthropic-sdk-python/commit/5953ba7b425ba113595de570bc8c6...",
      "content": "## 0.79.0 (2026-02-07)\n\nFull Changelog: [v0.78.0...v0.79.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.78.0...v0.79.0)\n\n### Features\n\n* **api:** enabling fast-mode in claude-opus-4-6 ([5953ba7](https://github.com/anthropics/anthropic-sdk-python/commit/5953ba7b425ba113595de570bc8c639ff4dc4047))\n\n\n### Bug Fixes\n\n* pass speed parameter through in sync beta count_tokens ([1dd6119](https://github.com/anthropics/anthropic-sdk-python/commit/1dd6119daca6de7a6eb730eb2494f368889ea050))",
      "publishedAt": "2026-02-07T18:05:51.000Z",
      "source": "Anthropic GitHub",
      "sourceUrl": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.79.0",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "Anthropic"
      ],
      "featured": false
    },
    {
      "id": "mlqm1a1yzag6clb13pk",
      "title": "Anthropic: v0.78.0",
      "summary": "## 0.78.0 (2026-02-05)\n\nFull Changelog: [v0.77.1...v0.78.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.77.1...v0.78.0)\n\n### Features\n\n* **api:** Release Claude Opus 4.6, adaptive thinking, and other features ([3ef1529](https://github.com/anthropics/anthropic-sdk-python/commit/3ef1...",
      "content": "## 0.78.0 (2026-02-05)\n\nFull Changelog: [v0.77.1...v0.78.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.77.1...v0.78.0)\n\n### Features\n\n* **api:** Release Claude Opus 4.6, adaptive thinking, and other features ([3ef1529](https://github.com/anthropics/anthropic-sdk-python/commit/3ef1529b45c55645646cc6043784f999fda088de))",
      "publishedAt": "2026-02-05T17:51:33.000Z",
      "source": "Anthropic GitHub",
      "sourceUrl": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.78.0",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlqm1hnt6dazbbyemnn",
      "title": "Hugging Face: v5.1.0: EXAONE-MoE, PP-DocLayoutV3, Youtu-LLM, GLM-OCR",
      "summary": "## New Model additions\r\n\r\n### EXAONE-MoE\r\n\r\n<img width=\"2278\" height=\"1142\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0c3d5341-0483-49c3-8467-f9784ec94b37\" />\r\n\r\nK-EXAONE is a large-scale multilingual language model developed by LG AI Research. Built using a Mixture-of-Experts arch...",
      "content": "## New Model additions\r\n\r\n### EXAONE-MoE\r\n\r\n<img width=\"2278\" height=\"1142\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0c3d5341-0483-49c3-8467-f9784ec94b37\" />\r\n\r\nK-EXAONE is a large-scale multilingual language model developed by LG AI Research. Built using a Mixture-of-Experts architecture, K-EXAONE features 236 billion total parameters, with 23 billion active during inference. Performance evaluations across various benchmarks demonstrate that K-EXAONE excels in reasoning, agentic capabilities, general knowledge, multilingual understanding, and long-context processing.\r\n\r\n* Add EXAONE-MoE implementations (#43080) by @nuxlear\r\n\r\n### PP-DocLayoutV3\r\n\r\n<img width=\"6252\" height=\"1892\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b2e58244-8ed3-42c6-80d7-e32842977ddb\" />\r\n\r\n**PP-DocLayoutV3** is a unified and high-efficiency model designed for comprehensive layout analysis. It addresses the challenges of complex physical distortions‚Äîsuch as skewing, curving, and adverse lighting‚Äîby integrating instance segmentation and reading order prediction into a single, end-to-end framework.\r\n\r\n* [Model] Add PP-DocLayoutV3 Model Support (#43098) by @zhang-prog\r\n\r\n### Youtu-LLM\r\n\r\n<img width=\"564\" height=\"352\" alt=\"image\" src=\"https://github.com/user-attachments/assets/864372be-4ecb-41fd-8c92-f3515be040d3\" />\r\n\r\nYoutu-LLM is a new, small, yet powerful LLM, contains only 1.96B parameters, supports 128k long context, and has native agentic talents. On general evaluations, Youtu-LLM significantly outperforms SOTA LLMs of similar size in terms of Commonsense, STEM, Coding and Long Context capabilities; in agent-related testing, Youtu-LLM surpasses larger-sized leaders and is truly capable of completing multiple end2end agent tasks. \r\n\r\n  * Add Youtu-LLM model (#43166) by @LuJunru\r\n\r\n### GlmOcr\r\n\r\n<img width=\"3972\" height=\"2352\" alt=\"image\" src=\"https://github.com/user-attachments/assets/a7ddfb4f-42ea-4dc6-bc73-aefb0f750c4e\" />\r\n\r\nGLM-OCR is a multimodal OCR model for complex document understanding, built on the GLM-V encoder‚Äìdecoder architecture. It introduces Multi-Token Prediction (MTP) loss and stable full-task reinforcement learning to improve training efficiency, recognition accuracy, and generalization. The model integrates the CogViT visual encoder pre-trained on large-scale image‚Äìtext data, a lightweight cross-modal connector with efficient token downsampling, and a GLM-0.5B language decoder. Combined with a two-stage pipeline of layout analysis and parallel recognition based on PP-DocLayout-V3, GLM-OCR delivers robust and high-quality OCR performance across diverse document layouts.\r\n\r\n* [GLM-OCR] GLM-OCR Support (#43391)by @zRzRzRzRzRzRzR\r\n\r\n## Breaking changes\r\n\r\n* üö® T5Gemma2 model structure (#43633) - Makes sure that the attn implementation is set to all sub-configs. The config.encoder.text_config was not getting its attn set because we aren't passing it to PreTrainedModel.__init__. We can't change the model structure without breaking so I manually re-added a call to self.adjust_attn_implemetation in modeling code\r\n\r\n* üö® Generation cache preparation (#43679) - Refactors cache initialization in generation to ensure sliding window configurations are now properly respected. Previously, some models (like Afmoe) created caches without passing the model config, causing sliding window limits to be ignored. This is breaking because models with sliding window attention will now enforce their window size limits during generation, which may change generation behavior or require adjusting sequence lengths in existing code.\r\n\r\n* üö® Delete duplicate code in backbone utils (#43323) - This PR cleans up backbone utilities. Specifically, we have currently 5 different config attr to decide which backbone to load, most of which can be merged into one and seem redundant\r\nAfter this PR, we'll have only one config.backbone_config as a single source of truth. The models will load the backbone from_config and load pretrained weights only if the checkpoint has any weights saved. The overall idea is same as in other composite models. A few config arguments are removed as a result.\r\n\r\n* üö® Refactor DETR to updated standards (#41549) - standardizes the DETR model to be closer to other vision models in the library.\r\n\r\n* üö®Fix floating-point precision in JanusImageProcessor resize (#43187) - replaces an `int()` with `round()`, expect light numerical differences \r\n\r\n* üö® Remove deprecated AnnotionFormat (#42983) - removes a missnamed class in favour of `AnnotationFormat`. \r\n\r\n## Bugfixes and improvements\r\n\r\n* fix(models): Migrate legacy segmentation_indices to out_indices in BeitConfig (#43505) by @harshaljanjani\r\n* [docs] Update torch version (#42135) by @stevhliu\r\n* Remove SDPA workarounds for torch 2.4+ (#43754) by @cyyever\r\n* add use_deterministic to guarantee the consistency for youtu-llm model (#43759) by @kaixuanliu\r\n* fix: add compatible_model_types to suppress model type mismatch warnings (#43495) by @leoneperdigao\r\n* Fix T5 v1.1 detection (#43681) by @githubnemo\r\n* Add moonshine streaming (#43702) by @eustlb\r\n* Allow bi-directional attention for all models (#43705) by @Cyrilvallez\r\n* Docs: fix Training step by removing tokenizer from trainer initialization (#43733) by @nesjett\r\n* Fix scheduler initialization order (#43711) by @SunMarc\r\n* Fix accelerate integration import  (#43732) by @SunMarc\r\n* Update torch minimum version to 2.4 (#41307) by @cyyever\r\n* Fix dtype in image-text-to-text pipe (#43731) by @zucchini-nlp\r\n* Preventing initialization of siglip's lecun_normal_, default_flax_embed_init in ZeRO3 (#43574) by @jp1924\r\n* fix: AttributeError for Qwen3_omni_moe (#43593) by @Vallabh-1504\r\n* Improve typing/explanations for general model properties (#43712) by @Cyrilvallez\r\n* [Kernels] kernel migration updates for activation kernels (#43518) by @ariG23498\r\n* [`feat`] Allow loading T5Gemma2Encoder with AutoModel (#43559) by @tomaarsen\r\n* Added S110 - try-except-pass rule (#43687) by @tarekziade\r\n* [docs] benchmarks (#43694) by @stevhliu\r\n* fix norm_eps dtype (#43669) by @fschlatt\r\n* Llava onevision: output align for tests and add `image_sizes` input param (#43678) by @kaixuanliu\r\n* Fix CLIPOutput attentions not being returned (#43657) by @jonathan-fulton\r\n* [`Attn`] Fixup interface usage after refactor (#43706) by @vasqu\r\n* Fix model/processor mismatch in SigLIP2 quantization example (#43652) by @jonathan-fulton\r\n* Fix crash of custom models in Notebook or Repl (#43690) by @Cyrilvallez\r\n* Simplify TrainingArguments docstring (#43568) by @SunMarc\r\n* Composite model inherit automatically all important properties from their children (#43691) by @Cyrilvallez\r\n* Update configuration_qwen3.py (#43703) by @francesco-bertolotti\r\n* fix gptoss tp crash (#43695) by @sywangyi\r\n* [CB] Keep order of incoming requests (#43626) by @remi-or\r\n* Fix Apertus model loading (NotImplementedError: Cannot copy out of meta tensor; no data!) (#43473) by @xenova\r\n* Remove `num_frames` in ASR pipeline (#43546) by @jiqing-feng\r\n* remove ipex and ccl for xpu and cpu (#42852) by @yao-matrix\r\n* update guide with new attr name for toks (#43689) by @itazap\r\n* Docs: fix typos in Get started (index, quicktour) (#43666) by @CodeByKodi\r\n* the cache class is deprecated by @vasqu (direct commit on main)\r\n* custom tok init fix (#43591) by @itazap\r\n* More export friendly rewrites and skipping the failing ones (#43436) by @IlyasMoutawwakil\r\n* Cast byte_count to int in caching_allocator_warmup for MPS compatibility (#43608) by @tobyliu2004\r\n* [Docs] Complete missing Llama4 configuration docs (#43460) by @udaymehta\r\n* Fix t5 failures (#43374) by @Abdennacer-Badaoui\r\n* Add EoMT with DINOv3 backbone (#41212) by @NielsRogge\r\n* Update DBRX docs to reference re-uploaded checkpoint (#43196) by @qgallouedec\r\n* [loading] Fix forced upcasting to fp32 (#43683) by @Cyrilvallez\r\n* Fix FP8Expert for Qwen (#43670) by @yiliu30\r\n* Simplify loading structure (#43589) by @Cyrilvallez\r\n* [CB] Refactor logic for inputs and outputs outside of the main API (#43569) by @remi-or\r\n* Make sure hub errors are surfaced in `PreTrainedTokenizerBase` (#43675) by @tarekziade\r\n* Fix `FP8Expert` for DeepSeek R1 (#43616) by @yiliu30\r\n* Use correct sampling rate in chat template (#43674) by @zucchini-nlp\r\n* [`HunYuan`] Fix RoPE init (#43411) by @vasqu\r\n* XPU now supports MoE kernel(MegaBlocks) implementation (#43435) by @YangKai0616\r\n* [`Sam`] Fixup training flags (#43567) by @vasqu\r\n* remove torchao.autoquant from transformers (#43561) by @vkuzo\r\n* [DeepSpeed] properly handle MoE weight conversion (#43524) by @kashif\r\n* Tie zamba weights correctly (#43623) by @zucchini-nlp\r\n* [kernels] Centralize kernels tests (#42819) by @MekkCyber\r\n* Fix `process_bad_commit_report.py`: avoid items to appear in `null` author in the report (#43662) by @ydshieh\r\n* Fix `KeyError` in `check_bad_commit.py` (#43655) by @ydshieh\r\n* [Benchmark] Minor fix for benchmark: kernel is not correctly called (#43428) by @sywangyi\r\n* Add explicit commit info to PR comment CI feedback  (#43635) by @ydshieh\r\n* Better new failures reporting for PR comment CI (#43629) by @ydshieh\r\n* [docs] serving (#42853) by @stevhliu\r\n* add XPU expected output for MixedInt8GPT2Test (#43615) by @kaixuanliu\r\n* Don't modify mappings in tests (#43634) by @Rocketknight1\r\n* Allow Attention and Experts to be used as standalone modules (#43622) by @Cyrilvallez\r\n* Don't modify `tied_weight_keys` in-place (#43619) by @zucchini-nlp\r\n* [`Rope`] Revert #43410 and make inheritance implicit again (#43620) by @vasqu\r\n* [vllm compat] Separate renaming from conversion ops (#43621) by @Cyrilvallez\r\n* refactor + robusts tests for Tensor Parallel  (#42809) by @3outeille\r\n* add contiguous operation for diffllama model for xpu to enable compile mode. (#43614) by @kaixuanliu\r\n* add xpu expectation for lw_detr model (#43339) by @kaixuanliu\r\n* minimax_m2: fix failed test case for XPU (#43324) by @kaixuanliu\r\n* Improve new failures reporting (#43628) by @ydshieh\r\n* Fix extras on all supported Python versions (#43490) by @tarekziade\r\n* fix(models): Fix suno/bark-small CPU offload device mismatch causing CI failures (#43607) by @harshaljanjani\r\n* [CB] [Serve] Fix broken serve tests (#43594) by @remi-or\r\n* Docs: fix typo in weight converter guide (#43610) by @KOKOSde\r\n* [MoE] Use int input for histc on CUDA to support deterministic algorithms (#43583) by @YangKai0616\r\n* Fixes configuration default values (#43592) by @zucchini-nlp\r\n* Fix `make_batched_video` with 5D arrays (#43486) by @zucchini-nlp\r\n* Operation Green CI II (#43537) by @Rocketknight1\r\n* enable cpu paged cache (#42869) by @jiqing-feng\r\n* Qwen3 omni - fix get video features (#43588) by @zucchini-nlp\r\n* [GLM-Image] Add batch > 1 support and fix configuration defaults (#43342) by @JaredforReal\r\n* [Model] Refactor modernbert with the attention interface (#43030) by @YangKai0616\r\n* Regex post processing in loading (#43585) by @Cyrilvallez\r\n* simplify extra tokens logic in base (#43230) by @itazap\r\n* Add XPU support to the tests for solar_open (#43579) by @YangKai0616\r\n* remove FbgemmFp8LinearTest (#43545) by @sywangyi\r\n* Increase default ReadTimeout in tests (#43586) by @Wauplin\r\n* Fix mistral checkpoint loading in `utils/fetch_hub_objects_for_ci.py`: avoid too many requests and/or timeout (#43584) by @ydshieh\r\n* [CI][AMD] Fix Pipeline CI  (#43178) by @Abdennacer-Badaoui\r\n* fix(converter): speed up `MistralConverter.extract_vocab_merges_from_model` (#43557) by @tarekziade\r\n* Improve GPU monitoring: switch to multiprocessing and use amdsmi for AMD GPUs (#43552) by @Abdennacer-Badaoui\r\n* Update test of Youtu-LLM to pr-aligned repos (#43578) by @LuJunru\r\n* Rework dependencies and extras + Remove outdated `templates` folder (#43536) by @Cyrilvallez\r\n* Fix repo. consistency bot (push permission issue) (#43570) by @ydshieh\r\n* Fix Wav2vec and a few others (#43566) by @Cyrilvallez\r\n* [`Modular`] Allow to add new bases that are not present in the inherited class (#43556) by @vasqu\r\n* add an option to disable Sam3VideoModel progress bar (#43564) by @ndeybach\r\n* check/fix repo. check bot workflow (#43565) by @ydshieh\r\n* Increase timeout when preparing CI (#43560) by @Rocketknight1\r\n* 43054: Add Siglip2Tokenizer to enforce training-time text preprocessing defaults (#43101) by @vaibhav-research\r\n* check PR bot permission - part 3 (try content attribute) (#43555) by @ydshieh\r\n* check PR bot permission - part 2 (style only) (#43554) by @ydshieh\r\n* check PR bot permission - part 1 (#43553) by @ydshieh\r\n* Fix failing tests due to no attribute `pad_token_id` (#43453) by @Sai-Suraj-27\r\n* fix: GPT OSS Conversion Script Enhancements (#42901) by @KyleMylonakisProtopia\r\n* [Quantization] Fix triton_kernels name after being renamed to gpt-oss-triton-kernels (#43528) by @MekkCyber\r\n* [Quantization] Add cutlass kernel for FP8 (#43304) by @MekkCyber\r\n* [CB] Minor perf improvements and ty compatibility (#43521) by @remi-or\r\n* Fix tiles mixing for batched input, add tie_word_embeddings to LFM2VL config (#43379) by @ankke\r\n* fix: return labels instead of label in reduce_label method in BeitImageProcessorFast (#43527) by @sbucaille\r\n* [`RoPE`] Make explicit inheritance (#43410) by @vasqu\r\n* Fix for #43530 (#43535) by @Rocketknight1\r\n* Operation Green CI (#43530) by @Rocketknight1\r\n* Tie the weights even if initializing from a config on meta device (#43523) by @Cyrilvallez\r\n* [kernels] Update cv_utils name (#43529) by @MekkCyber\r\n* add trackio to training notebooks (#43442) by @merveenoyan\r\n* Mark test_prompt_lookup_decoding as flaky (#42184) by @Rocketknight1\r\n* Fix some MoE routers (#43445) by @IlyasMoutawwakil\r\n* batched_mm is slow on cpu (#43438) by @IlyasMoutawwakil\r\n* fix: initialize BatchNorm2d buffers only when needed (#43520) by @tarekziade\r\n* Fix loading of Qwen3 FP8 (#43494) by @githubnemo\r\n* fix `ShieldGemma2IntegrationTest::test_model` (#43343) by @sywangyi\r\n* Update `SamHQModelIntegrationTest::test_inference_mask_generation_batched_points_batched_images` for `XPU` (#43511) by @sywangyi\r\n* Revert utils files changes from PR #42845 (#43507) by @ydshieh\r\n* Move hardcoded time_step params to config for Bamba, FalconH1, GraniteMoeHybrid (#43461) by @raimbekovm\r\n* Prepare inputs for generation is called from `super()` (#43280) by @zucchini-nlp\r\n* Enhance repo. consistency bot (#43503) by @ydshieh\r\n* Add `pytest-random-order` for reproducible test randomization (#43483) by @tarekziade\r\n* Add missing GPURawMetrics.from_dict() method in benchmark_v2 (#43499) by @Abdennacer-Badaoui\r\n* push dev version 5.0.1.dev0 by @ArthurZucker (direct commit on main)\r\n* Fix failing `markuplm` & `perception_lm` integration tests (#43464) by @Sai-Suraj-27\r\n* fix(Phi4Multimodal): Fix incorrect default vision/audio config initialization in Phi4MultimodalConfig (#43480) by @charlieJ107\r\n* handle 1D position_ids for modeling_flash_attention_utils as well (#43403) by @kaixuanliu\r\n* Remove stale TODO comments in UDOP tied weights (#43477) by @raimbekovm\r\n* Fix Mxfp4 dequantize (#43326) by @Cyrilvallez\r\n\r\n## Significant community contributions\r\n\r\nThe following contributors have made significant changes to the library over the last release:\r\n\r\n* @cyyever\r\n    * Remove SDPA workarounds for torch 2.4+ (#43754)\r\n    * Update torch minimum version to 2.4 (#41307)\r\n    * üö® Remove deprecated AnnotionFormat (#42983)\r\n* @eustlb\r\n    * Add moonshine streaming (#43702)\r\n* @tarekziade\r\n    * Added S110 - try-except-pass rule (#43687)\r\n    * Make sure hub errors are surfaced in `PreTrainedTokenizerBase` (#43675)\r\n    * Fix extras on all supported Python versions (#43490)\r\n    * fix(converter): speed up `MistralConverter.extract_vocab_merges_from_model` (#43557)\r\n    * fix: initialize BatchNorm2d buffers only when needed (#43520)\r\n    * Add `pytest-random-order` for reproducible test randomization (#43483)\r\n* @nuxlear\r\n    * Add EXAONE-MoE implementations (#43080)\r\n* @vasqu\r\n    * [`Attn`] Fixup interface usage after refactor (#43706)\r\n    * the cache class is deprecated\r\n    * [`HunYuan`] Fix RoPE init (#43411)\r\n    * [`Sam`] Fixup training flags (#43567)\r\n    * [`Rope`] Revert #43410 and make inheritance implicit again (#43620)\r\n    * [`Modular`] Allow to add new bases that are not present in the inherited class (#43556)\r\n    * [`RoPE`] Make explicit inheritance (#43410)\r\n* @remi-or\r\n    * [CB] Keep order of incoming requests (#43626)\r\n    * [CB] Refactor logic for inputs and outputs outside of the main API (#43569)\r\n    * [CB] [Serve] Fix broken serve tests (#43594)\r\n    * [CB] Minor perf improvements and ty compatibility (#43521)\r\n* @NielsRogge\r\n    * Add EoMT with DINOv3 backbone (#41212)\r\n* @YangKai0616\r\n    * XPU now supports MoE kernel(MegaBlocks) implementation (#43435)\r\n    * [MoE] Use int input for histc on CUDA to support deterministic algorithms (#43583)\r\n    * [Model] Refactor modernbert with the attention interface (#43030)\r\n    * Add XPU support to the tests for solar_open (#43579)\r\n* @ydshieh\r\n    * Fix `process_bad_commit_report.py`: avoid items to appear in `null` author in the report (#43662)\r\n    * Fix `KeyError` in `check_bad_commit.py` (#43655)\r\n    * Add explicit commit info to PR comment CI feedback  (#43635)\r\n    * Better new failures reporting for PR comment CI (#43629)\r\n    * Improve new failures reporting (#43628)\r\n    * Fix mistral checkpoint loading in `utils/fetch_hub_objects_for_ci.py`: avoid too many requests and/or timeout (#43584)\r\n    * Fix repo. consistency bot (push permission issue) (#43570)\r\n    * check/fix repo. check bot workflow (#43565)\r\n    * check PR bot permission - part 3 (try content attribute) (#43555)\r\n    * check PR bot permission - part 2 (style only) (#43554)\r\n    * check PR bot permission - part 1 (#43553)\r\n    * Revert utils files changes from PR #42845 (#43507)\r\n    * Enhance repo. consistency bot (#43503)\r\n* @JaredforReal\r\n    * [GLM-Image] Add batch > 1 support and fix configuration defaults (#43342)\r\n* @zhang-prog\r\n    * [Model] Add PP-DocLayoutV3 Model Support (#43098)\r\n* @LuJunru\r\n    * Update test of Youtu-LLM to pr-aligned repos (#43578)\r\n    * Add Youtu-LLM model (#43166)\r\n* @zRzRzRzRzRzRzR\r\n    * [GLM-OCR] GLM-OCR Support (#43391)",
      "publishedAt": "2026-02-05T15:44:54.000Z",
      "source": "Hugging Face GitHub",
      "sourceUrl": "https://github.com/huggingface/transformers/releases/tag/v5.1.0",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "GPT",
        "Llama",
        "LLM",
        "AI",
        "Transformer"
      ],
      "featured": false
    },
    {
      "id": "mlqm1r0ja8gstx2yo3f",
      "title": "Show HN: BrowserOS ‚Äì \"Claude Cowork\" in the browser",
      "summary": "Hey HN! We&#x27;re Nithin and Nikhil, twin brothers building BrowserOS (YC S24). We&#x27;re an open-source, privacy-first alternative to the AI browsers from big labs.<p>The big differentiator: on BrowserOS you can use local LLMs or BYOK and run the agent entirely on the client side, so your company...",
      "content": "Hey HN! We&#x27;re Nithin and Nikhil, twin brothers building BrowserOS (YC S24). We&#x27;re an open-source, privacy-first alternative to the AI browsers from big labs.<p>The big differentiator: on BrowserOS you can use local LLMs or BYOK and run the agent entirely on the client side, so your company&#x2F;sensitive data stays on your machine!<p>Today we&#x27;re launching filesystem access... just like Claude Cowork, our browser agent can read files, write files, run shell commands! But honestly, we didn&#x27;t plan for this. It turns out the privacy decision we made 9 months ago accidentally positioned us for this moment.<p>The architectural bet we made 9 months ago: Unlike other AI browsers (ChatGPT Atlas, Perplexity Comet) where the agent loop runs server-side, we decided early on to run our agent entirely on your machine (client side).<p>But building everything on the client side wasn&#x27;t smooth. We initially built our agent loop inside a Chrome extension. But we kept hitting walls -- service worker being single thread JS; not having access to NodeJS libraries. So we made the hard decision 2 months ago to throw away everything and start from scratch.<p>In the new architecture, our agent loop sits in a standalone binary that we ship alongside our Chromium. And we use gemini-cli for the agent loop with some tweaks! We wrote a neat adapter to translate between Gemini format and Vercel AI SDK format. You can look at our entire codebase here: <a href=\"https:&#x2F;&#x2F;git.new&#x2F;browseros-agent\" rel=\"nofollow\">https:&#x2F;&#x2F;git.new&#x2F;browseros-agent</a><p>How we give browser access to filesystem: When Claude Cowork launched, we realized something: because Atlas and Comet run their agent loop server-side, there&#x27;s no good way for their agent to access your files without uploading them to the server first. But our agent was already local. Adding filesystem access meant just... opening the door (with your permissions ofc). Our agent can now read and write files just like Claude Code.<p>What you can actually do today:<p>a) Organize files in my desktop folder <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;NOZ7xjto6Uc\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;NOZ7xjto6Uc</a><p>b) Open top 5 HN links, extract the details and write summary into a HTML file <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;uXvqs_TCmMQ\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;uXvqs_TCmMQ</a><p>--- Where we are now\nIf you haven&#x27;t tried us since the last Show HN (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44523409\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44523409</a>), give us another shot. The new architecture unlocked a ton of new features, and we&#x27;ve grown to 8.5K GitHub stars and 100K+ downloads:<p>c) You can now build more reliable workflows using n8n-like graph <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;H_bFfWIevSY\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;H_bFfWIevSY</a><p>d) You can also use BrowserOS as an MCP server in Cursor or Claude Code <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;5nevh00lckM\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;5nevh00lckM</a><p>We are very bullish on browser being the right platform for a Claude Cowork like agent. Browser is the most commonly used app by knowledge workers (emails, docs, spreadsheets, research, etc). And even Anthropic recognizes this -- for Claude Cowork, they have janky integration with browser via a chrome extension. But owning the entire stack allows us to build differentiated features that wouldn&#x27;t be possible otherwise. Ex:  Browser ACLs.<p>Agents can do dumb or destructive things, so we&#x27;re adding browser-level guardrails (think IAM for agents): &quot;role(agent): can never click buy&quot; or &quot;role(agent): read-only access on my bank&#x27;s homepage.&quot;<p>Curious to hear your take on this and the overall thesis.<p>We‚Äôll be in the comments. Thanks for reading!<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;browseros-ai&#x2F;BrowserOS\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;browseros-ai&#x2F;BrowserOS</a><p>Download: <a href=\"https:&#x2F;&#x2F;browseros.com\">https:&#x2F;&#x2F;browseros.com</a> (available for Mac, Windows, Linux!)",
      "publishedAt": "2026-01-22T16:30:58.000Z",
      "source": "Hacker News Claude/Anthropic",
      "sourceUrl": "https://github.com/browseros-ai/BrowserOS",
      "category": "companies",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "GPT",
        "ChatGPT",
        "Claude",
        "Gemini",
        "LLM"
      ],
      "featured": true
    },
    {
      "id": "mlqm1r0jy0dvxv4wsog",
      "title": "Show HN: I built Solveig, it turns any LLM into an assistant in your terminal",
      "summary": "Solveig (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig</a>) can plan tasks, read files, list directory trees, edit your code, run commands and more.<p>Watch 45s demo: <a href=\"https:&#x2F;&#x2F;asciinema.o...",
      "content": "Solveig (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig</a>) can plan tasks, read files, list directory trees, edit your code, run commands and more.<p>Watch 45s demo: <a href=\"https:&#x2F;&#x2F;asciinema.org&#x2F;a&#x2F;p5mzDGAoHTUHNEaVeROHpFibx\" rel=\"nofollow\">https:&#x2F;&#x2F;asciinema.org&#x2F;a&#x2F;p5mzDGAoHTUHNEaVeROHpFibx</a><p>---<p>QUICK START<p><pre><code>  # Install\n  pip install solveig\n\n  # Run from local models or remote APIs\n  solveig -u &quot;http:&#x2F;&#x2F;localhost:5001&#x2F;v1&quot; &quot;Create a demo BlackSheep webapp&quot;\n\n  # Mix config files and CLI args\n  solveig -c solveig.config -k &quot;&lt;API_KEY&gt;&quot; -m &quot;gpt-5&quot;\n</code></pre>\nSee Usage for more: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig&#x2F;blob&#x2F;main&#x2F;docs&#x2F;usage.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig&#x2F;blob&#x2F;main&#x2F;docs&#x2F;usage.m...</a><p>---<p>FEATURES<p>AI Terminal Assistant - Automate task planning, file management, code analysis and system management using natural language in your terminal.<p>Safe by Design - Granular controls with pattern-based permissions. File operations prioritized, and shell commands can be disabled.<p>Plugin Architecture - Extend capabilities through drop-in plugins. Add SQL queries, web scraping or block dangerous commands with 100 lines of Python.<p>Modern CLI - Clear interface with task planning and listing, file content previews, diff editing, API usage tracking, code linting, waiting animations and rich tree displays for informed user decisions.<p>Provider Independence - Works with any OpenAI-compatible API, including local models.<p>tl;dr: similar idea to Claude Code (<a href=\"https:&#x2F;&#x2F;claude.com&#x2F;product&#x2F;claude-code\" rel=\"nofollow\">https:&#x2F;&#x2F;claude.com&#x2F;product&#x2F;claude-code</a>) or Aider (<a href=\"https:&#x2F;&#x2F;aider.chat&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;aider.chat&#x2F;</a>), focusing on providing explicit user consent, granular configuration, drop-in plugins and the ability to integrate any model, backend or API.<p>See the Features for more: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig&#x2F;blob&#x2F;main&#x2F;docs&#x2F;about.md#features-and-principles\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig&#x2F;blob&#x2F;main&#x2F;docs&#x2F;about.m...</a><p>---<p>TYPICAL TASKS<p>- &quot;Find and list all the duplicate files inside ~&#x2F;Documents&#x2F;&quot;\n- &quot;Check my essay Final.docx for spelling, syntax or factual errors while maintaining the tone&quot;\n- &quot;Refactor my test_database.ts suite to be more concise&quot;\n- &quot;Try and find out why my computer is slow&quot;\n- &quot;Create a dockerized BlackSheep webapp with a test suite, then build the image and run it locally&quot;<p>---<p>So it&#x27;s a coding assistant?<p>You can use Solveig for analyzing, editing and testing your code, and all of these scenarios have received significant support through development features like code linting. But I didn&#x27;t build Solveig with a single kind of use case in mind.<p>---<p>So it&#x27;s yet another LLM-in-my-terminal?<p>Sort of. Solveig tries to do a few things that other tools don&#x27;t, and to do the shared features with clearer UX, explicit consent, and deeper configuration. It&#x27;s not an IDE extension, doesn&#x27;t require a GUI, and it&#x27;s not built for a specific user type or scenario.<p>At the same time, Solveig&#x27;s competitors are mature projects with real user testing that you should check out. I&#x27;ve written a detailed comparison (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig&#x2F;blob&#x2F;main&#x2F;docs&#x2F;comparison.md\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig&#x2F;blob&#x2F;main&#x2F;docs&#x2F;compari...</a>) to similar tools in the market in the docs.<p>---<p>UPCOMING<p>I have a Roadmap (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig&#x2F;discussions&#x2F;2\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig&#x2F;discussions&#x2F;2</a>) available, and feel free to suggest new features or improvements. I&#x27;ve recently added user-defined system prompt templates, and now I&#x27;m working on adding token counting from API messages instead of relying on encoders.<p>---<p>A cool aspect of this project is that I can use Solveig to analyze and improve its own code itself, which also gives me a lot of exposure to its actual usability.<p>I appreciate any feedback or comment, especially anyone who can try out Solveig using Anthropic or Gemini APIs. Tell me if it helped you do something or what stopped you from using it properly in your specific case. Even if you can&#x27;t see how Solveig could help you let me know, that&#x27;s an issue with me communicating value that I need to fix.<p>Leaving a star on the repository (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;FSilveiraa&#x2F;solveig</a>) is also very much appreciated.",
      "publishedAt": "2025-11-13T18:29:28.000Z",
      "source": "Hacker News Claude/Anthropic",
      "sourceUrl": "https://github.com/FSilveiraa/solveig",
      "category": "companies",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "GPT",
        "Claude",
        "Gemini",
        "LLM",
        "AI"
      ],
      "featured": false
    }
  ],
  "featuredCount": 8
}