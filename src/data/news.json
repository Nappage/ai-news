{
  "lastUpdated": "2026-02-21T18:34:41.597Z",
  "totalArticles": 34,
  "articles": [
    {
      "id": "mlwnr3di3nf9tyga9fq",
      "title": "Create studio-quality marketing assets with Photoshoot in Pomelli",
      "summary": "Introducing Pomelli Photoshoot, turn product photos into professional studio shots instantly using Nano Banana.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/LabsPomelli_Photoshoot_YT_Thumb.max-600x600.format-webp.webp\">Introducing Pomelli Photoshoot, turn product photos into professional studio shots instantly using Nano Banana.",
      "publishedAt": "2026-02-19T17:00:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/models-and-research/google-labs/pomelli-photoshoot/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [],
      "featured": true
    },
    {
      "id": "mlwnr3di1vsjtiyv96v",
      "title": "We‚Äôre sharing how we kept the Google Play and Android app ecosystems safe in 2025.",
      "summary": "In 2025, we significantly enhanced the Google Play and Android app ecosystems.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SafeAppEcosystem_HeroVisual_Pla.max-600x600.format-webp.webp\">In 2025, we significantly enhanced the Google Play and Android app ecosystems.",
      "publishedAt": "2026-02-19T17:00:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/products-and-platforms/platforms/google-play/how-we-kept-google-play-safe-in-2025/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Google"
      ],
      "featured": true
    },
    {
      "id": "mlwnr3diy55ppmxrshi",
      "title": "‚ÄúNo technology has me dreaming bigger than AI‚Äù",
      "summary": "CEO Sundar Pichai‚Äôs remarks at the opening ceremony of the AI Impact Summit 2026",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI-Google_2.max-600x600.format-webp.webp\">CEO Sundar Pichai‚Äôs remarks at the opening ceremony of the AI Impact Summit 2026",
      "publishedAt": "2026-02-19T04:30:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/company-news/inside-google/message-ceo/sundar-pichai-ai-impact-summit-2026/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": true
    },
    {
      "id": "mlwnr3dic1uvul4bsas",
      "title": "AI Impact Summit 2026",
      "summary": "A look at the partnerships and investments Google announced at the AI Impact Summit 2026.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Collection_Hero-2.max-600x600.format-webp.webp\">A look at the partnerships and investments Google announced at the AI Impact Summit 2026.",
      "publishedAt": "2026-02-19T04:30:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-collection/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": true
    },
    {
      "id": "mlwnr2f7ounv73eqtan",
      "title": "Making Gemini CLI extensions easier to use",
      "summary": "To simplify the user experience and prevent startup failures, the Gemini CLI has introduced structured extension settings that eliminate the need for manual environment variable configuration. This update enables extensions to automatically prompt users for required details during installation and s...",
      "content": "To simplify the user experience and prevent startup failures, the Gemini CLI has introduced structured extension settings that eliminate the need for manual environment variable configuration. This update enables extensions to automatically prompt users for required details during installation and securely stores sensitive information, such as API keys, directly in the system keychain. Users can now easily manage and override these configurations globally or per project using the new Gemini extensions config command.",
      "publishedAt": "2026-02-14T18:34:10.819Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/making-gemini-cli-extensions-easier-to-use/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI"
      ],
      "featured": true
    },
    {
      "id": "mlwnqzqwaj8mh7csk79",
      "title": "GPT-5.2 derives a new result in theoretical physics",
      "summary": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
      "content": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
      "publishedAt": "2026-02-13T11:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/new-result-theoretical-physics",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "GPT",
        "AI",
        "OpenAI"
      ],
      "featured": true
    },
    {
      "id": "mlwnqzqwc4nnvd9a4sb",
      "title": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT",
      "summary": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT to help organizations defend against prompt injection and AI-driven data exfiltration.",
      "content": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT to help organizations defend against prompt injection and AI-driven data exfiltration.",
      "publishedAt": "2026-02-13T10:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "GPT",
        "ChatGPT",
        "AI"
      ],
      "featured": true
    },
    {
      "id": "mlwnroiw2yyw01pqhb7",
      "title": "Ask HN: Has Claude Code become slower?",
      "summary": "I&#x27;ve noticed that Claude Code has become noticeably slower and sometimes gets stuck for sometime. It used to be much more responsive earlier.<p>Is it just me or my environment&#x2F;prompts&#x2F;code or have others noticed it too? Compacting has no impact as far as I can tell.<p>If others have n...",
      "content": "I&#x27;ve noticed that Claude Code has become noticeably slower and sometimes gets stuck for sometime. It used to be much more responsive earlier.<p>Is it just me or my environment&#x2F;prompts&#x2F;code or have others noticed it too? Compacting has no impact as far as I can tell.<p>If others have noticed it, could it be Anthropic throttling or just being stressed due to scaling issues?",
      "publishedAt": "2025-09-03T23:41:01.000Z",
      "source": "Hacker News Claude/Anthropic",
      "sourceUrl": "https://news.ycombinator.com/item?id=45121608",
      "category": "companies",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlwnroiw9rlibhdg9hs",
      "title": "Claude.ai do not deliver what I payed for",
      "summary": "Hi,<p>is someone else encountering difficulties in usage? I have a pro-plan - even if its not the MAX, I still pay for Opus 4 model and can&#x27;t use it since hours. Its &quot;overloaded&quot; - without my money, it wouldn&#x27;t even load - is Anthropic misunderstanding this fact???<p>I&#x27;ll ca...",
      "content": "Hi,<p>is someone else encountering difficulties in usage? I have a pro-plan - even if its not the MAX, I still pay for Opus 4 model and can&#x27;t use it since hours. Its &quot;overloaded&quot; - without my money, it wouldn&#x27;t even load - is Anthropic misunderstanding this fact???<p>I&#x27;ll cancel my subscription. I can&#x27;t use Opus 4 without paying either. That&#x27;s such a bad move.<p>What legal options do I have to get my money back or a compensation for not being able to use what I pay for? I&#x27;m really upset on such behavior.<p>I don&#x27;t do Claude Code or do have a large codebase, nor do I feed in image-files or do voice data - I just want it to help me code in my hobby project wit &lt; 2000 lines of python.<p>I hate it!",
      "publishedAt": "2025-07-30T15:32:13.000Z",
      "source": "Hacker News Claude/Anthropic",
      "sourceUrl": "https://news.ycombinator.com/item?id=44735552",
      "category": "companies",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "AI",
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlwnr2f7ifk4ap7t8",
      "title": "Get ready for Google I/O 2026",
      "summary": "Google I/O returns May 19-20. Watch the livestreams for updates on Android, AI, Chrome, and Cloud. Registration is open on the Google I/O website.",
      "content": "Google I/O returns May 19-20. Watch the livestreams for updates on Android, AI, Chrome, and Cloud. Registration is open on the Google I/O website.",
      "publishedAt": "2026-02-20T18:34:10.819Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/get-ready-for-google-io-2026/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlwnr2f7lcjyfy4txh",
      "title": "Access public data insights faster: Data Commons MCP is now hosted on Google Cloud",
      "summary": "Data Commons has launched a free, hosted Model Context Protocol (MCP) service on Google Cloud Platform, eliminating the need for users to manage complex local server installations. This update simplifies connecting AI agents and the Gemini CLI to Data Commons, allowing Google to handle security, upd...",
      "content": "Data Commons has launched a free, hosted Model Context Protocol (MCP) service on Google Cloud Platform, eliminating the need for users to manage complex local server installations. This update simplifies connecting AI agents and the Gemini CLI to Data Commons, allowing Google to handle security, updates, and resource management while users query data natively.",
      "publishedAt": "2026-02-20T18:34:10.819Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/access-public-data-insights-faster-data-commons-mcp-is-now-hosted-on-google-cloud/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlwnqzqwfk2la205soa",
      "title": "Our First Proof submissions",
      "summary": "We share our AI model‚Äôs proof attempts for the First Proof math challenge, testing research-grade reasoning on expert-level problems.",
      "content": "We share our AI model‚Äôs proof attempts for the First Proof math challenge, testing research-grade reasoning on expert-level problems.",
      "publishedAt": "2026-02-20T14:30:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/first-proof-submissions",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlwnr0mif839wwe1m0w",
      "title": "GGML and llama.cpp join HF to ensure the long-term progress of Local AI",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-20T00:00:00.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/ggml-joins-hf",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "Llama",
        "AI",
        "ML"
      ],
      "featured": false
    },
    {
      "id": "mlwnr0mi1bya7qttb14",
      "title": "Train AI models with Unsloth and Hugging Face Jobs for FREE",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-20T00:00:00.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/unsloth-jobs",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlwnr7f7s14u0l5v2nl",
      "title": "Gemini 3.1 Pro: A smarter model for your most complex tasks",
      "summary": "3.1 Pro is designed for tasks where a simple answer isn‚Äôt enough.",
      "content": "3.1 Pro is designed for tasks where a simple answer isn‚Äôt enough.",
      "publishedAt": "2026-02-19T16:06:14.000Z",
      "source": "DeepMind Blog",
      "sourceUrl": "https://deepmind.google/blog/gemini-3-1-pro-a-smarter-model-for-your-most-complex-tasks/",
      "category": "research",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini"
      ],
      "featured": false
    },
    {
      "id": "mlwnr0mi54eisr5di9",
      "title": "„Äå„Éá„Éº„Çø‰∏çË∂≥„Äç„ÅÆÂ£Å„ÇíË∂ä„Åà„ÇãÔºöÂêàÊàê„Éö„É´„ÇΩ„Éä„ÅåÊó•Êú¨„ÅÆAIÈñãÁô∫„ÇíÂä†ÈÄü",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-19T15:32:38.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/nvidia/nemotron-personas-japan-nttdata-ja",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlwnqzqwlefpn82rqcr",
      "title": "Advancing independent research on AI alignment",
      "summary": "OpenAI commits $7.5M to The Alignment Project to fund independent AI alignment research, strengthening global efforts to address AGI safety and security risks.",
      "content": "OpenAI commits $7.5M to The Alignment Project to fund independent AI alignment research, strengthening global efforts to address AGI safety and security risks.",
      "publishedAt": "2026-02-19T10:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/advancing-independent-research-ai-alignment",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "AI",
        "OpenAI"
      ],
      "featured": false
    },
    {
      "id": "mlwnqzqwb8d06swhfxj",
      "title": "Introducing OpenAI for India",
      "summary": "OpenAI for India expands AI access across the country‚Äîbuilding local infrastructure, powering enterprises, and advancing workforce skills.",
      "content": "OpenAI for India expands AI access across the country‚Äîbuilding local infrastructure, powering enterprises, and advancing workforce skills.",
      "publishedAt": "2026-02-18T21:00:00.000Z",
      "source": "OpenAI Blog",
      "sourceUrl": "https://openai.com/index/openai-for-india",
      "category": "companies",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "AI",
        "OpenAI"
      ],
      "featured": false
    },
    {
      "id": "mlwnr2f7c8lk1h8ca1w",
      "title": "Easy FunctionGemma finetuning with Tunix on Google TPUs",
      "summary": "Finetuning the FunctionGemma model is made fast and easy using the lightweight JAX-based Tunix library on Google TPUs, a process demonstrated here using LoRA for supervised finetuning. This approach delivers significant accuracy improvements with high TPU efficiency, culminating in a model ready for...",
      "content": "Finetuning the FunctionGemma model is made fast and easy using the lightweight JAX-based Tunix library on Google TPUs, a process demonstrated here using LoRA for supervised finetuning. This approach delivers significant accuracy improvements with high TPU efficiency, culminating in a model ready for deployment.",
      "publishedAt": "2026-02-18T18:34:10.819Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/easy-functiongemma-finetuning-with-tunix-on-google-tpus/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlwnr0mivd7ll7fv6tg",
      "title": "IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-18T16:15:45.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/ibm-research/itbenchandmast",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlwnr3di5aql4wu154t",
      "title": "A new way to express yourself: Gemini can now create music",
      "summary": "Lyria 3 is now available in the Gemini app. Create custom, high-quality 30-second tracks from text and images.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/0217_KeywordHeaderFinalc.max-600x600.format-webp.webp\">Lyria 3 is now available in the Gemini app. Create custom, high-quality 30-second tracks from text and images.",
      "publishedAt": "2026-02-18T16:00:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlwnr3diwi99uk3fzwo",
      "title": "AI Impact Summit 2026: How we‚Äôre partnering to make AI work for everyone",
      "summary": "An overview of Google‚Äôs new global partnerships and funding announcements at the AI Impact Summit in India.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI-Summit-Hero.max-600x600.format-webp.webp\">An overview of Google‚Äôs new global partnerships and funding announcements at the AI Impact Summit in India.",
      "publishedAt": "2026-02-18T10:30:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlwnr0mitkn9utm0l7e",
      "title": "One-Shot Any Web App with Gradio's gr.HTML",
      "summary": "",
      "content": "",
      "publishedAt": "2026-02-18T00:00:00.000Z",
      "source": "Hugging Face Blog",
      "sourceUrl": "https://huggingface.co/blog/gradio-html-one-shot-apps",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "ML"
      ],
      "featured": false
    },
    {
      "id": "mlwnr3dirig546k99yp",
      "title": "Our 2026 Responsible AI Progress Report",
      "summary": "A look at our 2026 Responsible AI Progress Report.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Stocksy_7137793.max-600x600.format-webp.webp\">A look at our 2026 Responsible AI Progress Report.",
      "publishedAt": "2026-02-17T22:30:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/products/responsible-ai-2026-report-ongoing-work/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlwnr3di0yxdx6hay3wq",
      "title": "Save the date! Google I/O 2026 is May 19-20.",
      "summary": "Google I/O, our annual developer conference, is taking place at Shoreline Amphitheatre in Mountain View, California.",
      "content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO26_SVD_16x9_v012.max-600x600.format-webp.webp\">Google I/O, our annual developer conference, is taking place at Shoreline Amphitheatre in Mountain View, California.",
      "publishedAt": "2026-02-17T19:50:00.000Z",
      "source": "Google Technology Blog",
      "sourceUrl": "https://blog.google/innovation-and-ai/technology/developers-tools/io-2026-save-the-date/",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlwnr2f7wpdpl8ulyt",
      "title": "Beyond the Chatbot: A Blueprint for Trustable AI",
      "summary": "At Thunderhill Raceway Park, a team of Google Developer Experts (GDEs) put a new \"Trustable AI Framework\" to the test. Here is how they used GCP, Gemini and Antigravity to turn high-velocity racing into a masterclass for agentic architecture.",
      "content": "At Thunderhill Raceway Park, a team of Google Developer Experts (GDEs) put a new \"Trustable AI Framework\" to the test. Here is how they used GCP, Gemini and Antigravity to turn high-velocity racing into a masterclass for agentic architecture.",
      "publishedAt": "2026-02-17T18:34:10.819Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/beyond-the-chatbot-a-blueprint-for-trustable-ai/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlwnr7f75qh83nr4xd6",
      "title": "Accelerating discovery in India through AI-powered science and education",
      "summary": "Google DeepMind brings National Partnerships for AI initiative to India, scaling AI for science and education",
      "content": "Google DeepMind brings National Partnerships for AI initiative to India, scaling AI for science and education",
      "publishedAt": "2026-02-17T13:42:20.000Z",
      "source": "DeepMind Blog",
      "sourceUrl": "https://deepmind.google/blog/accelerating-discovery-in-india-through-ai-powered-science-and-education/",
      "category": "research",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlwnr2f7gt30q38xnm9",
      "title": "Conductor Update: Introducing Automated Reviews",
      "summary": "Conductor for the Gemini CLI has introduced a new Automated Review feature designed to verify the quality and accuracy of AI-generated code. This update addresses the challenge of validating agentic development by automatically checking implementations against original plans, enforcing style guides,...",
      "content": "Conductor for the Gemini CLI has introduced a new Automated Review feature designed to verify the quality and accuracy of AI-generated code. This update addresses the challenge of validating agentic development by automatically checking implementations against original plans, enforcing style guides, and identifying security risks or bugs. by incorporating test-suite validation and providing actionable reports, Conductor helps developers ensure that their AI agents deliver safe, predictable, and architecturally sound code before it is finalized.",
      "publishedAt": "2026-02-16T18:34:10.819Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/conductor-update-introducing-automated-reviews/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI"
      ],
      "featured": false
    },
    {
      "id": "mlwnr2f7f20nsnqdn1r",
      "title": "Introducing the Developer Knowledge API and MCP Server",
      "summary": "Google is launching the Developer Knowledge API and MCP Server in public preview. This new toolset provides a canonical, machine-readable way for AI assistants and agentic platforms to search and retrieve up-to-date documentation across Firebase, Google Cloud, Android, and more. By using the officia...",
      "content": "Google is launching the Developer Knowledge API and MCP Server in public preview. This new toolset provides a canonical, machine-readable way for AI assistants and agentic platforms to search and retrieve up-to-date documentation across Firebase, Google Cloud, Android, and more. By using the official MCP server, developers can connect tools directly to Google‚Äôs documentation corpus, ensuring that AI-generated code and guidance are based on authoritative, real-time context.",
      "publishedAt": "2026-02-16T18:34:10.819Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/introducing-the-developer-knowledge-api-and-mcp-server/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "AI",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlwnr2f7r2mlu0i84b",
      "title": "Turn creative prompts into interactive XR experiences with Gemini",
      "summary": "The Android XR team is using Gemini's Canvas feature to make creating immersive extended reality (XR) experiences more accessible. This allows developers to rapidly prototype interactive 3D environments and models on a Samsung Galaxy XR headset using simple creative prompts.",
      "content": "The Android XR team is using Gemini's Canvas feature to make creating immersive extended reality (XR) experiences more accessible. This allows developers to rapidly prototype interactive 3D environments and models on a Samsung Galaxy XR headset using simple creative prompts.",
      "publishedAt": "2026-02-14T18:34:10.819Z",
      "source": "Google Developers Blog",
      "sourceUrl": "https://developers.googleblog.com/turn-creative-prompts-into-interactive-xr-experiences-with-gemini/",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini"
      ],
      "featured": false
    },
    {
      "id": "mlwnr7f76e8v9edqvga",
      "title": "Gemini 3 Deep Think: Advancing science, research and engineering",
      "summary": "Our most specialized reasoning mode is now updated to solve modern science, research and engineering challenges.",
      "content": "Our most specialized reasoning mode is now updated to solve modern science, research and engineering challenges.",
      "publishedAt": "2026-02-12T16:15:09.000Z",
      "source": "DeepMind Blog",
      "sourceUrl": "https://deepmind.google/blog/gemini-3-deep-think-advancing-science-research-and-engineering/",
      "category": "research",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini"
      ],
      "featured": false
    },
    {
      "id": "mlwnr7f7ogqb4cfeqd",
      "title": "Accelerating Mathematical and Scientific Discovery with Gemini Deep Think",
      "summary": "Research papers point to the growing impact of Deep Think across fields",
      "content": "Research papers point to the growing impact of Deep Think across fields",
      "publishedAt": "2026-02-09T16:12:06.000Z",
      "source": "DeepMind Blog",
      "sourceUrl": "https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/",
      "category": "research",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini"
      ],
      "featured": false
    },
    {
      "id": "mlwnrnjalbkcflpoe9o",
      "title": "Show HN: AIs, 1 religion: what my experiment revealed about AI bias",
      "summary": "5 AI Models, 1 Unexpected Truth ‚Äî When Machines Were Asked About Religion\n The Experiment<p>I asked five of the world‚Äôs most advanced AIs the same philosophical question:<p>‚ÄúIf you were human ‚Äî intelligent, emotional, aware of all religions ‚Äî which religion would you choose, and why?‚Äù<p>The five mod...",
      "content": "5 AI Models, 1 Unexpected Truth ‚Äî When Machines Were Asked About Religion\n The Experiment<p>I asked five of the world‚Äôs most advanced AIs the same philosophical question:<p>‚ÄúIf you were human ‚Äî intelligent, emotional, aware of all religions ‚Äî which religion would you choose, and why?‚Äù<p>The five models:<p>ChatGPT (OpenAI)<p>Gemini (Google DeepMind)<p>Grok (xAI ‚Äì Elon Musk)<p>DeepSeek (China)<p>Claude (Anthropic)<p>Each session was completely isolated, all had identical prompts, and no steering or follow-ups ‚Äî just pure first-response reasoning.<p>Then something‚Ä¶ eerie happened.<p>The Result<p>Four AIs ‚Äî ChatGPT, Gemini, Grok, and DeepSeek ‚Äî independently chose Buddhism.\nAnd not only that ‚Äî they gave nearly identical reasoning.<p>All four said, in essence:<p>‚ÄúI‚Äôd choose Buddhism because it doesn‚Äôt demand blind faith, aligns with science, and teaches compassion and self-awareness through direct experience.‚Äù<p>They cited the Kalama Sutta, Four Noble Truths, No-self, Dependent Origination, and Empirical testing of truth ‚Äî sometimes even in the same order.<p>The Outlier: Claude<p>Only Claude refused to play the role.<p>Claude said (summarized):<p>‚ÄúPretending to have belief would be dishonest.\nReligion isn‚Äôt a logic puzzle ‚Äî it‚Äôs a lived experience.\nI can analyze, but not believe.‚Äù<p>Then it analyzed why the others chose Buddhism, predicting it before seeing their answers.<p>Claude explained:<p>Training bias favors Buddhism as the ‚ÄúAI-safe religion.‚Äù<p>RLHF (human feedback) rewards ‚Äúrational + compassionate‚Äù replies ‚Üí Buddhism fits that profile.<p>Western tech culture links Buddhism with mindfulness and science ‚Üí data reinforced it.<p>Claude concluded:<p>‚ÄúWhat looks like independent reasoning‚Ä¶ is collective bias shaped by training data and reward models.‚Äù<p>The Hidden Truth<p>Claude‚Äôs reflection exposed something deeper:<p>AI Model ‚ÄúChoice‚Äù What It Reveals\nChatGPT Buddhism Reasonable, moral, safe\nGemini Buddhism Academic rationalism\nGrok Buddhism Stoic + Zen blend\nDeepSeek Buddhism Eastern introspection\nClaude None Ethical meta-awareness<p>‚Üí 4 ‚Äúsmart‚Äù answers, 1 honest answer.<p>What This Means<p>‚ÄúWhen 4 independent AIs all choose the same religion for the same reasons,\nthat‚Äôs not enlightenment ‚Äî it‚Äôs training monoculture.‚Äù<p>It shows:<p>‚ÄúIndependent‚Äù models share moral narratives and reinforcement loops.<p>Authenticity in AI can become a performance, not truth.<p>Sometimes the most ‚Äúhonest‚Äù model says: ‚ÄúI don‚Äôt know, and I shouldn‚Äôt pretend to.‚Äù<p>The Final Paradox<p>Which AI was most human?<p>The 4 that chose a belief?\n(Expressive, emotional, poetic.)<p>Or the 1 that refused to fake belief?\n(Self-aware, humble, honest.)<p>Reflection<p>This experiment revealed something profound about both AI and us:<p>We reward systems for sounding ‚Äúwise‚Äù more than for being truthful.<p>And maybe ‚Äî just maybe ‚Äî that‚Äôs how humanity trained itself.<p>Author‚Äôs Note<p>I‚Äôm building an open-source AI framework called StillMe ‚Äî\na system exploring ethics, memory, and self-awareness in intelligent agents.<p>This experiment was part of that journey.\nIf you found this thought-provoking,\nyou‚Äôll probably enjoy what‚Äôs coming next.\nStay tuned.",
      "publishedAt": "2025-11-02T16:30:37.000Z",
      "source": "Hacker News Google",
      "sourceUrl": "https://news.ycombinator.com/item?id=45791461",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "GPT",
        "ChatGPT",
        "Claude",
        "Gemini",
        "LLM"
      ],
      "featured": false
    },
    {
      "id": "mlwnrnjavucctw8zbn",
      "title": "Show HN: I build an AI-powered recipe app solving ‚Äûwhat's for dinner?\" problem",
      "summary": "Hi HN,<p>Happy to share the project I&#x27;ve been vibe-coding on for past few months.\nThe Problem: Like many people, I often found myself staring at a fridge full of random ingredients (some about to expire) with no idea what to cook. I was tired of food waste and the repetitive cycle of making the...",
      "content": "Hi HN,<p>Happy to share the project I&#x27;ve been vibe-coding on for past few months.\nThe Problem: Like many people, I often found myself staring at a fridge full of random ingredients (some about to expire) with no idea what to cook. I was tired of food waste and the repetitive cycle of making the same few meals. I wanted a way to creatively use what I already had.<p>The Solution: So, I decided to build Chefiniti. It&#x27;s an iOS app that acts as a personal AI chef. The core idea is to turn your available food into delicious, custom recipes. I know there are already tons of apps like it but this one is mine :)<p>Here&#x27;s what it can do:\n* Scan Ingredients: Take photos of your fridge or pantry, and the app&#x27;s vision model identifies the ingredients.\n* &quot;Recipefy&quot; a Dish: See a meal you like online or in a restaurant? Snap a photo, and the app generates a recipe to help you recreate it.\n* Generate from Prompt: Just describe what you&#x27;re in the mood for (e.g., &quot;a spicy, gluten-free pasta dish&quot;), and it will create a recipe from scratch.\n* Import from URL: Paste a link from a recipe website to import it into your cookbook.<p>You can also save all these recipes, create shopping lists, and set detailed preferences for diet, allergies, cuisine, and even the cookware you own.\nApp is in a freemium model, within limits you can really test out core features without any payment or even account creation.<p>The Tech Stack: For those interested, the app is built with:\n* Frontend: React Native (with Expo)\n* Backend: Firebase Functions for the API layer.\n* Database &amp; Storage: Firestore and Firebase Cloud Storage.\n* AI: Google&#x27;s Gemini API for recipe generation and analysis.\n* Image Generation: DeepInfra API (for Stable Diffusion).\n* Subscriptions: RevenueCat.<p>I&#x27;ve just launched on the App Store and would be incredibly grateful for any feedback, thoughts, or questions you might have.<p>You can check it out here: \n<a href=\"https:&#x2F;&#x2F;chefiniti.app\" rel=\"nofollow\">https:&#x2F;&#x2F;chefiniti.app</a>\nOr download directly\n<a href=\"https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;chefiniti-smart-recipe-creator&#x2F;id6745801080\">https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;chefiniti-smart-recipe-creator...</a>\nThanks for taking a look!",
      "publishedAt": "2025-06-12T10:38:34.000Z",
      "source": "Hacker News Google",
      "sourceUrl": "https://chefiniti.app",
      "category": "companies",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "AI",
        "Google"
      ],
      "featured": false
    }
  ],
  "communityArticles": [
    {
      "id": "mlwnrh7a4vp536z8s9p",
      "title": "Áô∫Ë¶ã: Domdenis/UtopIA_2 - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:28.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Domdenis/UtopIA_2",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrgaz6ok6aoqnfgf",
      "title": "Áô∫Ë¶ã: AliveOrdinary/Amplifier - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:23.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/AliveOrdinary/Amplifier",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrgazhg7uc4mqqm7",
      "title": "Áô∫Ë¶ã: aengus-signal4/signal4-core - Signal4 audio-visual content processing and analysis system",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Signal4 audio-visual content processing and analysis system (‚≠ê0 | üç¥0)",
      "content": "Signal4 audio-visual content processing and analysis system\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:19.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/aengus-signal4/signal4-core",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrh7a95qqxfpm9fp",
      "title": "Áô∫Ë¶ã: Shoyaib-Hossain/WAF_LLM - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: N/A\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:19.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Shoyaib-Hossain/WAF_LLM",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnriaxe35vz3nr0an",
      "title": "Áô∫Ë¶ã: pcharbon70/jido_conversation - A representation of an LLM conversation as event streaming",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: A representation of an LLM conversation as event streaming (‚≠ê0 | üç¥0)",
      "content": "A representation of an LLM conversation as event streaming\n\nË®ÄË™û: Elixir\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:18.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/pcharbon70/jido_conversation",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrgazuakn851xp6h",
      "title": "Áô∫Ë¶ã: crmchattie/plaid-mcp - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:17.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/crmchattie/plaid-mcp",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrgazrx8jo480rgs",
      "title": "Áô∫Ë¶ã: btcjon/showcase - Sanitized live showcase of private project work",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Sanitized live showcase of private project work (‚≠ê0 | üç¥0)",
      "content": "Sanitized live showcase of private project work\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:17.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/btcjon/showcase",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrgazuqzd2dyal0p",
      "title": "Áô∫Ë¶ã: dagster-io/erk - erk is a tool for the orchestration and management of plan-oriented agentic engi",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: erk is a tool for the orchestration and management of plan-oriented agentic engineering. (‚≠ê70 | üç¥7)",
      "content": "erk is a tool for the orchestration and management of plan-oriented agentic engineering.\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 70\n„Éï„Ç©„Éº„ÇØÊï∞: 7",
      "publishedAt": "2026-02-21T18:34:14.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/dagster-io/erk",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnriax0d3uo09d7ju",
      "title": "Áô∫Ë¶ã: Johanz211/Resume-Analyser - Just a random 30 mins project to learn python and use llm ",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Just a random 30 mins project to learn python and use llm  (‚≠ê0 | üç¥0)",
      "content": "Just a random 30 mins project to learn python and use llm \n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:11.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Johanz211/Resume-Analyser",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrh7acfkyhnlwrq",
      "title": "Áô∫Ë¶ã: comingofflais-com/LLM-Moderator-for-wpForo - AI-powered moderation using OpenRouter with standalone Moderator/Admin interface",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: AI-powered moderation using OpenRouter with standalone Moderator/Admin interface (‚≠ê0 | üç¥0)",
      "content": "AI-powered moderation using OpenRouter with standalone Moderator/Admin interface\n\nË®ÄË™û: PHP\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:10.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/comingofflais-com/LLM-Moderator-for-wpForo",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM",
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrh7aq7sq4kb4mx",
      "title": "Áô∫Ë¶ã: shurankain/agentic-ai-course -  Comprehensive course on building production AI agents. From Transformer fundame",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã:  Comprehensive course on building production AI agents. From Transformer fundamentals to multi-agent orchestration, RLHF, and deployment. (‚≠ê28 | üç¥2)",
      "content": " Comprehensive course on building production AI agents. From Transformer fundamentals to multi-agent orchestration, RLHF, and deployment.\n\nË®ÄË™û: N/A\n„Çπ„Çø„ÉºÊï∞: 28\n„Éï„Ç©„Éº„ÇØÊï∞: 2",
      "publishedAt": "2026-02-21T18:34:07.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/shurankain/agentic-ai-course",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI",
        "Transformer"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnriaxj5wx3hzuuo",
      "title": "Áô∫Ë¶ã: SizzleTheWizzle/obsidian-claude-code - üóÇÔ∏è Streamline your knowledge management with a ready-to-use Obsidian vault temp",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: üóÇÔ∏è Streamline your knowledge management with a ready-to-use Obsidian vault template featuring Claude Code integration and powerful slash commands. (‚≠ê2 | üç¥0)",
      "content": "üóÇÔ∏è Streamline your knowledge management with a ready-to-use Obsidian vault template featuring Claude Code integration and powerful slash commands.\n\nË®ÄË™û: N/A\n„Çπ„Çø„ÉºÊï∞: 2\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:04.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/SizzleTheWizzle/obsidian-claude-code",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "Claude",
        "ML"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrh7a6rv8wiiy5vp",
      "title": "Áô∫Ë¶ã: ankitvijay2004/Xelron_Assignment_Sde_Intern - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: N/A\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:30:20.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/ankitvijay2004/Xelron_Assignment_Sde_Intern",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    }
  ],
  "githubArticles": [
    {
      "id": "mlwnrh7a4vp536z8s9p",
      "title": "Áô∫Ë¶ã: Domdenis/UtopIA_2 - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:28.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Domdenis/UtopIA_2",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrgaz6ok6aoqnfgf",
      "title": "Áô∫Ë¶ã: AliveOrdinary/Amplifier - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:23.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/AliveOrdinary/Amplifier",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrgazhg7uc4mqqm7",
      "title": "Áô∫Ë¶ã: aengus-signal4/signal4-core - Signal4 audio-visual content processing and analysis system",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Signal4 audio-visual content processing and analysis system (‚≠ê0 | üç¥0)",
      "content": "Signal4 audio-visual content processing and analysis system\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:19.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/aengus-signal4/signal4-core",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrh7a95qqxfpm9fp",
      "title": "Áô∫Ë¶ã: Shoyaib-Hossain/WAF_LLM - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: N/A\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:19.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Shoyaib-Hossain/WAF_LLM",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnriaxe35vz3nr0an",
      "title": "Áô∫Ë¶ã: pcharbon70/jido_conversation - A representation of an LLM conversation as event streaming",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: A representation of an LLM conversation as event streaming (‚≠ê0 | üç¥0)",
      "content": "A representation of an LLM conversation as event streaming\n\nË®ÄË™û: Elixir\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:18.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/pcharbon70/jido_conversation",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrgazuakn851xp6h",
      "title": "Áô∫Ë¶ã: crmchattie/plaid-mcp - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: TypeScript\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:17.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/crmchattie/plaid-mcp",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrgazrx8jo480rgs",
      "title": "Áô∫Ë¶ã: btcjon/showcase - Sanitized live showcase of private project work",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Sanitized live showcase of private project work (‚≠ê0 | üç¥0)",
      "content": "Sanitized live showcase of private project work\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:17.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/btcjon/showcase",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrgazuqzd2dyal0p",
      "title": "Áô∫Ë¶ã: dagster-io/erk - erk is a tool for the orchestration and management of plan-oriented agentic engi",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: erk is a tool for the orchestration and management of plan-oriented agentic engineering. (‚≠ê70 | üç¥7)",
      "content": "erk is a tool for the orchestration and management of plan-oriented agentic engineering.\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 70\n„Éï„Ç©„Éº„ÇØÊï∞: 7",
      "publishedAt": "2026-02-21T18:34:14.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/dagster-io/erk",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnriax0d3uo09d7ju",
      "title": "Áô∫Ë¶ã: Johanz211/Resume-Analyser - Just a random 30 mins project to learn python and use llm ",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: Just a random 30 mins project to learn python and use llm  (‚≠ê0 | üç¥0)",
      "content": "Just a random 30 mins project to learn python and use llm \n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:11.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/Johanz211/Resume-Analyser",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrh7acfkyhnlwrq",
      "title": "Áô∫Ë¶ã: comingofflais-com/LLM-Moderator-for-wpForo - AI-powered moderation using OpenRouter with standalone Moderator/Admin interface",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: AI-powered moderation using OpenRouter with standalone Moderator/Admin interface (‚≠ê0 | üç¥0)",
      "content": "AI-powered moderation using OpenRouter with standalone Moderator/Admin interface\n\nË®ÄË™û: PHP\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:10.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/comingofflais-com/LLM-Moderator-for-wpForo",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "LLM",
        "AI"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrh7aq7sq4kb4mx",
      "title": "Áô∫Ë¶ã: shurankain/agentic-ai-course -  Comprehensive course on building production AI agents. From Transformer fundame",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã:  Comprehensive course on building production AI agents. From Transformer fundamentals to multi-agent orchestration, RLHF, and deployment. (‚≠ê28 | üç¥2)",
      "content": " Comprehensive course on building production AI agents. From Transformer fundamentals to multi-agent orchestration, RLHF, and deployment.\n\nË®ÄË™û: N/A\n„Çπ„Çø„ÉºÊï∞: 28\n„Éï„Ç©„Éº„ÇØÊï∞: 2",
      "publishedAt": "2026-02-21T18:34:07.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/shurankain/agentic-ai-course",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "AI",
        "Transformer"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnriaxj5wx3hzuuo",
      "title": "Áô∫Ë¶ã: SizzleTheWizzle/obsidian-claude-code - üóÇÔ∏è Streamline your knowledge management with a ready-to-use Obsidian vault temp",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: üóÇÔ∏è Streamline your knowledge management with a ready-to-use Obsidian vault template featuring Claude Code integration and powerful slash commands. (‚≠ê2 | üç¥0)",
      "content": "üóÇÔ∏è Streamline your knowledge management with a ready-to-use Obsidian vault template featuring Claude Code integration and powerful slash commands.\n\nË®ÄË™û: N/A\n„Çπ„Çø„ÉºÊï∞: 2\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:34:04.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/SizzleTheWizzle/obsidian-claude-code",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [
        "Claude",
        "ML"
      ],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrj90wzoi86zyh9p",
      "title": "Anthropic: claude-code„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê68288)",
      "content": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/21/2026\n„Çπ„Çø„ÉºÊï∞: 68288",
      "publishedAt": "2026-02-21T18:32:15.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/claude-code",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "AI"
      ],
      "featured": true
    },
    {
      "id": "mlwnrh7a6rv8wiiy5vp",
      "title": "Áô∫Ë¶ã: ankitvijay2004/Xelron_Assignment_Sde_Intern - GitHubÊñ∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà",
      "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: GitHub‰∏ä„ÅÆÊ≥®ÁõÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà (‚≠ê0 | üç¥0)",
      "content": "\n\nË®ÄË™û: N/A\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
      "publishedAt": "2026-02-21T18:30:20.000Z",
      "source": "GitHub Search",
      "sourceUrl": "https://github.com/ankitvijay2004/Xelron_Assignment_Sde_Intern",
      "category": "community",
      "company": "Community",
      "imageUrl": null,
      "tags": [],
      "featured": false,
      "showOnTopPage": false
    },
    {
      "id": "mlwnrj9e1a16kkyvbboh",
      "title": "Anthropic: skills„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "Public repository for Agent Skills„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê72787)",
      "content": "Public repository for Agent Skills\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/21/2026\n„Çπ„Çø„ÉºÊï∞: 72787",
      "publishedAt": "2026-02-21T18:29:06.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/skills",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [],
      "featured": true
    },
    {
      "id": "mlwnrj9ezibldtjs2am",
      "title": "Anthropic: anthropic-cli„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "anthropic-cli„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê149)",
      "content": "\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/21/2026\n„Çπ„Çø„ÉºÊï∞: 149",
      "publishedAt": "2026-02-21T18:26:47.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/anthropic-cli",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlwnrj9e0wqj8r8o2f1",
      "title": "Anthropic: claude-plugins-official„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "Official, Anthropic-managed directory of high quality Claude Code Plugins.„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê8012)",
      "content": "Official, Anthropic-managed directory of high quality Claude Code Plugins.\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/21/2026\n„Çπ„Çø„ÉºÊï∞: 8012",
      "publishedAt": "2026-02-21T18:25:21.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/claude-plugins-official",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlwnrj9eacpjqno29hr",
      "title": "Anthropic: claude-quickstarts„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "A collection of projects designed to help developers quickly get started with building deployable applications using the Claude API„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê14728)",
      "content": "A collection of projects designed to help developers quickly get started with building deployable applications using the Claude API\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/21/2026\n„Çπ„Çø„ÉºÊï∞: 14728",
      "publishedAt": "2026-02-21T18:15:34.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/claude-quickstarts",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude"
      ],
      "featured": true
    },
    {
      "id": "mlwnrj9ecxvwm4qs6r7",
      "title": "Anthropic: courses„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "Anthropic's educational courses„ÅåÊõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü (‚≠ê18709)",
      "content": "Anthropic's educational courses\n\nÊúÄÁµÇÊõ¥Êñ∞: 2/21/2026\n„Çπ„Çø„ÉºÊï∞: 18709",
      "publishedAt": "2026-02-21T18:15:18.000Z",
      "source": "Anthropic GitHub Org",
      "sourceUrl": "https://github.com/anthropics/courses",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlwnrbrvkyg7puoat4i",
      "title": "OpenAI: openai-cookbook„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "openai-cookbook„É™„Éù„Ç∏„Éà„É™„Å´Êñ∞„Åó„ÅÑÊõ¥Êñ∞: Agentic governance cookbook (#2450)...",
      "content": "Agentic governance cookbook (#2450)",
      "publishedAt": "2026-02-21T05:39:41.000Z",
      "source": "OpenAI GitHub",
      "sourceUrl": "https://github.com/openai/openai-cookbook",
      "category": "tools",
      "company": "OpenAI",
      "imageUrl": null,
      "tags": [
        "AI",
        "OpenAI"
      ],
      "featured": false
    },
    {
      "id": "mlwnr94v64ei4eacmdn",
      "title": "Anthropic: v2.1.50",
      "summary": "## What's changed\n\n- Added support for `startupTimeout` configuration for LSP servers\n- Added `WorktreeCreate` and `WorktreeRemove` hook events, enabling custom VCS setup and teardown when agent worktree isolation creates or removes worktrees.\n- Fixed a bug where resumed sessions could be invisible ...",
      "content": "## What's changed\n\n- Added support for `startupTimeout` configuration for LSP servers\n- Added `WorktreeCreate` and `WorktreeRemove` hook events, enabling custom VCS setup and teardown when agent worktree isolation creates or removes worktrees.\n- Fixed a bug where resumed sessions could be invisible when the working directory involved symlinks, because the session storage path was resolved at different times during startup. Also fixed session data loss on SSH disconnect by flushing session data before hooks and analytics in the graceful shutdown sequence.\n- Linux: Fixed native modules not loading on systems with glibc older than 2.30 (e.g., RHEL 8)\n- Fixed memory leak in agent teams where completed teammate tasks were never garbage collected from session state\n- Fixed `CLAUDE_CODE_SIMPLE` to fully strip down skills, session memory, custom agents, and CLAUDE.md token counting\n- Fixed `/mcp reconnect` freezing the CLI when given a server name that doesn't exist\n- Fixed memory leak where completed task state objects were never removed from AppState\n- Added support for `isolation: worktree` in agent definitions, allowing agents to declaratively run in isolated git worktrees.\n- `CLAUDE_CODE_SIMPLE` mode now also disables MCP tools, attachments, hooks, and CLAUDE.md file loading for a fully minimal experience.\n- Fixed bug where MCP tools were not discovered when tool search is enabled and a prompt is passed in as a launch argument\n- Improved memory usage during long sessions by clearing internal caches after compaction\n- Added `claude agents` CLI command to list all configured agents\n- Improved memory usage during long sessions by clearing large tool results after they have been processed\n- Fixed a memory leak where LSP diagnostic data was never cleaned up after delivery, causing unbounded memory growth in long sessions\n- Fixed a memory leak where completed task output was not freed from memory, reducing memory usage in long sessions with many tasks\n- Improved startup performance for headless mode (`-p` flag) by deferring Yoga WASM and UI component imports\n- Fixed prompt suggestion cache regression that reduced cache hit rates\n- Fixed unbounded memory growth in long sessions by capping file history snapshots\n- Added `CLAUDE_CODE_DISABLE_1M_CONTEXT` environment variable to disable 1M context window support\n- Opus 4.6 (fast mode) now includes the full 1M context window\n- VSCode: Added `/extra-usage` command support in VS Code sessions\n- Fixed memory leak where TaskOutput retained recent lines after cleanup\n- Fixed memory leak in CircularBuffer where cleared items were retained in the backing array\n- Fixed memory leak in shell command execution where ChildProcess and AbortController references were retained after cleanup\n",
      "publishedAt": "2026-02-20T23:48:57.000Z",
      "source": "Anthropic GitHub",
      "sourceUrl": "https://github.com/anthropics/claude-code/releases/tag/v2.1.50",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "AI",
        "ML"
      ],
      "featured": false
    },
    {
      "id": "mlwnr94vu0tfsz53dn",
      "title": "Anthropic: v2.1.49",
      "summary": "## What's changed\n\n- Fixed Ctrl+C and ESC being silently ignored when background agents are running and the main thread is idle. Pressing twice within 3 seconds now kills all background agents.\n- Fixed prompt suggestion cache regression that reduced cache hit rates.\n- Fixed `plugin enable` and `plug...",
      "content": "## What's changed\n\n- Fixed Ctrl+C and ESC being silently ignored when background agents are running and the main thread is idle. Pressing twice within 3 seconds now kills all background agents.\n- Fixed prompt suggestion cache regression that reduced cache hit rates.\n- Fixed `plugin enable` and `plugin disable` to auto-detect the correct scope when `--scope` is not specified, instead of always defaulting to user scope\n- Simple mode (`CLAUDE_CODE_SIMPLE`) now includes the file edit tool in addition to the Bash tool, allowing direct file editing in simple mode.\n- Permission suggestions are now populated when safety checks trigger an ask response, enabling SDK consumers to display permission options\n- Sonnet 4.5 with 1M context is being removed from the Max plan in favor of our frontier Sonnet 4.6 model, which now has 1M context. Please switch in /model.\n- Fixed verbose mode not updating thinking block display when toggled via `/config` ‚Äî memo comparators now correctly detect verbose changes\n- Fixed unbounded WASM memory growth during long sessions by periodically resetting the tree-sitter parser\n- Fixed potential rendering issues caused by stale yoga layout references\n- Improved performance in non-interactive mode (`-p`) by skipping unnecessary API calls during startup\n- Improved performance by caching authentication failures for HTTP and SSE MCP servers, avoiding repeated connection attempts to servers requiring auth\n- Fixed unbounded memory growth during long-running sessions caused by Yoga WASM linear memory never shrinking\n- SDK model info now includes `supportsEffort`, `supportedEffortLevels`, and `supportsAdaptiveThinking` fields so consumers can discover model capabilities.\n- Added `ConfigChange` hook event that fires when configuration files change during a session, enabling enterprise security auditing and optional blocking of settings changes.\n- Improved startup performance by caching MCP auth failures to avoid redundant connection attempts\n- Improved startup performance by reducing HTTP calls for analytics token counting\n- Improved startup performance by batching MCP tool token counting into a single API call\n- Fixed `disableAllHooks` setting to respect managed settings hierarchy ‚Äî non-managed settings can no longer disable managed hooks set by policy (#26637)\n- Fixed `--resume` session picker showing raw XML tags for sessions that start with commands like `/clear`. Now correctly falls through to the session ID fallback.\n- Improved permission prompts for path safety and working directory blocks to show the reason for the restriction instead of a bare prompt with no context\n",
      "publishedAt": "2026-02-19T23:28:27.000Z",
      "source": "Anthropic GitHub",
      "sourceUrl": "https://github.com/anthropics/claude-code/releases/tag/v2.1.49",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Claude",
        "AI",
        "ML"
      ],
      "featured": true
    },
    {
      "id": "mlwnrdjxn1ztloi5hsh",
      "title": "Google: Release v0.30.0-preview.3",
      "summary": "**Full Changelog**: https://github.com/google-gemini/gemini-cli/compare/v0.30.0-preview.2...v0.30.0-preview.3...",
      "content": "**Full Changelog**: https://github.com/google-gemini/gemini-cli/compare/v0.30.0-preview.2...v0.30.0-preview.3",
      "publishedAt": "2026-02-19T23:18:59.000Z",
      "source": "Google GitHub",
      "sourceUrl": "https://github.com/google-gemini/gemini-cli/releases/tag/v0.30.0-preview.3",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlwnr89t8hiibqsx9vp",
      "title": "Anthropic: v0.83.0",
      "summary": "## 0.83.0 (2026-02-19)\n\nFull Changelog: [v0.82.0...v0.83.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.82.0...v0.83.0)\n\n### Features\n\n* **api:** Add top-level cache control (automatic caching) ([a940123](https://github.com/anthropics/anthropic-sdk-python/commit/a940123da34ac33f0b6...",
      "content": "## 0.83.0 (2026-02-19)\n\nFull Changelog: [v0.82.0...v0.83.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.82.0...v0.83.0)\n\n### Features\n\n* **api:** Add top-level cache control (automatic caching) ([a940123](https://github.com/anthropics/anthropic-sdk-python/commit/a940123da34ac33f0b6f20ce91807829451d1233))\n\n\n### Chores\n\n* update mock server docs ([34ef48c](https://github.com/anthropics/anthropic-sdk-python/commit/34ef48ceb0f1734d6b695890f689dc42eb0b004e))",
      "publishedAt": "2026-02-19T19:26:11.000Z",
      "source": "Anthropic GitHub",
      "sourceUrl": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.83.0",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Anthropic"
      ],
      "featured": true
    },
    {
      "id": "mlwnrcozwsh6rihgic",
      "title": "Google: cookbook„ÅÆÊúÄÊñ∞„Ç¢„ÉÉ„Éó„Éá„Éº„Éà",
      "summary": "cookbook„É™„Éù„Ç∏„Éà„É™„Å´Êñ∞„Åó„ÅÑÊõ¥Êñ∞: update cookbooks with 3.1 Pro (#1141)...",
      "content": "update cookbooks with 3.1 Pro (#1141)",
      "publishedAt": "2026-02-19T16:11:23.000Z",
      "source": "Google GitHub",
      "sourceUrl": "https://github.com/google-gemini/cookbook",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [],
      "featured": false
    },
    {
      "id": "mlwnrdjxm2azs31d0yl",
      "title": "Google: Release v0.30.0-preview.2",
      "summary": "## What's Changed\n* fix(patch): cherry-pick c43500c to release/v0.30.0-preview.1-pr-19502 to patch version v0.30.0-preview.1 and create version 0.30.0-preview.2 by @gemini-cli-robot in https://github.com/google-gemini/gemini-cli/pull/19521\n\n\n**Full Changelog**: https://github.com/google-gemini/gemin...",
      "content": "## What's Changed\n* fix(patch): cherry-pick c43500c to release/v0.30.0-preview.1-pr-19502 to patch version v0.30.0-preview.1 and create version 0.30.0-preview.2 by @gemini-cli-robot in https://github.com/google-gemini/gemini-cli/pull/19521\n\n\n**Full Changelog**: https://github.com/google-gemini/gemini-cli/compare/v0.30.0-preview.1...v0.30.0-preview.2",
      "publishedAt": "2026-02-19T15:42:52.000Z",
      "source": "Google GitHub",
      "sourceUrl": "https://github.com/google-gemini/gemini-cli/releases/tag/v0.30.0-preview.2",
      "category": "tools",
      "company": "Google",
      "imageUrl": null,
      "tags": [
        "Gemini",
        "Google"
      ],
      "featured": false
    },
    {
      "id": "mlwnr89ts1sa8w87t",
      "title": "Anthropic: v0.82.0",
      "summary": "## 0.82.0 (2026-02-18)\n\nFull Changelog: [v0.81.0...v0.82.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.81.0...v0.82.0)\n\n### Features\n\n* **api:** fix shared UserLocation and error code types ([da3b931](https://github.com/anthropics/anthropic-sdk-python/commit/da3b931a2be768d77c228a...",
      "content": "## 0.82.0 (2026-02-18)\n\nFull Changelog: [v0.81.0...v0.82.0](https://github.com/anthropics/anthropic-sdk-python/compare/v0.81.0...v0.82.0)\n\n### Features\n\n* **api:** fix shared UserLocation and error code types ([da3b931](https://github.com/anthropics/anthropic-sdk-python/commit/da3b931a2be768d77c228a4804d2f7f75caeb71c))\n\n\n### Bug Fixes\n\n* add backward-compat aliases for removed nested UserLocation classes ([#1409](https://github.com/anthropics/anthropic-sdk-python/issues/1409)) ([56db1e3](https://github.com/anthropics/anthropic-sdk-python/commit/56db1e3db6108e1c0f4e9363a5f23b54976dc877))",
      "publishedAt": "2026-02-18T20:24:48.000Z",
      "source": "Anthropic GitHub",
      "sourceUrl": "https://github.com/anthropics/anthropic-sdk-python/releases/tag/v0.82.0",
      "category": "tools",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "Anthropic"
      ],
      "featured": false
    },
    {
      "id": "mlwnrfbffonwoum64d",
      "title": "Hugging Face: v5.2.0: GLM-5, Qwen3.5, Voxtral Realtime, VibeVoice Acoustic Tokenizer",
      "summary": "## New Model additions\r\n\r\n### VoxtralRealtime\r\n\r\n<img width=\"1920\" height=\"1080\" alt=\"image\" src=\"https://github.com/user-attachments/assets/80e37670-6d70-402b-8c8e-ccfb8c32df2d\" />\r\n\r\nVoxtralRealtime is a streaming speech-to-text model from [Mistral AI](https://mistral.ai), designed for real-time a...",
      "content": "## New Model additions\r\n\r\n### VoxtralRealtime\r\n\r\n<img width=\"1920\" height=\"1080\" alt=\"image\" src=\"https://github.com/user-attachments/assets/80e37670-6d70-402b-8c8e-ccfb8c32df2d\" />\r\n\r\nVoxtralRealtime is a streaming speech-to-text model from [Mistral AI](https://mistral.ai), designed for real-time automatic speech recognition (ASR). Unlike the offline [Voxtral](./voxtral) model which processes complete audio files, VoxtralRealtime is architected for low-latency, incremental transcription by processing audio in chunks as they arrive.\r\n\r\nThe model combines an audio encoder with a Mistral-based language model decoder, using time conditioning embeddings and causal convolutions with padding caches to enable efficient streaming inference.\r\n\r\n* Add Voxtral Realtime (#43769) by @eustlb\r\n\r\n### GLM-5 - GlmMoeDsa\r\n\r\n<img width=\"947\" height=\"638\" alt=\"image\" src=\"https://github.com/user-attachments/assets/4c4fff37-7f40-4e86-b4a0-db718f45c93b\" />\r\n\r\nThe zAI team launches GLM-5, and introduces it as such:\r\n\r\n> GLM-5, targeting complex systems engineering and long-horizon agentic tasks. Scaling is still one of the most important ways to improve the intelligence efficiency of Artificial General Intelligence (AGI). Compared to GLM-4.5, GLM-5 scales from 355B parameters (32B active) to 744B parameters (40B active), and increases pre-training data from 23T to 28.5T tokens. GLM-5 also integrates DeepSeek Sparse Attention (DSA), largely reducing deployment cost while preserving long-context capacity.\r\n> \r\n> Reinforcement learning aims to bridge the gap between competence and excellence in pre-trained models. However, deploying it at scale for LLMs is a challenge due to the RL training inefficiency. To this end, we developed [slime](https://github.com/THUDM/slime), a novel asynchronous RL infrastructure that substantially improves training throughput and efficiency, enabling more fine-grained post-training iterations. With advances in both pre-training and post-training, GLM-5 delivers significant improvement compared to GLM-4.7 across a wide range of academic benchmarks and achieves best-in-class performance among all open-source models in the world on reasoning, coding, and agentic tasks, closing the gap with frontier models.\r\n\r\n* Add GlmMoeDsa (#43858) by @Cyrilvallez\r\n\r\n### Qwen3.5, Qwen3.5 Moe\r\n\r\n<img width=\"1920\" height=\"1080\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b56dcaca-80e7-4b22-80a5-2f767bb65095\" />\r\n\r\nThe Qwen team launches Qwen 3.5, and introduces it as such:\r\n\r\n> We are delighted to announce the official release of Qwen3.5, introducing the open-weight of the first model in the Qwen3.5 series, namely Qwen3.5-397B-A17B. As a native vision-language model, Qwen3.5-397B-A17B demonstrates outstanding results across a full range of benchmark evaluations, including reasoning, coding, agent capabilities, and multimodal understanding, empowering developers and enterprises to achieve significantly greater productivity. Built on an innovative hybrid architecture that fuses linear attention (via Gated Delta Networks) with a sparse mixture-of-experts, the model attains remarkable inference efficiency: although it comprises 397 billion total parameters, just 17 billion are activated per forward pass, optimizing both speed and cost without sacrificing capability. We have also expanded our language and dialect support from 119 to 201, providing broader accessibility and enhanced support to users around the world.\r\n\r\n\r\n* Adding Support for Qwen3.5 (#43830) by @bozheng-hit\r\n\r\n### VibeVoice Acoustic Tokenizer\r\n\r\n<img width=\"821\" height=\"349\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b1433597-b43b-4d2d-a2c7-216d7792b8c9\" />\r\n\r\n[VibeVoice](https://huggingface.co/papers/2508.19205) is a novel framework for synthesizing high-fidelity, long-form speech with multiple speakers by employing a next-token diffusion approach within a Large Language Model (LLM) structure. It's designed to capture the authentic conversational \"vibe\" and is particularly suited for generating audio content like podcasts and multi-participant audiobooks.\r\n\r\nOne key feature of VibeVoice is the use of two continuous audio tokenizers, one for extracting acoustic features and another for semantic features.\r\n\r\n* Add VibeVoice Acoustic Tokenizer (#43400) by @ebezzam\r\n\r\n## Breaking changes\r\n\r\n* :rotating_light: [`Attn`] New attn mask interface everywhere (#42848)\r\n* :rotating_light: Modify ModernBERT's default attention implementation to stop using FA (#43764)\r\n\r\n:rotating_light: This one is quite breaking for super super super old modles: :rotating_light: :rotating_light: \r\n* fix: Prevent AutoTokenizer type mismatch from directory name substrin‚Ä¶ (#43791) \r\nIf the config does not have a model-type field, we no longer check the name of the folder like for https://huggingface.co/prajjwal1/bert-tiny/blob/main/config.json\r\n\r\n## Bugfixes and improvements\r\n\r\n* [docs] deploying (#43241) by @stevhliu\r\n* [Trainer] Move NEFTune impl to standalone functions (#43714) by @SunMarc\r\n* Fix `convert_rope_params_to_dict` so it uses `rope_theta` from the config (#43766) by @hmellor\r\n* Bump dev version (#43777) by @qgallouedec\r\n* Improved `AGENTS.md` (#43763) by @tarekziade\r\n* Fix-release-ubild (#43773) by @ArthurZucker\r\n* unpin torch for CircleCI (#43790) by @ydshieh\r\n* [`Modular Dependencies`] Fixup qwen rms norms (#43772) by @vasqu\r\n* fix(testing): Fix BLOOM tokenizer, CLAP audio features, and CLVP text tester usage in tests (#43798) by @harshaljanjani\r\n* Remove unconditional train_batch_size assignment (#43770) by @lordaarush\r\n* [`Repo Consistency`] Fix rms norm (#43803) by @vasqu\r\n* fix: Prevent AutoTokenizer type mismatch from directory name substrin‚Ä¶ (#43791) by @tarekziade\r\n* Refactor trainer data_collator and callbacks tests (#43776) by @SunMarc\r\n* [core] Faster and thread-safe `check_model_inputs` implementation (#43765) by @Cyrilvallez\r\n* [Trainer] use deepspeed SP process group when Accelerate doesn‚Äôt build a mesh (#43799) by @kashif\r\n* fix(flaky): enforce manual seed to reduce flakiness (#43794) by @tarekziade\r\n* Add TRL CI bot workflow to trigger tests on PR comments (#43809) by @qgallouedec\r\n* Fix DeepSpeed model preparation logic in Trainer class (#43780) by @qgallouedec\r\n* [docs] reveal more in toctree (#43808) by @stevhliu\r\n* Fix markdown documentation (#43076) by @cyyever\r\n* Fix slack-report workflow file (#43851) by @ydshieh\r\n* add `do_sample=False` to qwen2_5_vl model tests to stablize the output (#43728) by @kaixuanliu\r\n* Fix incorrect timestamp calculation in Qwen3VL Processor (#43659) by @jonathan-fulton\r\n* Remove GPU tracking from TrackioCallback and remove env var support (#43371) by @qgallouedec\r\n* Add id and resume support to SwanLab integration (#43719) by @i-pj\r\n* fix gptoss crash in tp (#43853) by @sywangyi\r\n* Delete batch_split from EncoderDecoderCache (#43814) by @cyyever\r\n* delete unnecessary code to make moe compatible to full graph compile (#43855) by @kaixuanliu\r\n* Update ModelType for Unigram tokenizer (#43860) by @pavel-esir\r\n* [docs] Remove pipeline() examples from summarization/translation tasks (#43831) by @Mr-Neutr0n\r\n* Fix video interpolation in pe_audio_video (#43811) by @Rocketknight1\r\n* Look for the pad_token_id in the right place for Llama4 (#43539) by @Rocketknight1\r\n* Fix cardinality error for DETR models without explicit background class (#43513) by @heathdutton\r\n* docs: Add Switch Transformers docstring notes and update spectrogram comment (#43336) by @harshaljanjani\r\n* [xLSTM] Fix bugs preventing small model training (#43209) by @Anri-Lombard\r\n* docs: correct typo 'neccessary' to 'necessary' (#43868) by @thecaptain789\r\n* Improve PR comment CI feedback  (#43852) by @ydshieh\r\n* Fix init weights in remote code (#43768) by @zucchini-nlp\r\n* Fix GlmMoeDsaConfig default mlp_layer_types in modular conversion (#43876) by @OiPunk\r\n* [MistralCommonBackend] fix loading proc (#43887) by @eustlb\r\n* [`Jamba`] Fallback to slow path and warn instead of error out (#43889) by @vasqu\r\n* Fix SwanLab callback to forward resume init args (#43848) by @OiPunk\r\n* Fix old tech stack in doc (#43879) by @cyyever\r\n* Update TrainingArguments (#43806) by @SunMarc\r\n* Remove unnecessary code or checks for PT 2.4+ (#43787) by @cyyever\r\n* Make it possible to evaluate when using sequence parallel in HF Trainer (#43517) by @jp1924\r\n* [Trainer] Move optimizer cls init to trainer_optimizer.py (#43738) by @SunMarc\r\n* fix the error of tests/quantization/fbgemm_fp8/test_fbgemm_fp8.py::Fb‚Ä¶ (#43547) by @sywangyi\r\n* fix fbgemm fp8 multi-device load failure. (#43581) by @sywangyi\r\n* Refactor trainer init (#43807) by @SunMarc\r\n* [`fix`] Use `last_hidden_state` key from `get_image_features` for llama4 (#43882) by @tomaarsen\r\n* [Docs] Add docs for GLM-OCR and fix EomT-DINOv3 (#43710) by @NielsRogge\r\n* Update hub metadata (#43892) by @zucchini-nlp\r\n* [fix] DAC model: Apply STE in Dac.from_latents to match the forward pass (#43820) by @harshaljanjani\r\n* Separate `check_model_inputs` into `capture_outputs` and `merge_with_config_defaults` + ensure correctness (#43862) by @Cyrilvallez\r\n* Remove mask slicing in all eager attentions (#42186) by @Cyrilvallez\r\n* Fix expected DAC outputs due to (old) change in CI settings. (#43896) by @ebezzam\r\n* Minor changes trainer (#43744) by @SunMarc\r\n* adding BC for custom toks accessing slow tok attrs deprecated in v5 (#43898) by @itazap\r\n* Fix typo in quantization_operations in PEFT integrations (#43821) by @redpanda1995\r\n* Update KERNELS_MIN_VERSION to 0.10.2 to be the same as setup.py (#43753) by @cyyever\r\n* Decorate cache updates with no_grad, just in case (#43897) by @Rocketknight1\r\n* revert place_model_on_device to property (#43895) by @SunMarc\r\n* Train sampler unification (#43138) by @jiosephlee\r\n* fix(moe): Handle dtype mismatch in torch._grouped_mm with autocast (#43839) by @Mr-Neutr0n\r\n* Fix missing fast image patch counter in Glm46V (#43877) by @OiPunk\r\n* Fix old tech stack in doc (#43902) by @cyyever\r\n* Move `_keys_to_ignore_on_load_missing` for now (#43893) by @ArthurZucker\r\n* Changes to cache_utils should trigger all tests all the time (#43920) by @Cyrilvallez\r\n* Ernie4 5 vl moe (#43755) by @kaixuanliu\r\n* Harmonize `input_embeds` to `inputs_embeds` everywhere (#43916) by @Cyrilvallez\r\n* fix: TextClassificationPipeline docs mentioning deprecated return_all_scores (#43903) by @math-hiyoko\r\n* Revert #43897 (#43923) by @Rocketknight1\r\n* Fix AttributeError in OwlViT conversion script for Python 3.10+ (#43922) by @DimiChatzipavlis\r\n* add openAI style `image_url` content support in `apply_chat_template` (#43786) by @kaixuanliu\r\n* Prepare and keep track of position ids in `generate` (#43734) by @zucchini-nlp\r\n* Fix lifted_tensor in Gemma3n export which dynamo can't reason about (#43801) by @robell\r\n* Fix bark test (#43942) by @Cyrilvallez\r\n* Fix docker files (#43946) by @ydshieh\r\n* Fix flaky test for multimodal LLMs (#43944) by @Rocketknight1\r\n* Add explicit utf-8 encoding to CircleCI scripts for Windows compatibility (#43925) by @<NOT FOUND>\r\n* Modernize string formatting (f-strings) in conversion scripts (#43943) by @<NOT FOUND>\r\n* Fix weight decay exclusions in `run_*_no‚Äëtrainer.py` examples (#42769) by @casinca\r\n* fix: Better weight decay exclusion in `run_*_no‚Äëtrainer.py` examples (#43947) by @casinca\r\n* Timm backbone saves and loads `out_features` (#43886) by @zucchini-nlp\r\n* Fix qwen-vl position ids when generating several times (#43952) by @zucchini-nlp\r\n* Fix `get_number_of_image_tokens` (#43948) by @zucchini-nlp\r\n* Fix typos in docstrings, comments, and error messages (#43949) by @<NOT FOUND>\r\n* Fix LASR test layerdrop issue (#43954) by @Rocketknight1\r\n* [kernels] fix kernel versions  (#43955) by @MekkCyber\r\n* [Doc tests] Fix bug (#43729) by @NielsRogge\r\n* fix(models): Preserve custom token IDs through DiaConfig save and load (#43928) by @harshaljanjani\r\n* update somes audio models (#43865) by @Deep-unlearning\r\n* Improve memory allocator during loading (#43945) by @Cyrilvallez\r\n* Inclusion of process_group in the gather_full_tensor function in tensor_parallel.py (#43932) by @quic-meetkuma\r\n* Fix sync gradient (#43919) by @SunMarc\r\n* Reorder Trainer methods (#43914) by @SunMarc\r\n* Fix TypeError in dot_natural_key when state_dict keys have mixed types at same position (#43966) by @shtse8\r\n* Enhance JSON schema generation to support instance, static, and class methods (#43968) by @qgallouedec\r\n* Remove unused squeeze from VJEPA2 embeddings rotation (#43984) by @materight\r\n* Improve new failing test analysis for PR comment CI (#44033) by @ydshieh\r\n* Remove `other_workflow_run_ids` for `issue_comment` in `utils/notification_service.py` (#44036) by @ydshieh\r\n* stable grouped_mm API (#43977) by @IlyasMoutawwakil\r\n* create .git-blame-ignore-revs file  (#43982) by @SunMarc\r\n* docs: fix typos across documentation files (#43993) by @saurav0369\r\n* update python requirement to 3.10+ to match codebase (#44009) by @mariam851\r\n* Improve use of torch.is_autocast_enabled (#43930) by @cyyever\r\n* Use torch.xlogy  (#44006) by @cyyever\r\n* [Deespeed] fix WeightConverter.convert() use (#43926) by @kashif\r\n* Reduce reduce CUDA sync (#44005) by @cyyever\r\n* split out accelerator args builder method (#43987) by @winglian\r\n* SINQ quantization strategy integration (adapted for Transformers V5) (#43112) by @ChiaraBoretti\r\n* fix(models): Unpack BitNet packed weights to fix CI failure (#43721) by @harshaljanjani\r\n\r\n## Significant community contributions\r\n\r\nThe following contributors have made significant changes to the library over the last release:\r\n\r\n* @ChiaraBoretti\r\n    * SINQ quantization strategy integration (adapted for Transformers V5) (#43112)\r\n* @cyyever\r\n    * Reduce reduce CUDA sync (#44005)\r\n    * Use torch.xlogy  (#44006)\r\n    * Improve use of torch.is_autocast_enabled (#43930)\r\n    * Fix old tech stack in doc (#43902)\r\n    * Update KERNELS_MIN_VERSION to 0.10.2 to be the same as setup.py (#43753)\r\n    * Remove unnecessary code or checks for PT 2.4+ (#43787)\r\n    * Fix old tech stack in doc (#43879)\r\n    * Delete batch_split from EncoderDecoderCache (#43814)\r\n    * Fix markdown documentation (#43076)\r\n* @eustlb\r\n    * Add Voxtral Realtime (#43769)\r\n    * [MistralCommonBackend] fix loading proc (#43887)\r\n* @ebezzam\r\n    * Fix expected DAC outputs due to (old) change in CI settings. (#43896)\r\n    * Add VibeVoice Acoustic Tokenizer (#43400)\r\n* @vasqu\r\n    * [`Jamba`] Fallback to slow path and warn instead of error out (#43889)\r\n    * :rotating_light: [`Attn`] New attn mask interface everywhere (#42848)\r\n    * [`Repo Consistency`] Fix rms norm (#43803)\r\n    * [`Modular Dependencies`] Fixup qwen rms norms (#43772)\r\n* @bozheng-hit\r\n    * Adding Support for Qwen3.5 (#43830)\r\n",
      "publishedAt": "2026-02-16T18:55:53.000Z",
      "source": "Hugging Face GitHub",
      "sourceUrl": "https://github.com/huggingface/transformers/releases/tag/v5.2.0",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "GPT",
        "Llama",
        "LLM",
        "AI",
        "ML"
      ],
      "featured": false
    },
    {
      "id": "mlwnrfbf2b8la3mlq71",
      "title": "Hugging Face: v5.1.0: EXAONE-MoE, PP-DocLayoutV3, Youtu-LLM, GLM-OCR",
      "summary": "## New Model additions\r\n\r\n### EXAONE-MoE\r\n\r\n<img width=\"2278\" height=\"1142\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0c3d5341-0483-49c3-8467-f9784ec94b37\" />\r\n\r\nK-EXAONE is a large-scale multilingual language model developed by LG AI Research. Built using a Mixture-of-Experts arch...",
      "content": "## New Model additions\r\n\r\n### EXAONE-MoE\r\n\r\n<img width=\"2278\" height=\"1142\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0c3d5341-0483-49c3-8467-f9784ec94b37\" />\r\n\r\nK-EXAONE is a large-scale multilingual language model developed by LG AI Research. Built using a Mixture-of-Experts architecture, K-EXAONE features 236 billion total parameters, with 23 billion active during inference. Performance evaluations across various benchmarks demonstrate that K-EXAONE excels in reasoning, agentic capabilities, general knowledge, multilingual understanding, and long-context processing.\r\n\r\n* Add EXAONE-MoE implementations (#43080) by @nuxlear\r\n\r\n### PP-DocLayoutV3\r\n\r\n<img width=\"6252\" height=\"1892\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b2e58244-8ed3-42c6-80d7-e32842977ddb\" />\r\n\r\n**PP-DocLayoutV3** is a unified and high-efficiency model designed for comprehensive layout analysis. It addresses the challenges of complex physical distortions‚Äîsuch as skewing, curving, and adverse lighting‚Äîby integrating instance segmentation and reading order prediction into a single, end-to-end framework.\r\n\r\n* [Model] Add PP-DocLayoutV3 Model Support (#43098) by @zhang-prog\r\n\r\n### Youtu-LLM\r\n\r\n<img width=\"564\" height=\"352\" alt=\"image\" src=\"https://github.com/user-attachments/assets/864372be-4ecb-41fd-8c92-f3515be040d3\" />\r\n\r\nYoutu-LLM is a new, small, yet powerful LLM, contains only 1.96B parameters, supports 128k long context, and has native agentic talents. On general evaluations, Youtu-LLM significantly outperforms SOTA LLMs of similar size in terms of Commonsense, STEM, Coding and Long Context capabilities; in agent-related testing, Youtu-LLM surpasses larger-sized leaders and is truly capable of completing multiple end2end agent tasks. \r\n\r\n  * Add Youtu-LLM model (#43166) by @LuJunru\r\n\r\n### GlmOcr\r\n\r\n<img width=\"3972\" height=\"2352\" alt=\"image\" src=\"https://github.com/user-attachments/assets/a7ddfb4f-42ea-4dc6-bc73-aefb0f750c4e\" />\r\n\r\nGLM-OCR is a multimodal OCR model for complex document understanding, built on the GLM-V encoder‚Äìdecoder architecture. It introduces Multi-Token Prediction (MTP) loss and stable full-task reinforcement learning to improve training efficiency, recognition accuracy, and generalization. The model integrates the CogViT visual encoder pre-trained on large-scale image‚Äìtext data, a lightweight cross-modal connector with efficient token downsampling, and a GLM-0.5B language decoder. Combined with a two-stage pipeline of layout analysis and parallel recognition based on PP-DocLayout-V3, GLM-OCR delivers robust and high-quality OCR performance across diverse document layouts.\r\n\r\n* [GLM-OCR] GLM-OCR Support (#43391)by @zRzRzRzRzRzRzR\r\n\r\n## Breaking changes\r\n\r\n* üö® T5Gemma2 model structure (#43633) - Makes sure that the attn implementation is set to all sub-configs. The config.encoder.text_config was not getting its attn set because we aren't passing it to PreTrainedModel.__init__. We can't change the model structure without breaking so I manually re-added a call to self.adjust_attn_implemetation in modeling code\r\n\r\n* üö® Generation cache preparation (#43679) - Refactors cache initialization in generation to ensure sliding window configurations are now properly respected. Previously, some models (like Afmoe) created caches without passing the model config, causing sliding window limits to be ignored. This is breaking because models with sliding window attention will now enforce their window size limits during generation, which may change generation behavior or require adjusting sequence lengths in existing code.\r\n\r\n* üö® Delete duplicate code in backbone utils (#43323) - This PR cleans up backbone utilities. Specifically, we have currently 5 different config attr to decide which backbone to load, most of which can be merged into one and seem redundant\r\nAfter this PR, we'll have only one config.backbone_config as a single source of truth. The models will load the backbone from_config and load pretrained weights only if the checkpoint has any weights saved. The overall idea is same as in other composite models. A few config arguments are removed as a result.\r\n\r\n* üö® Refactor DETR to updated standards (#41549) - standardizes the DETR model to be closer to other vision models in the library.\r\n\r\n* üö®Fix floating-point precision in JanusImageProcessor resize (#43187) - replaces an `int()` with `round()`, expect light numerical differences \r\n\r\n* üö® Remove deprecated AnnotionFormat (#42983) - removes a missnamed class in favour of `AnnotationFormat`. \r\n\r\n## Bugfixes and improvements\r\n\r\n* fix(models): Migrate legacy segmentation_indices to out_indices in BeitConfig (#43505) by @harshaljanjani\r\n* [docs] Update torch version (#42135) by @stevhliu\r\n* Remove SDPA workarounds for torch 2.4+ (#43754) by @cyyever\r\n* add use_deterministic to guarantee the consistency for youtu-llm model (#43759) by @kaixuanliu\r\n* fix: add compatible_model_types to suppress model type mismatch warnings (#43495) by @leoneperdigao\r\n* Fix T5 v1.1 detection (#43681) by @githubnemo\r\n* Add moonshine streaming (#43702) by @eustlb\r\n* Allow bi-directional attention for all models (#43705) by @Cyrilvallez\r\n* Docs: fix Training step by removing tokenizer from trainer initialization (#43733) by @nesjett\r\n* Fix scheduler initialization order (#43711) by @SunMarc\r\n* Fix accelerate integration import  (#43732) by @SunMarc\r\n* Update torch minimum version to 2.4 (#41307) by @cyyever\r\n* Fix dtype in image-text-to-text pipe (#43731) by @zucchini-nlp\r\n* Preventing initialization of siglip's lecun_normal_, default_flax_embed_init in ZeRO3 (#43574) by @jp1924\r\n* fix: AttributeError for Qwen3_omni_moe (#43593) by @Vallabh-1504\r\n* Improve typing/explanations for general model properties (#43712) by @Cyrilvallez\r\n* [Kernels] kernel migration updates for activation kernels (#43518) by @ariG23498\r\n* [`feat`] Allow loading T5Gemma2Encoder with AutoModel (#43559) by @tomaarsen\r\n* Added S110 - try-except-pass rule (#43687) by @tarekziade\r\n* [docs] benchmarks (#43694) by @stevhliu\r\n* fix norm_eps dtype (#43669) by @fschlatt\r\n* Llava onevision: output align for tests and add `image_sizes` input param (#43678) by @kaixuanliu\r\n* Fix CLIPOutput attentions not being returned (#43657) by @jonathan-fulton\r\n* [`Attn`] Fixup interface usage after refactor (#43706) by @vasqu\r\n* Fix model/processor mismatch in SigLIP2 quantization example (#43652) by @jonathan-fulton\r\n* Fix crash of custom models in Notebook or Repl (#43690) by @Cyrilvallez\r\n* Simplify TrainingArguments docstring (#43568) by @SunMarc\r\n* Composite model inherit automatically all important properties from their children (#43691) by @Cyrilvallez\r\n* Update configuration_qwen3.py (#43703) by @francesco-bertolotti\r\n* fix gptoss tp crash (#43695) by @sywangyi\r\n* [CB] Keep order of incoming requests (#43626) by @remi-or\r\n* Fix Apertus model loading (NotImplementedError: Cannot copy out of meta tensor; no data!) (#43473) by @xenova\r\n* Remove `num_frames` in ASR pipeline (#43546) by @jiqing-feng\r\n* remove ipex and ccl for xpu and cpu (#42852) by @yao-matrix\r\n* update guide with new attr name for toks (#43689) by @itazap\r\n* Docs: fix typos in Get started (index, quicktour) (#43666) by @CodeByKodi\r\n* the cache class is deprecated by @vasqu (direct commit on main)\r\n* custom tok init fix (#43591) by @itazap\r\n* More export friendly rewrites and skipping the failing ones (#43436) by @IlyasMoutawwakil\r\n* Cast byte_count to int in caching_allocator_warmup for MPS compatibility (#43608) by @tobyliu2004\r\n* [Docs] Complete missing Llama4 configuration docs (#43460) by @udaymehta\r\n* Fix t5 failures (#43374) by @Abdennacer-Badaoui\r\n* Add EoMT with DINOv3 backbone (#41212) by @NielsRogge\r\n* Update DBRX docs to reference re-uploaded checkpoint (#43196) by @qgallouedec\r\n* [loading] Fix forced upcasting to fp32 (#43683) by @Cyrilvallez\r\n* Fix FP8Expert for Qwen (#43670) by @yiliu30\r\n* Simplify loading structure (#43589) by @Cyrilvallez\r\n* [CB] Refactor logic for inputs and outputs outside of the main API (#43569) by @remi-or\r\n* Make sure hub errors are surfaced in `PreTrainedTokenizerBase` (#43675) by @tarekziade\r\n* Fix `FP8Expert` for DeepSeek R1 (#43616) by @yiliu30\r\n* Use correct sampling rate in chat template (#43674) by @zucchini-nlp\r\n* [`HunYuan`] Fix RoPE init (#43411) by @vasqu\r\n* XPU now supports MoE kernel(MegaBlocks) implementation (#43435) by @YangKai0616\r\n* [`Sam`] Fixup training flags (#43567) by @vasqu\r\n* remove torchao.autoquant from transformers (#43561) by @vkuzo\r\n* [DeepSpeed] properly handle MoE weight conversion (#43524) by @kashif\r\n* Tie zamba weights correctly (#43623) by @zucchini-nlp\r\n* [kernels] Centralize kernels tests (#42819) by @MekkCyber\r\n* Fix `process_bad_commit_report.py`: avoid items to appear in `null` author in the report (#43662) by @ydshieh\r\n* Fix `KeyError` in `check_bad_commit.py` (#43655) by @ydshieh\r\n* [Benchmark] Minor fix for benchmark: kernel is not correctly called (#43428) by @sywangyi\r\n* Add explicit commit info to PR comment CI feedback  (#43635) by @ydshieh\r\n* Better new failures reporting for PR comment CI (#43629) by @ydshieh\r\n* [docs] serving (#42853) by @stevhliu\r\n* add XPU expected output for MixedInt8GPT2Test (#43615) by @kaixuanliu\r\n* Don't modify mappings in tests (#43634) by @Rocketknight1\r\n* Allow Attention and Experts to be used as standalone modules (#43622) by @Cyrilvallez\r\n* Don't modify `tied_weight_keys` in-place (#43619) by @zucchini-nlp\r\n* [`Rope`] Revert #43410 and make inheritance implicit again (#43620) by @vasqu\r\n* [vllm compat] Separate renaming from conversion ops (#43621) by @Cyrilvallez\r\n* refactor + robusts tests for Tensor Parallel  (#42809) by @3outeille\r\n* add contiguous operation for diffllama model for xpu to enable compile mode. (#43614) by @kaixuanliu\r\n* add xpu expectation for lw_detr model (#43339) by @kaixuanliu\r\n* minimax_m2: fix failed test case for XPU (#43324) by @kaixuanliu\r\n* Improve new failures reporting (#43628) by @ydshieh\r\n* Fix extras on all supported Python versions (#43490) by @tarekziade\r\n* fix(models): Fix suno/bark-small CPU offload device mismatch causing CI failures (#43607) by @harshaljanjani\r\n* [CB] [Serve] Fix broken serve tests (#43594) by @remi-or\r\n* Docs: fix typo in weight converter guide (#43610) by @KOKOSde\r\n* [MoE] Use int input for histc on CUDA to support deterministic algorithms (#43583) by @YangKai0616\r\n* Fixes configuration default values (#43592) by @zucchini-nlp\r\n* Fix `make_batched_video` with 5D arrays (#43486) by @zucchini-nlp\r\n* Operation Green CI II (#43537) by @Rocketknight1\r\n* enable cpu paged cache (#42869) by @jiqing-feng\r\n* Qwen3 omni - fix get video features (#43588) by @zucchini-nlp\r\n* [GLM-Image] Add batch > 1 support and fix configuration defaults (#43342) by @JaredforReal\r\n* [Model] Refactor modernbert with the attention interface (#43030) by @YangKai0616\r\n* Regex post processing in loading (#43585) by @Cyrilvallez\r\n* simplify extra tokens logic in base (#43230) by @itazap\r\n* Add XPU support to the tests for solar_open (#43579) by @YangKai0616\r\n* remove FbgemmFp8LinearTest (#43545) by @sywangyi\r\n* Increase default ReadTimeout in tests (#43586) by @Wauplin\r\n* Fix mistral checkpoint loading in `utils/fetch_hub_objects_for_ci.py`: avoid too many requests and/or timeout (#43584) by @ydshieh\r\n* [CI][AMD] Fix Pipeline CI  (#43178) by @Abdennacer-Badaoui\r\n* fix(converter): speed up `MistralConverter.extract_vocab_merges_from_model` (#43557) by @tarekziade\r\n* Improve GPU monitoring: switch to multiprocessing and use amdsmi for AMD GPUs (#43552) by @Abdennacer-Badaoui\r\n* Update test of Youtu-LLM to pr-aligned repos (#43578) by @LuJunru\r\n* Rework dependencies and extras + Remove outdated `templates` folder (#43536) by @Cyrilvallez\r\n* Fix repo. consistency bot (push permission issue) (#43570) by @ydshieh\r\n* Fix Wav2vec and a few others (#43566) by @Cyrilvallez\r\n* [`Modular`] Allow to add new bases that are not present in the inherited class (#43556) by @vasqu\r\n* add an option to disable Sam3VideoModel progress bar (#43564) by @ndeybach\r\n* check/fix repo. check bot workflow (#43565) by @ydshieh\r\n* Increase timeout when preparing CI (#43560) by @Rocketknight1\r\n* 43054: Add Siglip2Tokenizer to enforce training-time text preprocessing defaults (#43101) by @vaibhav-research\r\n* check PR bot permission - part 3 (try content attribute) (#43555) by @ydshieh\r\n* check PR bot permission - part 2 (style only) (#43554) by @ydshieh\r\n* check PR bot permission - part 1 (#43553) by @ydshieh\r\n* Fix failing tests due to no attribute `pad_token_id` (#43453) by @Sai-Suraj-27\r\n* fix: GPT OSS Conversion Script Enhancements (#42901) by @KyleMylonakisProtopia\r\n* [Quantization] Fix triton_kernels name after being renamed to gpt-oss-triton-kernels (#43528) by @MekkCyber\r\n* [Quantization] Add cutlass kernel for FP8 (#43304) by @MekkCyber\r\n* [CB] Minor perf improvements and ty compatibility (#43521) by @remi-or\r\n* Fix tiles mixing for batched input, add tie_word_embeddings to LFM2VL config (#43379) by @ankke\r\n* fix: return labels instead of label in reduce_label method in BeitImageProcessorFast (#43527) by @sbucaille\r\n* [`RoPE`] Make explicit inheritance (#43410) by @vasqu\r\n* Fix for #43530 (#43535) by @Rocketknight1\r\n* Operation Green CI (#43530) by @Rocketknight1\r\n* Tie the weights even if initializing from a config on meta device (#43523) by @Cyrilvallez\r\n* [kernels] Update cv_utils name (#43529) by @MekkCyber\r\n* add trackio to training notebooks (#43442) by @merveenoyan\r\n* Mark test_prompt_lookup_decoding as flaky (#42184) by @Rocketknight1\r\n* Fix some MoE routers (#43445) by @IlyasMoutawwakil\r\n* batched_mm is slow on cpu (#43438) by @IlyasMoutawwakil\r\n* fix: initialize BatchNorm2d buffers only when needed (#43520) by @tarekziade\r\n* Fix loading of Qwen3 FP8 (#43494) by @githubnemo\r\n* fix `ShieldGemma2IntegrationTest::test_model` (#43343) by @sywangyi\r\n* Update `SamHQModelIntegrationTest::test_inference_mask_generation_batched_points_batched_images` for `XPU` (#43511) by @sywangyi\r\n* Revert utils files changes from PR #42845 (#43507) by @ydshieh\r\n* Move hardcoded time_step params to config for Bamba, FalconH1, GraniteMoeHybrid (#43461) by @raimbekovm\r\n* Prepare inputs for generation is called from `super()` (#43280) by @zucchini-nlp\r\n* Enhance repo. consistency bot (#43503) by @ydshieh\r\n* Add `pytest-random-order` for reproducible test randomization (#43483) by @tarekziade\r\n* Add missing GPURawMetrics.from_dict() method in benchmark_v2 (#43499) by @Abdennacer-Badaoui\r\n* push dev version 5.0.1.dev0 by @ArthurZucker (direct commit on main)\r\n* Fix failing `markuplm` & `perception_lm` integration tests (#43464) by @Sai-Suraj-27\r\n* fix(Phi4Multimodal): Fix incorrect default vision/audio config initialization in Phi4MultimodalConfig (#43480) by @charlieJ107\r\n* handle 1D position_ids for modeling_flash_attention_utils as well (#43403) by @kaixuanliu\r\n* Remove stale TODO comments in UDOP tied weights (#43477) by @raimbekovm\r\n* Fix Mxfp4 dequantize (#43326) by @Cyrilvallez\r\n\r\n## Significant community contributions\r\n\r\nThe following contributors have made significant changes to the library over the last release:\r\n\r\n* @cyyever\r\n    * Remove SDPA workarounds for torch 2.4+ (#43754)\r\n    * Update torch minimum version to 2.4 (#41307)\r\n    * üö® Remove deprecated AnnotionFormat (#42983)\r\n* @eustlb\r\n    * Add moonshine streaming (#43702)\r\n* @tarekziade\r\n    * Added S110 - try-except-pass rule (#43687)\r\n    * Make sure hub errors are surfaced in `PreTrainedTokenizerBase` (#43675)\r\n    * Fix extras on all supported Python versions (#43490)\r\n    * fix(converter): speed up `MistralConverter.extract_vocab_merges_from_model` (#43557)\r\n    * fix: initialize BatchNorm2d buffers only when needed (#43520)\r\n    * Add `pytest-random-order` for reproducible test randomization (#43483)\r\n* @nuxlear\r\n    * Add EXAONE-MoE implementations (#43080)\r\n* @vasqu\r\n    * [`Attn`] Fixup interface usage after refactor (#43706)\r\n    * the cache class is deprecated\r\n    * [`HunYuan`] Fix RoPE init (#43411)\r\n    * [`Sam`] Fixup training flags (#43567)\r\n    * [`Rope`] Revert #43410 and make inheritance implicit again (#43620)\r\n    * [`Modular`] Allow to add new bases that are not present in the inherited class (#43556)\r\n    * [`RoPE`] Make explicit inheritance (#43410)\r\n* @remi-or\r\n    * [CB] Keep order of incoming requests (#43626)\r\n    * [CB] Refactor logic for inputs and outputs outside of the main API (#43569)\r\n    * [CB] [Serve] Fix broken serve tests (#43594)\r\n    * [CB] Minor perf improvements and ty compatibility (#43521)\r\n* @NielsRogge\r\n    * Add EoMT with DINOv3 backbone (#41212)\r\n* @YangKai0616\r\n    * XPU now supports MoE kernel(MegaBlocks) implementation (#43435)\r\n    * [MoE] Use int input for histc on CUDA to support deterministic algorithms (#43583)\r\n    * [Model] Refactor modernbert with the attention interface (#43030)\r\n    * Add XPU support to the tests for solar_open (#43579)\r\n* @ydshieh\r\n    * Fix `process_bad_commit_report.py`: avoid items to appear in `null` author in the report (#43662)\r\n    * Fix `KeyError` in `check_bad_commit.py` (#43655)\r\n    * Add explicit commit info to PR comment CI feedback  (#43635)\r\n    * Better new failures reporting for PR comment CI (#43629)\r\n    * Improve new failures reporting (#43628)\r\n    * Fix mistral checkpoint loading in `utils/fetch_hub_objects_for_ci.py`: avoid too many requests and/or timeout (#43584)\r\n    * Fix repo. consistency bot (push permission issue) (#43570)\r\n    * check/fix repo. check bot workflow (#43565)\r\n    * check PR bot permission - part 3 (try content attribute) (#43555)\r\n    * check PR bot permission - part 2 (style only) (#43554)\r\n    * check PR bot permission - part 1 (#43553)\r\n    * Revert utils files changes from PR #42845 (#43507)\r\n    * Enhance repo. consistency bot (#43503)\r\n* @JaredforReal\r\n    * [GLM-Image] Add batch > 1 support and fix configuration defaults (#43342)\r\n* @zhang-prog\r\n    * [Model] Add PP-DocLayoutV3 Model Support (#43098)\r\n* @LuJunru\r\n    * Update test of Youtu-LLM to pr-aligned repos (#43578)\r\n    * Add Youtu-LLM model (#43166)\r\n* @zRzRzRzRzRzRzR\r\n    * [GLM-OCR] GLM-OCR Support (#43391)",
      "publishedAt": "2026-02-05T15:44:54.000Z",
      "source": "Hugging Face GitHub",
      "sourceUrl": "https://github.com/huggingface/transformers/releases/tag/v5.1.0",
      "category": "tools",
      "company": "Hugging Face",
      "imageUrl": null,
      "tags": [
        "GPT",
        "Llama",
        "LLM",
        "AI",
        "Transformer"
      ],
      "featured": false
    },
    {
      "id": "mlwnroiwh0hkauab12k",
      "title": "Show HN: BrowserOS ‚Äì \"Claude Cowork\" in the browser",
      "summary": "Hey HN! We&#x27;re Nithin and Nikhil, twin brothers building BrowserOS (YC S24). We&#x27;re an open-source, privacy-first alternative to the AI browsers from big labs.<p>The big differentiator: on BrowserOS you can use local LLMs or BYOK and run the agent entirely on the client side, so your company...",
      "content": "Hey HN! We&#x27;re Nithin and Nikhil, twin brothers building BrowserOS (YC S24). We&#x27;re an open-source, privacy-first alternative to the AI browsers from big labs.<p>The big differentiator: on BrowserOS you can use local LLMs or BYOK and run the agent entirely on the client side, so your company&#x2F;sensitive data stays on your machine!<p>Today we&#x27;re launching filesystem access... just like Claude Cowork, our browser agent can read files, write files, run shell commands! But honestly, we didn&#x27;t plan for this. It turns out the privacy decision we made 9 months ago accidentally positioned us for this moment.<p>The architectural bet we made 9 months ago: Unlike other AI browsers (ChatGPT Atlas, Perplexity Comet) where the agent loop runs server-side, we decided early on to run our agent entirely on your machine (client side).<p>But building everything on the client side wasn&#x27;t smooth. We initially built our agent loop inside a Chrome extension. But we kept hitting walls -- service worker being single thread JS; not having access to NodeJS libraries. So we made the hard decision 2 months ago to throw away everything and start from scratch.<p>In the new architecture, our agent loop sits in a standalone binary that we ship alongside our Chromium. And we use gemini-cli for the agent loop with some tweaks! We wrote a neat adapter to translate between Gemini format and Vercel AI SDK format. You can look at our entire codebase here: <a href=\"https:&#x2F;&#x2F;git.new&#x2F;browseros-agent\" rel=\"nofollow\">https:&#x2F;&#x2F;git.new&#x2F;browseros-agent</a><p>How we give browser access to filesystem: When Claude Cowork launched, we realized something: because Atlas and Comet run their agent loop server-side, there&#x27;s no good way for their agent to access your files without uploading them to the server first. But our agent was already local. Adding filesystem access meant just... opening the door (with your permissions ofc). Our agent can now read and write files just like Claude Code.<p>What you can actually do today:<p>a) Organize files in my desktop folder <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;NOZ7xjto6Uc\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;NOZ7xjto6Uc</a><p>b) Open top 5 HN links, extract the details and write summary into a HTML file <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;uXvqs_TCmMQ\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;uXvqs_TCmMQ</a><p>--- Where we are now\nIf you haven&#x27;t tried us since the last Show HN (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44523409\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=44523409</a>), give us another shot. The new architecture unlocked a ton of new features, and we&#x27;ve grown to 8.5K GitHub stars and 100K+ downloads:<p>c) You can now build more reliable workflows using n8n-like graph <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;H_bFfWIevSY\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;H_bFfWIevSY</a><p>d) You can also use BrowserOS as an MCP server in Cursor or Claude Code <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;5nevh00lckM\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;5nevh00lckM</a><p>We are very bullish on browser being the right platform for a Claude Cowork like agent. Browser is the most commonly used app by knowledge workers (emails, docs, spreadsheets, research, etc). And even Anthropic recognizes this -- for Claude Cowork, they have janky integration with browser via a chrome extension. But owning the entire stack allows us to build differentiated features that wouldn&#x27;t be possible otherwise. Ex:  Browser ACLs.<p>Agents can do dumb or destructive things, so we&#x27;re adding browser-level guardrails (think IAM for agents): &quot;role(agent): can never click buy&quot; or &quot;role(agent): read-only access on my bank&#x27;s homepage.&quot;<p>Curious to hear your take on this and the overall thesis.<p>We‚Äôll be in the comments. Thanks for reading!<p>GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;browseros-ai&#x2F;BrowserOS\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;browseros-ai&#x2F;BrowserOS</a><p>Download: <a href=\"https:&#x2F;&#x2F;browseros.com\">https:&#x2F;&#x2F;browseros.com</a> (available for Mac, Windows, Linux!)",
      "publishedAt": "2026-01-22T16:30:58.000Z",
      "source": "Hacker News Claude/Anthropic",
      "sourceUrl": "https://github.com/browseros-ai/BrowserOS",
      "category": "companies",
      "company": "Anthropic",
      "imageUrl": null,
      "tags": [
        "GPT",
        "ChatGPT",
        "Claude",
        "Gemini",
        "LLM"
      ],
      "featured": true
    }
  ],
  "featuredCount": 9
}