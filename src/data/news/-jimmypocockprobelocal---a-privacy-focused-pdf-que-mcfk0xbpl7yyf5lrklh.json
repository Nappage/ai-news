{
  "id": "mcfk0xbpl7yyf5lrklh",
  "title": "Áô∫Ë¶ã: jimmypocock/ProbeLocal - A privacy-focused PDF question-answering system built for M3 MacBook Air and App",
  "summary": "Êñ∞„Åó„ÅÑ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÇíÁô∫Ë¶ã: A privacy-focused PDF question-answering system built for M3 MacBook Air and Apple Silicon Macs. Uses Ollama and open-source LLMs to provide completely  local, free document intelligence. Features a clean web UI, support for multiple AI models, and optimized performance for machines with 8-24GB RAM. (‚≠ê0 | üç¥0)",
  "content": "A privacy-focused PDF question-answering system built for M3 MacBook Air and Apple Silicon Macs. Uses Ollama and open-source LLMs to provide completely  local, free document intelligence. Features a clean web UI, support for multiple AI models, and optimized performance for machines with 8-24GB RAM.\n\nË®ÄË™û: Python\n„Çπ„Çø„ÉºÊï∞: 0\n„Éï„Ç©„Éº„ÇØÊï∞: 0",
  "publishedAt": "2025-06-28T01:19:51.000Z",
  "source": "GitHub Search",
  "sourceUrl": "https://github.com/jimmypocock/ProbeLocal",
  "category": "tools",
  "company": "Community",
  "imageUrl": null,
  "tags": [
    "Llama",
    "LLM",
    "AI"
  ],
  "featured": false
}