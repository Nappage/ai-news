{
  "id": "mdakv9s71j9yd5hkkd8",
  "title": "Bias Discovery within Human Raters: A Case Study of the Jigsaw Dataset",
  "summary": "Understanding and quantifying the bias introduced by human annotation of data is a crucial problem for trustworthy supervised learning. Recently, a perspectivist trend has emerged in the NLP community, focusing on the inadequacy of previous aggregation schemes, which suppose the existence of single ...",
  "content": "Understanding and quantifying the bias introduced by human annotation of data is a crucial problem for trustworthy supervised learning. Recently, a perspectivist trend has emerged in the NLP community, focusing on the inadequacy of previous aggregation schemes, which suppose the existence of single ground truth. This assumption is particularly problematic for sensitive tasks involving subjective human judgments, such as toxicity detection. To address these issues, we propose a preliminary approach for bias discovery within human raters by exploring individual ratings for specific sensitive topics annotated in the texts. Our analysisâ€™s object consists of the Jigsaw dataset, a collection of comments aiming at challenging online toxicity identification.",
  "publishedAt": "1970-01-01T00:00:00.000Z",
  "source": "Papers with Code",
  "sourceUrl": "https://aclanthology.org/2022.nlperspectives-1.4.pdf",
  "category": "research",
  "company": "Community",
  "imageUrl": null,
  "tags": [
    "AI"
  ],
  "featured": false
}