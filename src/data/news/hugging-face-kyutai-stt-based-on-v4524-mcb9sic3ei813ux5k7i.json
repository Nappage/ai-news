{
  "id": "mcb9sic3ei813ux5k7i",
  "title": "Hugging Face: Kyutai-STT (based on v4.52.4)",
  "summary": "A new model is added to transformers: Kyutai-STT\r\nIt is added on top of the v4.52.4 release, and can be installed from the following tag: `v4.52.4-Kyutai-STT-preview`.\r\n\r\nIn order to install this version, please install with the following command:\r\n\r\n```\r\npip install git+https://github.com/huggingfa...",
  "content": "A new model is added to transformers: Kyutai-STT\r\nIt is added on top of the v4.52.4 release, and can be installed from the following tag: `v4.52.4-Kyutai-STT-preview`.\r\n\r\nIn order to install this version, please install with the following command:\r\n\r\n```\r\npip install git+https://github.com/huggingface/transformers@v4.52.4-Kyutai-STT-preview\r\n```\r\n\r\nIf fixes are needed, they will be applied to this release; this installation may therefore be considered as stable and improving.\r\n\r\nAs the tag implies, this tag is a **_preview_** of the Kyutai-STT model. This tag is a tagged version of the `main` branch and does not follow semantic versioning. This model will be included in the next minor release: `v4.53.0`.\r\n\r\n## Kyutai-STT\r\n\r\n<img src=\"https://huggingface.co/datasets/eustlb/documentation-images/resolve/main/kyutai_stt.png\"/>\r\n\r\nKyutai STT is a speech-to-text model architecture based on the [Mimi codec](https://huggingface.co/docs/transformers/en/model_doc/mimi), which encodes audio into discrete tokens in a streaming fashion, and a [Moshi-like](https://huggingface.co/docs/transformers/en/model_doc/moshi) autoregressive decoder. Kyutaiâ€™s lab has released two model checkpoints:\r\n- [kyutai/stt-1b-en_fr](https://huggingface.co/kyutai/stt-1b-en_fr): a 1B-parameter model capable of transcribing both English and French\r\n- [kyutai/stt-2.6b-en](https://huggingface.co/kyutai/stt-2.6b-en): a 2.6B-parameter model focused solely on English, optimized for maximum transcription accuracy\r\n\r\n\r\n## Usage example\r\n\r\nKyutai-STT can be found on the [Huggingface Hub](https://huggingface.co/models?other=stt).\r\n\r\n### Inference\r\n\r\n```python\r\nimport torch\r\nfrom datasets import load_dataset, Audio\r\nfrom transformers import KyutaiSpeechToTextProcessor, KyutaiSpeechToTextForConditionalGeneration\r\n\r\n# 1. load the model and the processor\r\ntorch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\nmodel_id = \"kyutai/stt-2.6b-en\"\r\n\r\nprocessor = KyutaiSpeechToTextProcessor.from_pretrained(model_id)\r\nmodel = KyutaiSpeechToTextForConditionalGeneration.from_pretrained(model_id, device_map=torch_device)\r\n\r\n# 2. load audio samples\r\nds = load_dataset(\r\n    \"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\"\r\n)\r\nds = ds.cast_column(\"audio\", Audio(sampling_rate=24000))\r\n\r\n# 3. prepare the model inputs\r\ninputs = processor(\r\n    ds[0][\"audio\"][\"array\"],\r\n)\r\ninputs.to(torch_device)\r\n\r\n# 4. infer the model\r\noutput_tokens = model.generate(**inputs)\r\n\r\n# 5. decode the generated tokens\r\nprint(processor.batch_decode(output_tokens, skip_special_tokens=True))\r\n```\r\n\r\n### Batched Inference\r\n\r\n```python\r\nimport torch\r\nfrom datasets import load_dataset, Audio\r\nfrom transformers import KyutaiSpeechToTextProcessor, KyutaiSpeechToTextForConditionalGeneration\r\n\r\n# 1. load the model and the processor\r\ntorch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\nmodel_id = \"kyutai/stt-2.6b-en\"\r\n\r\nprocessor = KyutaiSpeechToTextProcessor.from_pretrained(model_id)\r\nmodel = KyutaiSpeechToTextForConditionalGeneration.from_pretrained(model_id, device_map=torch_device)\r\n\r\n# 2. load audio samples\r\nds = load_dataset(\r\n    \"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\"\r\n)\r\nds = ds.cast_column(\"audio\", Audio(sampling_rate=24000))\r\n\r\n# 3. prepare the model inputs\r\naudio_arrays = [ds[i][\"audio\"][\"array\"] for i in range(4)]\r\ninputs = processor(audio_arrays, return_tensors=\"pt\", padding=True)\r\ninputs = inputs.to(torch_device)\r\n\r\n# 4. infer the model\r\noutput_tokens = model.generate(**inputs)\r\n\r\n# 5. decode the generated tokens\r\ndecoded_outputs = processor.batch_decode(output_tokens, skip_special_tokens=True)\r\nfor output in decoded_outputs:\r\n    print(output)\r\n```",
  "publishedAt": "2025-06-24T16:05:00.000Z",
  "source": "Hugging Face GitHub",
  "sourceUrl": "https://github.com/huggingface/transformers/releases/tag/v4.52.4-Kyutai-STT-preview",
  "category": "tools",
  "company": "Hugging Face",
  "imageUrl": null,
  "tags": [
    "AI",
    "Transformer"
  ],
  "featured": false
}